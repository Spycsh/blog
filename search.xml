<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[kafka & page cache & zero copy]]></title>
    <url>%2Fblog%2F2021%2F08%2F18%2Fkafka-page-cache%2F</url>
    <content type="text"><![CDATA[kafka为什么那么快 page cacheLinux中引入 Cache 层的目的是为了提高 Linux 操作系统对磁盘访问的性能。Cache 层在内存中缓存了磁盘上的部分数据。当数据的请求到达时，如果在 Cache 中存在该数据且是最新的，则直接将数据传递给用户程序，免除了对底层磁盘的操作，提高了性能。Cache 层也正是磁盘 IOPS 为什么能突破 200 的主要原因之一。 在 Linux 的实现中，文件 Cache 分为两个层面，一是 Page Cache，另一个 Buffer Cache，每一个 Page Cache 包含若干 Buffer Cache。Page Cache 主要用来作为文件系统上的文件数据的缓存来用，尤其是针对当进程对文件有 read/write 操作的时候。Buffer Cache 则主要是设计用来在系统对块设备进行读写的时候，对块进行数据缓存的系统来使用。 page cache与buffer cache的共同目的都是加速数据I/O：写数据时首先写到缓存，将写入的页标记为dirty，然后向外部存储flush，也就是缓存写机制中的write-back（另一种是write-through，Linux未采用）；读数据时首先读取缓存，如果未命中，再去外部存储读取，并且将读取来的数据也加入缓存。操作系统总是积极地将所有空闲内存都用作page cache和buffer cache，当内存不够用时也会用LRU等算法淘汰缓存页。 在Linux 2.4版本的内核之前，page cache与buffer cache是完全分离的。但是，块设备大多是磁盘，磁盘上的数据又大多通过文件系统来组织，这种设计导致很多数据被缓存了两次，浪费内存。所以在2.4版本内核之后，两块缓存近似融合在了一起：如果一个文件的页加载到了page cache，那么同时buffer cache只需要维护块指向页的指针就可以了。只有那些没有文件表示的块，或者绕过了文件系统直接操作（如dd命令）的块，才会真正放到buffer cache里。因此，我们现在提起page cache，基本上都同时指page cache和buffer cache两者，本文之后也不再区分，直接统称为page cache。 Kafka为什么不自己管理缓存，而非要用page cache？原因有如下三点： JVM中一切皆对象，数据的对象存储会带来所谓object overhead，浪费空间； 如果由JVM来管理缓存，会受到GC的影响，并且过大的堆也会拖累GC的效率，降低吞吐量； 进程重启，JVM自己管理的缓存数据会全部丢失，Page cache还在。 12345678Producer ---pwrite--&gt; | [(JVM Heap) Page Cache] ---&gt;send file --&gt; Consumer | | sync | | Disk producer生产消息时，会使用pwrite()系统调用【对应到Java NIO中是FileChannel.write() API】按偏移量写入数据，并且都会先写入page cache里。consumer消费消息时，会使用sendfile()系统调用【对应FileChannel.transferTo() API】，零拷贝地将数据从page cache传输到broker的Socket buffer，再通过网络传输。 图中没有画出来的还有leader与follower之间的同步，这与consumer是同理的：只要follower处在ISR中，就也能够通过零拷贝机制将数据从leader所在的broker page cache传输到follower所在的broker。 如果Kafka producer的生产速率与consumer的消费速率相差不大，那么就能几乎只靠对broker page cache的读写完成整个生产-消费过程 两个问题：JVM堆大小（5~8GB，剩下的系统内存都作为page cache空间以最大化I/O效率）？lagging consumer冷热数据问题（消费速率慢、明显落后的consumer大概率不在broker page cache中，它们不必要的读盘仍会使冷数据进入page cache）。 zero copyproducer -&gt; broker -&gt; consumer 数据传送的过程的性能影响到kafka的整天吞吐量。 传统的 Linux 系统中，标准的 I/O 接口（例如 read，write）都是基于数据拷贝操作的，即 I/O 操作会导致数据在内核地址空间的缓冲区和用户地址空间的缓冲区之间进行拷贝，所以标准 I/O 也被称作缓存 I/O。这样做的好处是，如果所请求的数据已经存放在内核的高速缓冲存储器中，那么就可以减少实际的 I/O 操作，但坏处就是数据拷贝的过程，会导致 CPU 开销。 Producer -&gt; broker1234data = socket.read()// 读取网络数据 File file = new File() file.write(data)// 持久化到磁盘 file.flush() 这一过程实际上发生了四次数据拷贝： 首先通过 DMA copy 将网络数据拷贝到内核态 Socket Buffer 然后应用程序将内核态 Buffer 数据读入用户态（CPU copy） 接着用户程序将用户态 Buffer 再拷贝到内核态（CPU copy） 最后通过 DMA copy 将数据拷贝到磁盘文件 网卡–DMA copy–&gt;Socket缓存区–CPU copy–&gt;用户缓存–CPU copy–&gt;内核缓存区–DMA copy–&gt;磁盘 kafka直接在内核空间完成落盘，而不用读到应用进程缓冲区（broker收到数据后持久化）。采用mmap文件（Memory Mapped Files，使用page来实现文件到物理内存的直接映射）映射实现内核缓冲区与应用程序内存的共享，也就是Page cache。 mmap 也有一个很明显的缺陷——不可靠，写到 mmap 中的数据并没有被真正的写到硬盘，操作系统会在程序主动调用 flush 的时候才把数据真正的写到硬盘。Kafka 提供了一个参数——producer.type 来控制是不是主动 flush；如果 Kafka 写入到 mmap 之后就立即 flush 然后再返回 Producer 叫同步(sync)；写入 mmap 之后立即返回 Producer 不调用 flush 就叫异步(async)，默认是 sync。 DMA（Direct Memory Access）：直接存储器访问。DMA 是一种无需 CPU 的参与，让外设和系统内存之间进行双向数据传输的硬件机制。使用 DMA 可以使系统 CPU 从实际的 I/O 数据传输过程中摆脱出来，从而大大提高系统的吞吐率。 然后就是DMA copy到磁盘文件。 broker 到 Consumer12buffer = File.readSocket.send(buffer) 首先通过系统调用将文件数据读入到内核态 Buffer（DMA 拷贝） 然后应用程序将内存态 Buffer 数据读入到用户态 Buffer（CPU 拷贝） 接着用户程序通过 Socket 发送数据时将用户态 Buffer 数据拷贝到内核态 Buffer（CPU 拷贝） 最后通过 DMA 拷贝将数据拷贝到 NIC Buffer Linux 2.4+ 内核通过 sendfile 系统调用，提供了零拷贝。数据通过 DMA 拷贝到内核态 Buffer 后，直接通过 DMA 拷贝到 NIC Buffer，无需 CPU 拷贝。这也是零拷贝这一说法的来源。除了减少数据拷贝外，因为整个读文件 - 网络发送由一个 sendfile 调用完成，整个过程只有两次上下文切换，因此大大提高了性能。 Kafka 在这里采用的方案是通过 NIO 的 transferTo/transferFrom 调用操作系统的 sendfile 实现零拷贝。总共发生 2 次内核数据拷贝、2 次上下文切换和一次系统调用，消除了 CPU 数据拷贝 批处理在很多情况下，系统的瓶颈不是 CPU 或磁盘，而是网络 IO。 因此，除了操作系统提供的低级批处理之外，Kafka 的客户端和 broker 还会在通过网络发送数据之前，在一个批处理中累积多条记录 (包括读和写)。记录的批处理分摊了网络往返的开销，使用了更大的数据包从而提高了带宽利用率。 数据压缩Producer 可将数据压缩后发送给 broker，从而减少网络传输代价，目前支持的压缩算法有：Snappy、Gzip、LZ4。数据压缩一般都是和批处理配套使用来作为优化手段的。 Referencehttps://cloud.tencent.com/developer/article/1488144 https://xie.infoq.cn/article/c06fea629926e2b6a8073e2f0]]></content>
  </entry>
  <entry>
    <title><![CDATA[Emacs常用命令]]></title>
    <url>%2Fblog%2F2021%2F08%2F03%2FEmacs%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Emacs常用的有用的命令汇总 启动/打开/新建文件: emacs example.erl C-x表示按住CTRL键，然后按x M-x表示先按住Alt键，然后按x 取消执行 C-g，按错键或中断emacs命令可以按C-g 翻页 C-v 上一页 M-v (view next screen) 移到行头 C-a，行尾 C-e，移到句首 M-a，到句尾 M-e，移到文档投 M-&lt;, 档尾 M-&gt; 删到行尾(剪贴) C-k ，删掉选中highlight的区域 C-w，黏贴 C-Y C-x 1 （One Window) C-x 2 （two Window) 保存 C-x C-c 查看buffer C-x C-b 切换Mode（Fundamental原始编辑模式，C-mode,lisp-mode,tex-mode,text-mode等等）M-x fundamental-mode可以变回来，可以用tab补全 查找 C-s （forward）C-r (backward)，想要看下一个就可以再按C-s或C-r。按C-g可以取消搜索跳回原位置，按enter可以让游标停在找到的地方 grep替代品（使用regex），M-x occur M-x replace 然后按tab，可以替换从光标开始所有的字符 Emacs的一些package：M-x shell 开个shell]]></content>
      <tags>
        <tag>tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB笔记]]></title>
    <url>%2Fblog%2F2021%2F08%2F02%2FMongoDB%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[MongoDB的一些总结与实验 MongoDB介绍MongoDB是一个面向文档的数据库。它没有“行”的概念，没有预定义的schema，key和value不再是固定的类型和大小。 MongoDB适合横向扩展，能自动处理跨集群的数据和负载，自动重新分配文档，以及将用户请求路由到正确的机器上。如果一个集群需要更大的容量，只需要向集群添加新服务器，MongoDB就会自动将现有数据向新服务器传送。 MongoDB支持二级索引、唯一索引、复合索引、地理空间索引、全文索引；支持聚合管道；支持时间有限的集合（session）和一定大小的集合（log）。支持存储大文件和metadata。 MongoDB主要目标是高性能，能对document进行dynamic padding，也能预分配数据文件来换取稳定的性能。它把尽可能多的内存当作缓存。但不追求关系型数据库的全部功能，而是把处理逻辑交给客户端代码实现。 MongoDB基础MongoDB中，document是基本单元，collection可以看作是一个拥有dynamic schema的表，一个实例可以有多个db，每个db有自己的collection。自带js shell。 一个基本的文档1&#123;"greeting":"Hello, world!", "foo":3&#125; 不能含有\0，这表示末尾。.和$具有特殊意义。 不能有重复的键，区分大小写，且区分类型。 文档的键值对是有序的，会对字段重新排序。 shell打开mongo后默认有3个数据库，config（分片设置）、admin（身份验证）、local（不可复制，一台服务器所有本地集合都可存储在这个数据库）。如果要使用cms数据库中的blog.posts集合，就可以用cms.blog.posts。 shell 操作1234567891011use blogpost = &#123;"title":"example"&#125;// 插入db.blog.insert(post)//读取db.blog.findOne()// 更新post.comments = []db.blog.update(&#123;title:"example"&#125;,post)// 删除db.blog.remove(&#123;title:"example"&#125;) 数据类型近似类似于JSON，有null、布尔、数字、字符串、数组和对象这几种数据类型。不同的是，还添加了日期类型和一些其它数据类型。 1234567891011121314151617181920212223&#123;"x":null&#125;&#123;"x":true&#125;// 默认64位浮点型数值&#123;"x":3.14&#125;// 整型&#123;"x" : NumberInt("3")&#125;// Long&#123;"x" : NumberLong("3")&#125;// 字符串&#123;"x":"foobar"&#125;// date类型：//ISODate("2021-08-02T19:51:17.878Z")&#123;"x": new Date()&#125;// 正则, 不区分大小写&#123;"x":/foobar/i&#125;// 数组&#123;"x":["a","b","c"]&#125;// 内嵌文档&#123;"x":&#123;"foo":"bar"&#125;&#125;// 对象id&#123;"x":ObjectId()&#125;// js代码&#123;"x":function()&#123;/*...*/&#125;&#125; 每个文档都有一个ObjectId的12个字节（24个16进制数，举例：{“_id” : ObjectId(“5fe3c9b3f12bbe57b8f62978”)}）按照以下方式生成 0~3字节：4个字节的时间戳4~6字节：3字节机器号（机器主机名的hash值）7~8字节：2字节PID进程号9~11字节：3字节自动增加的计数器，保证同一秒生成的ObjectId也是不一样的，允许每秒每个进程有2^24(16777216)个不同的ObjectId shell tips123456// 连通别的计算机的Mongo实例mongo some-host:30000/myDB// 或者mongo --nodbconn = new Mongo("some-host:30000")db = conn.getDB("myDB") 增删查改文档insert插入一个文档到目标集合 db.foo.insert({&quot;bar&quot;:&quot;baz&quot;}) 批量插入多个文档到一个集合 db.foo.batchInsert([{&quot;_id&quot;:0}, {&quot;_id&quot;:1}, {&quot;_id&quot;:2}]) mongo shell中比较实验10000次插入，每次插入一条数据：12345678910var timeInsert = function()&#123; var start1 = (new Date()).getTime(); for(var i=0; i&lt;10000; i++)&#123; db.test.insert(&#123;"foo":i, "oof":i&#125;) &#125; var timeDiff1 = (new Date()).getTime() - start1; print("insert 1000000 documents into MongoDB cost: "+timeDiff1+"ms");&#125;timeInsert(); 1次插入1万条数据 注意：mongo中的batchInsert方法已经废弃，直接用insert就行了 12345678910111213var timeBatchInsert = function(records)&#123; var start2 = (new Date()).getTime(); db.test.insert(records); var timeDiff2 = (new Date()).getTime() - start2; return timeDiff2;&#125;records = [];for(var i=0; i&lt;10000; i++)&#123; records.push(&#123;"foo":i, "oof":i&#125;);&#125;timeBatchInsert(records) 实验结果得出，前者花费7216ms，后者花费134毫秒。可见，一次性insert多个记录要快得多。 一次发送多个文档会提高插入的速度。不能重复插入，如果一个插入失败，之前的都会成功，之后的都会插入失败（可以用continueOnError选项强制执行后续插入。 insert check：所有文档都需小于16MB，要查看某个文档doc的BSON大小（字节）可以在shell中执行Object.bsonsize(doc)。不包含非UTF-8的字符串，以及类型检查。 delete删除db.foo.remove() 删除mailing.list集合中所有”opt-out”为true的人db.mailing.list.remove({&quot;opt-out&quot;:true}) 直接drop删除集合更快db.mailing.list.drop() update先find到唯一记录再update1234567joe = db.people.findOne(&#123;"name":"joe","age":20&#125;);// 添加一个新的子文档relationshipjoe.relationships = &#123;"friends":joe.friends, "enemies":joe.enemies&#125;;delete joe.friends;delete joe.enemies;// 更新db.people.update(&#123;"name":"joe"&#125;, joe); 问题是如果若有多个name叫joe的，那么update条件就必须唯一，可以使用_id来指明。 而使用_id作为查询条件比随机字段速度更快，因为是通过_id建立了索引。 使用修改器总结的update模板 12db.表名.update(&#123;过滤条件&#125;, &#123;修改器:&#123;键，值&#125;&#125;) 键的值加一12db.analytics.update(&#123;"url":"www.example.com"&#125;, &#123;"$inc":&#123;"pageviews":1&#125;&#125;) // 用$inc修改器增加pageviews的值，增加1 加/修改一对键值12db.users.update(&#123;"_id":ObjectId("...")&#125;, &#123;"$set":&#123;"favorite book":"War and Peace"&#125;&#125;) // 用$set修改器加一对键值 删除一对键值12db.users.update(&#123;"_id":ObjectId("...")&#125;, &#123;"$unset":&#123;"favorite book":1&#125;&#125;) // 用$unset修改器删除1个键 数组添加元素（如果没有就创建一个新的数组）1234db.blog.posts.update(&#123;"title":"A blog post"&#125;, &#123;"$push":&#123;"comments": // $push &#123;"name":"joe","email":"joe@example.com", "content":"nice post."&#125;&#125;&#125;) 一次添加多个值$push:{&quot;comments&quot;:{&quot;$each&quot;:[aa,bb]}} 数组删除元素{&quot;$pop&quot;:{&quot;key&quot;:1}} 更多操作请查看原书 修改器速度 $inc较快因为能就地修改，由于在磁盘上，文档都是顺序写的，所以若一个文档变大了，原先的位置放不下这个文档，就要移到到集合另一个位置。这时就会修改集合的填充因子（padding factor），可以通过db.coll.stats()查看，初始值是1。之后插入的新文档都会拥有填充因子指定大小的增长空间，如果之后的插入中不再发生文档移到，填充因子会逐渐变小。 upsertupsert是一种特殊的更新，要是没有找到符合更新条件的文档，就会以这个条件和更新文档为基础创建一个新的文档。如果找到了匹配的文档，则正常更新。 最基础的方法（可能有多个进程同时运行代码，导致同时对给定URL插入到多个文档这样的race condition）123456789// 检查这个页面是否有一个文档, url会自动转化成stringblog = db.analytics.findOne(&#123;url : "/blog"&#125;)// 如果有，就将视图数加/并保存if (blog) &#123; blog.pageviews++; db.analytics.save(blog);&#125;else&#123; // 否则为这个页面创建一个新文档 db.analytics.save(&#123;url:"/blog",pageviews:1&#125;)&#125; 可以防止race condition的原子性的upsert方法1db.analytics.update(&#123;"url":"/blog"&#125;,&#123;"$inc":&#123;"pageviews":1&#125;&#125;, true&#125;); // true表示upsert $setOnInsert没有就创建字段并为它赋值，但是之后所有更新，字段值不再改变。 更新多个文档为所有该生日用户都添加了gift键1db.users.update(&#123;"birthday":"10/13/1978"&#125;, &#123;"$set":&#123;"gift":"Happy Birthday!"&#125;&#125;, false, true); // 第四个参数设成true 应答式/非应答式写入 非应答式写入不会抛出异常（比如插入重复键值） 查询db.users.find({}, {&quot;username&quot; : 1, &quot;email&quot; : 1}) 只返回username，email信息 条件查询“$lt”,”$lte”,”$gt”,”gte”, “$ne”比较操作符db.users.find({&quot;age&quot; : {&quot;$gte&quot; : 18, &quot;$lte&quot; : 30}}) db.users.find({&quot;registered&quot;:{&quot;$lt&quot;:new Date(&quot;01/01/2007&quot;)}}) 另外，可以用”$in”,”$nin”,”$or”,”$not”,”$mod”,”$not”等，参见原书。 特定类型的查询MongoDB使用Perl兼容的正则表达式（PCRE）来匹配。 db.users.find({&quot;name&quot;: /joe/i}) 查询前10个（后10个就slice改成-10，也可以用[23, 10]代表返回从24~33个元素db.blog.posts.findOne(criteria, {&quot;comments&quot;:{&quot;$slice&quot;:10}}) 查询内嵌文档（例如查询名字为joe的文档），原来查询指定精确匹配的条件12345678910&#123; "name" : &#123; "first" : "Joe", "last" : "Schmoe" &#125;, "age" : 45&#125; db.people.find(&#123;"name" : &#123;"first" : "Joe", "last" : "Schmoe"&#125;&#125;) 如果加一个middle名，就不能这样精确匹配，而是要用点表示法1db.people.find(&#123;"name.first":"Joe","name.last":"Schmoe"&#125;) 查询由Joe发表的5分以上的评论1234567891011121314151617181920&gt; db.blog.find()&#123; "content" : "...", "comments" : [ &#123; "author" : "joe", "score" : 3, "comment" : "nice post" &#125;, &#123; "author" : "mary", "score" : 6, "comment" : "terrible post" &#125; ]&#125;// 使用$elemMatch,不用的话会返回错误的记录&gt; db.blog.find(&#123;"comments" : &#123;"$elemMatch" : &#123;"author" : "joe", "score" : &#123;"$gte" : 5&#125;&#125;&#125;&#125;) 服务器脚本在服务器上执行js脚本很容易受到注入攻击。 游标数据库使用游标返回find的执行结果。客户端对游标的实现能对最终结果进行有效的控制。可以限制结果的数量，略过部分结果，根据任意键按任意顺序的组合对结果进行各种排序，或者执行一些其他强大的操作。 1234567891011&gt; for(i=0; i&lt;100; i++) &#123;... db.collection.insert(&#123;x : i&#125;);... &#125;&gt; var cursor = db.collection.find();&gt; while (cursor.hasNext()) &#123;... obj = cursor.next();... // do stuff... &#125;&gt; cursor.forEach(function(x) &#123;... print(x.name);... &#125;); 这样得到cursor的查询都没有真正执行，直到hasNext或next方法被调用时，查询被发往服务器，shell立刻获取前100个结果或者前4MB数据（两者较小者），这样下一次hasNext或next就不用再次连接服务器取结果了，直到用光第一组结果会再次联系数据库。 limit，skip和sort下面几种是等价的123&gt; var cursor = db.foo.find().sort(&#123;"x" : 1&#125;).limit(1).skip(10);&gt; var cursor = db.foo.find().limit(1).sort(&#123;"x" : 1&#125;).skip(10);&gt; var cursor = db.foo.find().skip(10).limit(1).sort(&#123;"x" : 1&#125;); sort按照username升序以及age降序db.c.find().sort({username : 1, age : -1}) 获取一致性结果当cursor hasNext时，一个文档改了之后，如果体积变大了，再存进去，就会放到集合末尾，也会再最后被重新遍历到。为此必须使用snapshot，查询就会在”_id”索引上遍历执行，这样就可以保证每个文档只被返回一次。 db.foo.find().snapshot() 索引索引简介一个比较创建索引前后的实验 书上的例子已过时，具体参考文档，原来的执行时间millis属性已被改成executionStats.executionTimeMillis，以下是一个正确的例子 123456789&gt; use testswitched to db test&gt; for(i=0;i&lt;100000;i++)&#123;... db.users.insert(... &#123;... "i":i,... "username":"user"+i,"age":Math.floor(Math.random()*120),"created":new Date()&#125;... );... &#125; 12345678910111213141516171819202122232425262728&gt; db.users.find(&#123;username:"user101"&#125;).explain("executionStats").executionStats&#123; "executionSuccess" : true, "nReturned" : 1, "executionTimeMillis" : 62, "totalKeysExamined" : 0, "totalDocsExamined" : 100000, "executionStages" : &#123; "stage" : "COLLSCAN", "filter" : &#123; "username" : &#123; "$eq" : "user101" &#125; &#125;, "nReturned" : 1, "executionTimeMillisEstimate" : 1, "works" : 100002, "advanced" : 1, "needTime" : 100000, "needYield" : 0, "saveState" : 100, "restoreState" : 100, "isEOF" : 1, "direction" : "forward", "docsExamined" : 100000 &#125;&#125; 在username上建立索引：1&gt; db.users.ensureIndex(&#123;"username" : 1&#125;) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758&gt; db.users.find(&#123;username:"user101"&#125;).explain("executionStats").executionStats&#123; "executionSuccess" : true, "nReturned" : 1, "executionTimeMillis" : 0, "totalKeysExamined" : 1, "totalDocsExamined" : 1, "executionStages" : &#123; "stage" : "FETCH", "nReturned" : 1, "executionTimeMillisEstimate" : 0, "works" : 2, "advanced" : 1, "needTime" : 0, "needYield" : 0, "saveState" : 0, "restoreState" : 0, "isEOF" : 1, "docsExamined" : 1, "alreadyHasObj" : 0, "inputStage" : &#123; "stage" : "IXSCAN", "nReturned" : 1, "executionTimeMillisEstimate" : 0, "works" : 2, "advanced" : 1, "needTime" : 0, "needYield" : 0, "saveState" : 0, "restoreState" : 0, "isEOF" : 1, "keyPattern" : &#123; "username" : 1 &#125;, "indexName" : "username_1", "isMultiKey" : false, "multiKeyPaths" : &#123; "username" : [ ] &#125;, "isUnique" : false, "isSparse" : false, "isPartial" : false, "indexVersion" : 2, "direction" : "forward", "indexBounds" : &#123; "username" : [ "[\"user101\", \"user101\"]" ] &#125;, "keysExamined" : 1, "seeks" : 1, "dupsTested" : 0, "dupsDropped" : 0 &#125; &#125;&#125; 可以发现，executionTimeMillis执行时间显著减少。 复合索引在如下的sort代码中，对单个username建索引作用不大，因为sort是先对age进行1&gt; db.users.find().sort(&#123;"age" : 1, "username" : 1&#125;) 此时可以建立复合索引compound index db.users.ensureIndex({&quot;age&quot; : 1, &quot;username&quot; : 1}) 例子：假设我们有一个users集合，如果在这个集合上执行一个自然顺序的查询。如何建立索引？如何查询比较快？ 复合索引结构大致如下：123[0, &quot;user100309&quot;] -&gt; 0x0c965148[0, &quot;user100334&quot;] -&gt; 0xf51f818e[0, &quot;user100479&quot;] -&gt; 0x00fd7934 对索引的使用方式取决于查询的类型 db.users.find({“age”:21}).sort({“username”:-1}) Mongo从age等于21匹配的最后一个索引开始，逆序依次遍历索引。 db.users.find({“age”:{“$gte”:21,”$lte”:30}}) 查询结果按照索引顺序排列，也即先age再username 应当特别注意，用来排列的键可能是字符串类型，也就是1、10、100这样 db.users.find({“age”:{“$gte”:21,”$lte”:30}}).sort({“username”:1}) 这样第一个find得到的结果username是无序的，尤其是当find的结果集大于32MB进行排序就会报错，因此如果文档很大，使用{&quot;username&quot; : 1，&quot;age&quot; : 1}作索引。先对username有序sort，再对sort的结果集进行find，这样也有缺点就是find的时间会很长，需要对全表扫描。 《高性能MySQL》一书中提到的一个经验法则：将选择性最高的列放到索引最前列。”选择性最高”指的是差异性最大，也即这一列的重复值最少. 123456// 前者时间显著大于后者&gt; db.users.find(&#123;"age" : &#123;"$gte" : 21, "$lte" : 30&#125;&#125;).sort(&#123;"username" : 1&#125;).explain()// 可以通过hint来强制MongoDB使用某个特定的索引&gt; db.users.find(&#123;"age" : &#123;"$gte" : 21, "$lte" : 30&#125;&#125;).sort(&#123;"username" : 1&#125;).hint(&#123;"username" : 1, "age":1&#125;).explain() 但是，在上面用limit(1000)会发现后者比前者快很多。 ensureIndexes()添加索引db.users.ensureIndex({&#39;username&#39;: 1}), 1代表从小到大顺序getIndexes()查看索引db.users.getIndexes()dropIndex删除索引db.users.dropIndex(&quot;username_1&quot;) 何时不应该用索引文档较小，集合较小或非选择性查询时，不应该使用索引。想象每次要返回集合95%的文档，还不如不建索引。区间查询时，使用索引就可以顺序的取文档出来，索引就很有用。 索引类型 唯一索引 可以确保集合的每个文档的指定键都有唯一值。 db.users.ensureIndex({‘username’: 1, unique: true}) ，指定unique: true，如果插入2个相同都叫张三的数据，第二次插入的则会失败。_id即为唯一索引，并且不能删除。 稀疏索引 聚合对数据进行分析并加以利用，就可以只有MondoDB提供的聚合工具。 聚合框架用多个component创建一个pipeline，对一连串的文档处理，这样的component包括filtering、projecting、grouping、sorting、limiting和skipping。 一个例子 12345678910// 1. 将每个文章文档中的作者投射出来。// 2. 将作者按照名字排序，统计每个名字出现的// 次数。// 3. 将作者按照名字出现次数降序排列。// 4. 将返回结果限制为前5个。db.articles.aggregate( &#123;"$project":&#123;"author":1&#125;&#125;, // 每个文档会以&#123;"_id":id,"author":"authorName"&#125;形式表示，并且只存在内存中 &#123;"$group":&#123;"_id":"$author","count":&#123;"$sum":1&#125;&#125;&#125;, // &#123;"$sort":&#123;"count":-1&#125;&#125;, &#123;"$limit":5&#125;) 聚合的结果必须要限制在16 MB以内（MongoDB支持的最大响应消息大小） 管道操作符$match: { $match : { score : { $gt : 70, $lte : 90 } } } $project: {“$project” : {“author” : 1, “_id” : 0}} 包括author，不包括_id $group: $group: { _id: null, count: { $sum: 1 } } 相当于select *, count(*) from mycol group by by_user $sum, $avg, $min, $max, $push, $addToSet, $first, $last $unwind: 拆分一篇有多条评论的博客文章到多个独立的文档。 $sort：与$group一样，$sort也是一个无法使用流式工作方式的操作符。”$sort”也必须要接收所有文档后才能进行排序。在分片环境下，先在各个分片上排序，再将各个分片排序结果发到mongos做进一步处理。 $limit：返回集合前n个文档 $skip：丢弃结果集的前n个文档 顺序：”$project”,”$group”,”$unwind”操作应当最先运行，将尽可能多的文档和字段过滤掉。 MapReduce有些问题过于复杂，无法用聚合框架的查询语言表达，可以使用MapReduce。 map-shuffle-reduce map to all documents -&gt; group the key values by key -&gt; reduce the values corresponding to one key to one single value 例子1：wordCount123456789101112131415161718192021map = function()&#123; for(var key in this)&#123; // this is the reference to the current document that is mapped to emit(key, &#123;count:1&#125;); &#125;&#125;;reduce = function(key, emits)&#123; total = 0; for(var i in emits)&#123; total += emits[i].count; &#125; return &#123;"count":total&#125;;&#125;// mongodb可能将这样调用reduce&gt; r1 = reduce("x",[&#123;count:1,id:1&#125;, &#123;count:1,id:2&#125;])&#123;count:2&#125;&gt; r2 = reduce("x",[&#123;count:1,id:3&#125;])&#123;count:1&#125;&gt; reduce("x", [r1,r2])&#123;count:3&#125; reduce一定要能够在之前的map阶段或者前一个reduce阶段的结果上反复执行。所以reduce返回的文档必须能作为reduce的第二个参数的一个元素 应用程序设计范式化与反范式化student, class 表，需要范式化(normalization)吗？MongoDB没有join，如果范式化，查询需要多次查询；如果不范式化(denormalization)，把classes信息内嵌到student表中，更新某个字段（比如credits）就需要更新许多记录，不划算。 第一范式（1NF，Normal Forms），列不能分成其他几列；第二范式，必须有一个主键，其他列不能只依赖于主键的一部分；第三范式，任何非主属性不依赖于其它非主属性。 内嵌数据与引用数据的比较： 更适合内嵌 major 子文档较小 子文档较大 数据不会定期改变 数据经常改变 最终数据一致即可 中间阶段的数据必须一致 文档数据小幅增加 文档数据大幅增加 数据通常需要执行二次查询才能获得 数据通常不包含在结果中 快速读取 快速写入 副本集实践mongodb采用副本集方式实现冗余，以下是windows上模拟副本集（真实情况下应当在不同机器上模拟，条件有限）的实践过程 首先建立mongoReplTest文件夹，在下面建立三个data文件夹，对应三个节点，也就是一个主节点和两个从节点组成一个副本集。 然后，打开三个shell开启3个mongod服务，指定数据库存取文件夹位置，再指定同一个replication set123mongod --port 27018 --dbpath &quot;C:\Users\Spycsh\Desktop\mongoReplTest\data1&quot; --replSet rs0mongod --port 27019 --dbpath &quot;C:\Users\Spycsh\Desktop\mongoReplTest\data2&quot; --replSet rs0mongod --port 27020 --dbpath &quot;C:\Users\Spycsh\Desktop\mongoReplTest\data3&quot; --replSet rs0 其次，打开三个shell开启3个mondo client123mongo localhost:27018mongo localhost:27019mongo localhost:27020 在端口为27018（主节点）的clinet shell中，指定它是primary节点，在它里面建立一个叫test的数据库，建立一个叫test的表，再添加一条记录123456789rs.initiate()rs.conf()// 按一下回车就可以出现rs0:PRIMARY的标识rs0:PRIMARY&gt; use testrs0:PRIMARY&gt; db.createCollection(&quot;test&quot;)rs0:PRIMARY&gt; db.test.insert(&#123;&quot;test&quot;:1&#125;)rs0:PRIMARY&gt; db.test.find()&#123; &quot;_id&quot; : ObjectId(&quot;6112daf152385613cbb6bcfc&quot;), &quot;test&quot; : 1 &#125; 再在主节点的client shell添加从节点12rs0:PRIMARY&gt; rs.add(&quot;localhost:27019&quot;)rs0:PRIMARY&gt; rs.add(&quot;localhost:27020&quot;) 再到端口为27019，27020的从节点client shell中，按一下回车就可以发现它们都变成了SECONDARY节点，执行以下命令查看主节点复制过来的数据12rs0:SECONDARY&gt; rs.secondaryOk()rs0:SECONDARY&gt; db.test.find() 把主节点变成从节点1rs.stepDown() 然后在另两个shell里面按按回车，就可以看到有一个原来的从节点变成了主节点。如果没有节点变成主节点，该节点60s后会重新选举当主节点。 阻止选举12rs.freeze(10000) // 从节点冻结10000秒，不能参加选举。常用在主节点维护且不希望其它节点成为主节点情况下rs.freeze(0) // 从节点解除冻结 监控复制1rs.status() self 这个字段只会出现在执行rs.status()函数的成员信息中 stateStr 用于描述服务器状态的字符串。 uptime 从成员可达一直到现在所经历的时间，单位是秒。 optimeDate 每个成员的oplog中最后一个操作发生的时间（也就是操作被同步过来的时间）。注意，这里状态是每个成员通过心跳报告上来的状态，所以optime跟实际时间可能会有几秒钟的偏差。 lastHeartbeat 当前服务器最后一次收到其他成员心跳的时间。如果网络故障或者当前服务器比较繁忙，这个时间可能会是2秒钟之前。 pingMs 心跳从当前服务器到达某个成员所花费的平均时间，可以根据这个字段选择从哪个成员进行同步。 errmsg 成员在心跳请求中返回的状态信息。这个字段的内容通常只是一些状态信息，而不是错误信息。 复制图谱新的备份节点通常会从与自己处于同一个数据中心的其他成员进行复制 如果在备份节点上运行rs.status()，输出信息中会有一个名为”syncSourceId”的字段，用于表示当前成员正在从哪个成员处进行复制。 复制循环A从B复制数据，B从C，C从A，没有人能成为主节点，都不能复制写操作。 禁用复制链12345&gt; var config = rs.config()&gt; // 如果设置子对象不存在，就自动创建一个空的&gt; config.settings = config.settings || &#123;&#125;&gt; config.settings.allowChaining = false&gt; rs.reconfig(config) 类似星型拓补 主从模式可以看作是没有自动故障恢复功能的副本集模式，已经弃用。 分片（sharding）也称为partitioning。指将数据分散到不同的机器上，不需要功能强大的大型计算机就可以储存更多的数据。 1234567891011// replication set实现了冗余复制与故障恢复// sharding解决了大量数据的存储与负载的水平拓展// 如下是一个replication set和sharding都考虑的示意图// A1, A2...这些都表示不同的机器// (A1, A2, A3) 代表一个replication set，每个元素都有相同的数据集// (A1, B1, C1) 涵盖了所有的数据，比如A1负责数据key hash值// 0~999的，B负责1000~1999的...以此类推(A1, A2, A3) --- (B1, B2, B3) \ / \ / (C1, C2, C3)]]></content>
  </entry>
  <entry>
    <title><![CDATA[使用sftp在不同云主机间传递文件]]></title>
    <url>%2Fblog%2F2021%2F07%2F15%2F%E4%BD%BF%E7%94%A8sftp%E5%9C%A8%E4%B8%8D%E5%90%8C%E4%BA%91%E4%B8%BB%E6%9C%BA%E9%97%B4%E4%BC%A0%E9%80%92%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[使用sftp在不同云主机间传递文件 公司里的unix工作环境都部署在citrix云上，并且都没有接入互联网。想要给同事共享一个文件就很麻烦，需要复制黏贴代码到本地windows上再邮件发过去。 无意间想到一个sftp（secure file transport protocol），大家都知道ftp是不加密的传输，而sftp可以通过ssh建立一个可靠的链路进行文件传输，就尝试用了用，发现确实可以在远程unix工作环境启动sftp然后直接共享文件给同事的unix工作环境。 unix shell命令如下 1234567891011121314151617sftp username@192.168.xx.xx # 打开sftp服务# 输入远程用户的windows密码# 一些操作，如果本地用命令就加一个l前缀就行了sftp&gt; lcd Desktop # cd到本地Desktop目录（local cd）sftp&gt; cd Desktop # 远程cd到Desktop目录sftp&gt; ls Desktop # 查看远程桌面目录下的文件sftp&gt; lls Desktop # 查看本地桌面目录下的文件sftp&gt; pwd # 查看远程工作目录sftp&gt; lpwd # 查看本地工作目录sftp&gt; get example.txt # 下载文件sftp&gt; put example.txt # 上传文件sftp&gt; mkdir new_dirsftp&gt; rmdir new_dirsftp&gt; exit # 退出 详细用法可以参见。]]></content>
      <tags>
        <tag>tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DDIA 数据密集型应用笔记 （III）]]></title>
    <url>%2Fblog%2F2021%2F07%2F13%2FDDIA-%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%AC%94%E8%AE%B0-III%2F</url>
    <content type="text"><![CDATA[Design Data-intensive applications (II) – 派生数据 本章主要会介绍面向批处理（batch processing）和面向流的处理的数据系统。 批处理系统UNIX123456cat /var/log/nginx/access/log | awk '&#123;print $7&#125;' | sort | uniq -c | sort -r -n | head -n 5 | awk命令按空格分割成不同的字段，每行打印第7个字段（也可以指定awk -F ‘//‘ ‘{print $2}’用-F表示以’//‘分隔。sort命令从大到小排，因为uniq只比较相邻行去重，所以需要sort。head表示取前五个。 使用这样的UNIX命令可以像流水线一样处理数据，每个命令处理好一件事情，组合成强大的作业。 当某个程序输出称为另一个程序的输入时，就必须统一接口。在UNIX中就是文件（文件描述符）。如上的命令将输入文件视为由\n字符分隔的记录列表。 UNIX工具另外也使用stdin和stdout。管道允许将一个进程的stdout附加到另一个进程的stdin（小的内存缓冲区）。也可以将文件作为输入/输出重定向到文件。而这里局限性是，有多个输入或输出就很棘手。用户不能pipe输出给一个网络连接。 最大的局限是，UNIX工具只能在一台机器上运行。 MapReduce与分布式文件系统UNIX工具使用stdin和stdout作为输入和输出，而MapReduce作业在分布式文件系统上读写文件。在Hadoop的MapReduce实现中，该文件系统称为HDFS。HDFS基于无共享原则。 HDFS包含一个在每台机器上运行的守护进程，并会开放一个网络服务以允许其他节点访问存储在该机器上的文件（假设数据中心的每台节点都附带一些本地磁盘）。名为NameNode的中央服务器会跟踪哪个文件块存储在哪台机器上。因此，从概念上讲，HDFS创建了一个庞大的文件系统，来充分利用每个守护进程机器上的磁盘资源。 HDFS架构和Hadoo守护进程。master节点上会运行一个叫做 namenode 的守护进程，每个 slave 节点上都会有 datanode 守护进程，两个进程都是属于HDFS 的。因此，slave 节点也叫做 datanode 节点。Namenode 主要用于存储元数据和管理 datanode 节点。而 datanode 则是真正存储数据和执行任务的地方。此外，还有一个SecondaryNameNode（管理层）辅助NameNode管理。 Apache Hadoop 工作原理： 输入数据被划分成若干个128MB（默认值）的块，然后把它们移动到不同的节点。 在多个 datanode 存储完所有数据块之后，用户才能处理这些数据。 接着，master 把用户提交的程序调度到独立的节点上。 等所有节点处理完数据之后，输出计算结果并写回 HDFS。 MapReduce作业执行JobTracker：属于管理层，管理集群资源与对任务调度，监控任务的执行TaskTracker：属于应用层，执行JobTracker分配分发的任务，并向JobTracker汇报任务的执行情况 MapReduce工作步骤： 读取一组输入文件，分解成记录，web日志例子里每个记录就是一行。 调用mapper函数从每个输入记录中提取一个键值对。 按关键字将所有键值对排序。对应日志例子里的sort。 调用reducer遍历排序后的键值对，键重复，则可以组合，对应uniq -c，reducer可以对相邻记录进行计数。 mapper 和 reducer 如何链接通过目录名隐式完成，每个命令的输出被写入临时文件，下一个命令从临时文件中读取，而不是像UNIX命令一样直接从一个进程通过很小的内存缓冲区传递到另一个进程 Hadoop的工作流调度，一个作业只有在先前的作业成功完成时才能开始，为了处理其中的依赖关系，有各种Hadoop的工作流调度器，包括Oozie，Azkaban，Luigi，Airflow和Pinball。 一个MongoDB的js的例子 1234567891011121314db.observations.mapReduce( function map() &#123; var year = this.observationTimestamp.getFullYear(); var month = this.observationTimestamp.getMonth() + 1; emit(year + &quot;-&quot; + month, this.numAnimals); &#125;, function reduce(key, values)&#123; return Array.sum(values); &#125; &#123; query: &#123;family: &quot;Sharks&quot;&#125;, out: &quot;monthlySharkReport&quot; &#125;); MapReduce的分布式执行（详见原书图10-1） MapReduce的并行化基于分区，HDFS输入目录的每个文件或文件块都被视为一个单独的分区。 MapReduce调度器会尝试在有输入文件的那台机器上运行mapper任务，这被称为计算靠近数据，避免输入文件网络复制。 1234567891011121314# 带有3个mapper和reducer的MapReduce作业# 为了确保具有相同关键字的所有键值对都在相同的reducer任务中处理，框架使用关键字的哈希值来确定哪个reduce任务接收特定的键值对---- mapper ----- ---- reducer ---- m1, r1 m1, r1m1 =&gt; m1, r2 =》 m2, r1 =&gt; r1 m1, r3 m3, r1 m2, r1 m1, r2m2 =&gt; m2, r2 =》 m2, r2 =&gt; r2 m2, r3 m3, r2 m3, r1 m1, r3m3 =&gt; m3, r2 =》 m2, r3 =&gt; r3 m3, r3 m3, r3 每当mapper完成读取输入文件并写入经过排序的输出文件，MapReduce调度器就会通知reducer开始从mapper中获取输出文件。根据key哈希值，有相同的key的kv pair会复制到同一个reducer。 Reduce端的join与分组查询涉及少量记录，对全表扫描费时，建索引比较好。 分析查询，则需要并行扫描数据集。 12345678# loguser 105 clicked button ... to load URL ... user 296 viewed the profile of user 134 user 251 logged out from browser session ...# dbuser_id email data_of_birth105 ... 活动事件需要与用户描述的数据库进行join。但是尽量应该在一个机器上运行，因此应当获取db副本，将其放在HDFS的一组文件中，并将用户活动记录放在另一组文件中，然后用MapReduce将所有记录集中到一起，从而有效处理它们。 排序-合并join 使用相同的ID遍历活动事件，输出相应的已观看网址和观看者年龄。详见书图10-3 分组GROUP BY + COUNT(*) / SUM(fieldname) / topK 收集用户会话（使用会话cookie、用户id作key）的所有活动事件，确定选择网站新版本的用户是否比选择旧版本(A / B测试）的用户更有可能产生购买行为。将不同用户的事件分配到不同分区。 处理数据倾斜有些用户有上百万关注者，这些人被称为热键。 某个reducer必须处理比其他reducer更多的记录。然而，MapReduce必须等到所有mapper和reducer都完成时才能完成。 解决方法是先抽样作业(Pig)或明确指定(Crunch)哪些是热键，然后复制到多个reducer并行处理。 Hive则是明确指定哪些是热键，然后独立出来，使用map端join。 map端joinreducer join：mapper从每个输入记录中提取关键字和值，将键值对分配给reducer分区，并按关键字排序。这样的问题是复制到reducer以及合并reducer输入可能会是非常昂贵的操作。 而map端join则是缩减版的MapReduce作业。没有reducer，没有排序，每个mapper只需从分布式文件系统中读取输入文件块，然后将输出文件写入文件系统即可。 以下是三种优化： 广播哈希join 实现map端join的最简单方法广播哈希适合大数据与小数据join，尤其当小数据集能够全部加载到每个mapper的内存（以哈希表形式）中。每个大数据集的分区都会读取整个小数据集。 另外不一定要把小数据集保存在哈希表中，也可以保存到本地磁盘上的只读索引中（驻留在操作系统的页面缓存中）。 Hive中称为（MapJoin），Pig中称为（replicated join）。 分区哈希join 如果以“相同”方式对map端的join的输入进行分区（某个key都在一个分区里），则哈希join方法可以独立作用于每个分区。例如，可以根据用户ID的最后一个数字来分配活动事件和用户数据库的记录。 这样的优点是每个mapper都可以将较少的数据加载到其哈希表中。 Hive这称为bucketed map join。 map端合并join 输入数据集不仅以“相同”的方式进行了分区（某个key都在一个分区里），也同时基于相同关键字进行了排序，可以使用另一种变体。 直接按关键字升序增量读取两个输入文件，并且匹配具有相同关键字的记录。 MapReduce的弊端中间状态实体化 某些任务需要比其他任务花费更长的时间，必须等待前面作业所有任务完成会减慢整个工作流的执行。 mapper有时是冗余的。可能只需要mapper-&gt;reducer-&gt;reducer-&gt;reducer…，直接链接在一起 将中间状态存储在分布式文件系统中意味着这些文件被复制到多个节点，这对临时数据来说是大材小用了。 数据流引擎为了解决以上问题，开发了分布式批处理的新的执行引擎：Spark，Tez和Flink。也是有分区并行工作，复制输出到网络，成为另一个功能的输入。不同的是 不需要map和reduce，而是用更灵活的函数运算符 排序等代价昂贵的实际需要才进行 没有不必要的mapper 所有join和数据依赖明确声明，因此调度器知道哪些数据在哪里是必须的，可以本地优化。 例如，可以尝试将占用某些数据的任务放在与生成它的任务相同的机器上，以便可以通过共享内存缓冲区来交换数据，而不必通过网络复制数据。 中间状态保存在内存或本地磁盘而不是HDFS(复制到多个节点并写入每个副本所在的磁盘) 运算符可以在输入准备就绪后立即开始执行，无须等待前一个全部完成。 MapReduce为每个任务启动一个新的JVM，现有Java虚拟机JVM可以被重用来运行新的运算符，减少开销。 容错Spark, Flink和Tez避免将中间状态写入HDFS, 所以它们采用不同的方法来容忍错误： 如果机器发生故障， 并且该机器上的中间状态丢失， 则利用其他可用的数据重新计算（例如之前的中间阶段， 如果可能的话；或原始输入数据， 通常在HDFS上）。为了实现重新计算，框架必须追踪给定数据是如何计算的， 使用了哪个输入分区，以及应用了哪个运算符。Spark使用弹性分布式数据集(Resilient Distributed Dataset, RDD)抽象来追踪数据的祖先, 而Flink对运算符状态建立检查点，从而允许将执行过程中遇到故障的运算符恢复运行。 流处理系统 为什么需要流处理？输入是有限大小的，批处理知道何时读完它们。而流处理则是只要有事件就开始处理。这个概念简单的例子有UNIX的stdin和stdout、Java的FileInputStream、TCP连接、通过互联网传送音频和视频等。 批处理的基本对象是记录，在流处理里则称之为事件，通常带有时间戳。在文件系统中，文件名标识一组相关记录，在流处理系统中，相关事件通常被组合成主体或流。 生产者将其生成的每个事件写入数据存储，并且每个消费者定期轮询数据存储以检查自上次运行以来出现的事件。 但是，如果数据存储没有特别为这种轮询设计，那么轮询次数越多，返回新事件请求的百分比越低。所以当新事件出现时，最好通知消费者。 传统数据库只有触发器（行插入表时），功能有限，因此开发了专门的工具用来提高事件通知。 消息系统UNIX管道和TCP连接一个发送者和一个接收者。而消息系统允许多个生产者节点将消息发送到同一主题，并允许多个消费者节点接收主题中的消息。 如果生产者发送消息的速度比消费者所能处理的快，会发生什么？一般来说，有三种选择：系统丢弃消息；将消息缓存在队列中；或者激活背压，也称为流量控制（即阻止生产者发送更多消息）。例如，UNIX管道和TCP使用背压： 他们有一个固定大小的小缓冲区， 如果它被填满， 发送者将被阻塞，直到接收方将数据从缓冲区中取出（参阅书第8章 “网络拥塞与排队”) 。如果缓存在队列中，可能无法容纳，也许要将消息写入磁盘，这样或许会影响消息传递系统的性能。 如果节点崩溃或暂时离线，是否会有消息丢失？持久性可能需要写入磁盘或结合复制（WAL?)方案（参阅书第7章“复制与持久性”）。而这些都是需要成本的。如果有时能接受丢失消息，那么在同样的硬件上可能获得更高的吞吐量和更低的延迟。 批处理系统对失败的任务会自动重试，失败任务部分输出会自动丢弃；下面会讲到如何在流上下文提供类似的保证。 数据库 vs. 消息队列 数据库通常会保留数据直到被明确要求删除，而大多数消息代理在消息成功传递给消费者时就自动删除消息。这样的消息代理不适合长期的数据存储。 由于消息代理很快删除了消息，多数消息系统会假定当前工作集相当小，即队列很短。缓存不够用则会存到磁盘，吞吐量就会降低 消息代理不支持任意的查询，但是当数据发生变化时（即新消息可用时），它们会通知客户端。 多个消费者 AMQP/JMS风格的消息代理, 相关标准：STOMP, MQTT。举例：RabbitMQ。无日志，生产者和消费者直连，消费后就删除 负载均衡式 和 扇出fan-out式，前者每个消息有一个消费者消费即可，后者每个消息都传递给所有消费者。 前者可能会出问题：消费者（客户端）关闭超时，代理没有收到ack，就需要重新传递给另一个消费者，这样可能就不会按照生产者发送的顺序处理消息了。如果消息有因果关系就比较棘手。还要注意：消息可能完全处理，但是ack丢失，这时候可能要原子提交协议，譬如2PC。 分区日志append-only 基于日志的消息存储（Kafka，Amazon Kinesis， Twitter Distributed Log） 生产者通过将消息追加到日志的末尾来发送消息，消费者通过依次读取日志来接收消息。如果消费者读到日志的末尾，它就开始等待新消息被追加的通知。 生产者通过将消息追加到基于主题-分区的文件，消费者依次读取这些文件。尽管这些消息代理将所有消息写入磁盘，但通过多台机器的分区，支持百万条消息的吞吐量，并且通过复制消息实现了容错性。 Kafka 如何保证消息的消费顺序？详见链接 消费者顺序读取一个分区，需要一个偏移量 磁盘空间使用中需要回收，日志会被分为段，不断的归档或删除。mq很短时，很快。当写入磁盘时吞吐量会降低。 消费者跟不上生产者时，会写到mq里，积压很多会写到磁盘里，再不济就会丢弃过旧的信息（环形缓冲区)，但这些不会影响其它的消费者。 数据库与流大多数重要的应用程序都需要结合多种不同的技术来满足需求：例如，使用OLTP数据库来为用户请求提供服务， 使用缓存来加速常见请求， 使用全文索引处理搜索查询， 以及使用数据仓库用于分析。 如果数据库某个项更新，也需要在缓存、搜索索引和数据仓库中更新。这时就可以在数据更改时显式地写入每个系统，称之为双重写入。这时就会出现race condition（书中图11-4，客户端1 set X=A，客户端2 set X=B，都是先更新数据库再更新搜索索引，但是可能出现数据库与索引不一致的情况）。 这个问题书上是以版本向量作为解决方案，但是我个人对此表示怀疑，因为即使知道数据库上的happens-before关系，搜索索引也不知道，版本向量又有什么用呢？我觉得缓存本身就是查不到（目标没命中）就去回查数据库，那么就是以数据库为主的。所以可以数据库更新时就直接删了缓存，而不是写入缓存。到时候要新值的时候,缓存既然是空，就从数据库加载新值就行了。 变更数据捕获(CDC)当然，另一种可能性就是change data capture，也就是用数据库触发器来检测数据库变更，变更的数据日志（只追加）会被发到搜索索引和数仓里，类似的比如用PostgreSQL的预写日志，MySQL的binlog等。这样的操作因为是异步的，所以用户依然可能会在写到搜索和数仓前查到旧数据，也就是遇到复制滞后问题。 初始快照 日志通常需要被阶段，因为太耗空间了。因此有了快照。全文索引需要整个数据库的完整副本，所以仅仅应用最近更改的日志不够，需要从一致的快照开始应用。 日志压缩 正如书第3章“哈希索引”的日志结果存储引擎，存储引擎定期查找具有相同key的日志记录，丢弃所有的重复项，并且只保留每个key的最新的更新。这个压缩和合并的过程是在后台运行的。Apache Kafka支持此日志压缩功能。 流处理的目标场景 基于事件模型的查询（复杂事件处理） 计算窗口聚合（流分析） 保持派生数据系统处于最新状态（物化视图） 流join 流和流join 两个输入流都由活动事件组成，采用join操作来搜索在特定时间窗口内发生的相关事件。例如，匹配相同用户在30min内采取的两个动作。两个join可以是相同的流。 流和表join 一个事件输入流，另一个是数据库变更日志。join来输出一个包含更多信息的事件。 表和表join 两个都是数据库更新日志。对两个表之间的join的物化视图进行持续的更新。 容错 批处理中，恰好一次exactly once可以由重新启动任务并丢弃失败的副本输出实现。但由于流是无限的，几乎无法做到。 Apache Flink定期生成状态滚动检查点并写入持久化存储。 幂等（idempotent） 多次执行输出一样。kafka的offset避免了这个问题防止重复执行相同的更新。 流式处理与服务当前流行的应用程序开发风格是将功能分解为一组通过同步网络请求（REST,RPC)进行通信的服务。优点是松耦合，让不同的团队可以在不同服务上工作。将stream operator组合成数据流系统与微服务理念有许多相似的特征。但是通信机制是单向、异步的消息流而非同步的请求/响应交互。 数据流能具有更好的容错，也可以有更好的性能，比如买东西需要知道汇率，用微服务RPC的方法就要从远程数据库查汇率服务，用数据流方法就可以订阅汇率更新流，在当地数据库发生更改时记录当前的汇率，有购汇请求就只需查询本地数据库即可。也就是购汇请求和汇率更新事件有一个流与表的join。 结语 暑假花了一个月，终于把这本书大概看了一遍了，每一章看的时候都能和以前的课程或项目联系起来，也扩充了自己的知识面。正如作者最后所说，数据是把双刃剑，它能给生活带来便捷，也能危及人们的隐私。从学校课堂监视孩子表情来检测积极性，到外卖软件对骑手送餐的监管与时间的严格限制，再到Deepfake，再到各大视频流网站的推荐技术。大数据似乎像一个囚笼，把人的自由和隐私作为一种积累资本的工具。我不否认大数据带来的便捷，但是它绝不应当无视道德边界与人文关怀。]]></content>
      <tags>
        <tag>Distributed System</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DDIA 数据密集型应用笔记 (II)]]></title>
    <url>%2Fblog%2F2021%2F06%2F29%2FDDIA-%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%AC%94%E8%AE%B0-II%2F</url>
    <content type="text"><![CDATA[Design Data-intensive applications (II) – 分布式数据系统 上一部分针对单机存储系统技术，这一部分我们将讨论多台机器的存储与检索服务。 扩展性：读写压力大，负载分散到多台机器上 容错与高可用性：单机故障，多机提供冗余接管失效组件 延迟：应优先让用户就近的数据中心提供服务 如何处理更强的负载？ 垂直扩展（更强大机器）： 共享内存架构：热插拔组件（服务器不关闭机器情况下更换磁盘，内存模块，甚至CPU）；无法异地容错； 共享磁盘：数据存储在可共享访问的磁盘阵列上，服务器与磁盘之间往往提供高速网络连接。race condition或锁会限制。 水平扩展： 无共享shared-nothing架构（本章重点）：每个节点独立使用本地CPU，运行数据库软件的机器或虚拟机称为节点，节点之间的协调通信全部在传统网络且核心逻辑主要依靠软件实现。 复制和分区复制replication：在多个节点上保存相同数据的副本。 分区partitioning：将一个大的数据库拆分成多个较小的分区，不同分区分配给不同的节点（sharding）。 数据复制主节点与从节点 如何确保所有副本之间的数据是一致的？ 对于每一笔数据写入，所有副本都有随之更新。否者某些副本将出现不一致，最常见的解决方案是基于主节点的复制（主从复制）。在这种情况下，只有主副本处理写请求，写入本地存储，然后将数据更改为复制的日志或更改流发送给所有从副本，每个从副本获得更改日之后应用到本地，严格保持顺序。而对于读请求，主从副本都可以处理。 同步复制还是异步复制 同步是指执行一个请求前，讯问从节点的确认，得到确认后再执行，异步指不用等到确认就立即执行。前者好处在于主节点发生故障数据丢失，从节点就可以继续访问最新数据；缺点在于从节点会阻塞，没有throughput。所以有时设为半同步会比较好。 如何处理主从节点呈现不同时间点的数据？ 对主节点的数据副本产生一个consistent snapshot，将快照拷贝到新的从节点。从节点连接到主节点并请求快照点之后发生的数据更改日志。快照与复制日志的某个确定位置相关联，这个位置信息在PostgreSQL中称为”log sequence number”，MySQL称为”binlog coordinates”。获得日志后从节点处理主节点上的新的数据变化（追赶caught up)。 处理节点失效 从节点失效 - 追赶式恢复 主节点失效 - 节点切换（leader election，心跳确认失效，选主共识，重新配置reconfigure把主节点降级为从节点并认可新的主节点） 使用异步复制，且失效之前，新的主节点并未收到原主节点的所有数据，选举后，原主节点又重新上线并加入到集群，接下来的写操作会发生什么？ 新的主节点会收到冲突的写请求，那么就需要让这个把请求丢弃，如果数据库之外有其它系统依赖于数据库的内容，丢弃数据会特别危险。 脑裂（split brain）是什么？ 两个节点各认为是主节点，都会接收写请求。 如何设置合适的超时来检测主节点失效? 超时太短，突发的负载峰值会导致节点的响应时间变长甚至超时，严重拥塞。 复制滞后问题上面讲到了利用冗余容忍节点故障，复制还可以加强可扩展性（多节点处理更多请求），以及保证低延迟（将副本部署在地理上距离用户更近的地方）？ 如果用户从副本读数据，但副本还没有和主节点同步。这时就会引起复制滞后replication lag，而在现实生活中又可能对应下列三种问题。 读自己的写 read your own write写请求到主节点，主节点insert一条数据，复制SQL语句到从节点，但这条SQL尚未到达从节点，此时若从从节点查询结果，结果可能空。 因此我们需要写后读一致性，也称为读写一致性。 解决方法有： 社交网站上用户首页信息通常只能由所有者编辑，其他人无法编辑，所以总是从主节点读取字节的首页配置文件。如果用户访问可能会被修改的内容，从主节点读取；否则，在从节点读取。 监控从节点的复制滞后程度。避免从滞后时间过长的从节点读取。 单调读 monotonic reads写请求到主节点，主节点insert一条数据，复制SQL语句到A,B两个从节点，传到了A节点但没有传到B节点，用户先从A从节点查询结果有数据，而从B节点查询结果无数据。 因此我们需要单调读，这介于强一致性和最终一致性之间。它保证了用户绝对不会看到这种“回滚”现象。 解决方法：用户总是从同一副本执行读取，为此，需要基于用户ID的哈希选择副本，副本失效则要重新路由到另外一个副本。 前缀一致读 consistent prefix reads情景：对于观察者，A提出问题之前，B就就回答了A的问题。 这是分区partitioned（分片sharded）数据库的一个特殊问题。不同分区独立运行，因此不存在全局写入顺序，这就导致当用户从数据库中读时，可能会看到数据库的某部分旧值和另一部分新值。 A在一个分区，B在另一个分区，分区各有一个从节点，主节点A，B接发消息维持顺序，从节点逆序，观察者从从节点查看消息记录发现颠倒。 解决方法：只在主节点进行特定类型的读取？应用层代码复杂；支持事务？可用性代价过高。 多主节点复制主节点网络中断，主从复制就无效了。因此可以以一定的topology配置多个主节点。 适用场景 多数据中心 多数据中心（接近用户）。在每个数据中心都配置主节点。性能上，主从复制每个写请求都必须经由广域网传送到主节点所在的数据中心，而多主节点复制中，可以在本地数据中心快速响应，然后采取异步复制将变化同步到其他数据中心。对上层应用有效屏蔽了数据中心之间的网络延迟，使得终端用户所体验到的性能更好。此外，还可以容忍数据中心失效和网络问题。如MySQL的Tungsten Replicator，PostgreSQL的BDR和Oracle的GoldenGate。 问题：冲突解决？ 离线客户端操作 应用在网络断开后还要继续工作。比如手机，笔记本上的日历，需要随时查看或添加，在离线状态下进行任何更改会在下次设备上线时与服务器同步。例子：CouchDB 协作编辑 Google Docs。冲突可以将文档锁定，或单个按键或全程无锁。 处理写冲突 检测到冲突后，根据ID或时间戳大小先后选择一个写请求作为胜利者，将另外的丢弃（数据丢失）。 所有冲突保存下来，下一次读取时，提示用户或自动解决冲突（CouchDB）。 拓补结构多个主节点的拓补（环形MySQL，星形，all-to-all）。环形拓补中，中间节点需要转发数据变更，如果某个节点收到包含自身标识符的数据更改，表明请求已经被处理过。问题是单点故障。需要重新配置拓补结构排除故障。 all-to-all拓补中消息可以沿不同方向传播，没有单点故障。但是，可能会出现某些网络链路比其他更快的情况，产生意外的顺序。（因果序乱了，类似前缀一致读中）。 为此可以使用version vector向量来描述因果序。 无主节点复制Dynamo, Riak, Cassandra。取消主节点，任何副本都可以接收写请求。 向多个副本并行发送读请求，根据版本号确定哪个值更新。向多个副本并行发送写请求，三个副本有两个成功确认写操作，则成功。 read-repair: 当检测查询到三个中两个副本返回一个值，另一个返回一个旧值时，把新值写入旧的副本。 anti-entropy：后台进程不断查找副本之间的差异。同步到最新。 读写quorum多少个副本完成才可以认为写成功？ n个副本，w个节点确认，必须查询r个节点，则只需要w+r&gt;n，读取的节点一定包含最新值。一般来说n是奇数，w=r=(n+1)/2向上舍入。读多写少的情况下，w=n，r=1，写需要所有节点确认，查询只需查询1给节点也是ok的。 数据分区分区数据库早在20世纪80年代就有了，最近又被一些NoSQL和基于Hadoop的数据库重视起来。接下来会讨论如何根据数据索引分区，以及分区的再平衡，和如何路由请求到正确的分区并查询。 数据分区与复制分区（可扩展性）：面临海量数据，需要把数据切分成多段，那么每一段就是一个分区， 复制（冗余容错）：一个分区有一个主副本（写请求经过）和多个从副本，每个副本存在不同的节点上。 如果分区不均匀，那么某些分区节点会承担更多的数据量或查询负载，称之为倾斜skewed。因此我们有几种分区方法 基于关键字区间分区 类似字典，ABC顺序。分区边界由管理员手动确定。Bigtable、HBase、RethinkDB、2.4版本之前的MongoDB。 对于时间戳，可以很好的区间查询。但是可能某天写入过多（当天分区），负载过高，而其它分区空闲。为此，可以引入传感器名称，然后按时间分区。 基于关键字哈希值分区（一致性哈希算法) 哈希函数可以将字符串转换为定长随机分布的数值，减轻热点（相近的两个key也会存储在不同分区上），但是就丧失了区间查询。 组合索引 Cassandra的表可以声明为由多个列组成的复合主键。复合主键只有第一部分可用于哈希分区，其它列用作组合索引对Cassandra SSTable中的数据进行排序。因此它不支持在第一列上进行区间查询，但如果第一列指定好了固定值，可以对其他列进行高效的区间查询。 e.g. (user_id, update_timestamp)。不同user在不同分区，但消息时间戳顺序存在一个分区上。 负载倾斜与热点出现大量对相同关键字的写操作（点赞，关键字名人ID），哈希无效，因为两个相同的哈希值仍然相同。一个操作是key头尾各加一个随机数。 分区与二级索引上面讨论的是kv模型，根据关键字查，但是二级索引会更复杂，是关系数据库的必备特性。HBase不支持，但是Riak支持，也是ES等全文索引的根本。 基于文档分区的二级索引 假设二手车ID: 0~1000, 根据id两个分区，按颜色和厂商过滤，就需要并行对两个分区，生成color:black, color:silver等文档ID的list，软件合并（对所有分区执行查询，然后合并结果，scatter/gather）。 基于词条的二级索引 对所有数据进行全局索引，而不是每个分区维护自己的本地索引。读取更为高效，不需要并行scatter/gather，只需对包含词条的那个分区发出读请求。写入慢，负载，二级索引分区可能不同、在不同节点上，产生写放大。 读放大（Read Amplification）。LSM-Tree 的读操作需要从新到旧（从上到下）一层一层查找，直到找到想要的数据。这个过程可能需要不止一次 I/O。特别是区间查询的情况，影响很明显。RocksDB 和 LevelDB后台compaction减少读放大的同时，也会增加写放大的问题，也即观察到的写入数据多于上层程序写入的数据。 分区再平衡随着时间的推移，数据库需要增加节点（冗余容错，更多CPU处理负载，更多磁盘和内存存储），这样一来，请求需要从一个节点转移到另一个节点。这被称之为再平衡。目标是至少要满足：负载、读写请求数据存储更均匀分布，再平衡过程中，数据库可以继续正常提供读写服务，避免不必要的负载迁移，尽量减少网络和磁盘I/O。 动态再平衡的策略为什么不hash(key) 然后取模（mod节点数，以均匀分布所有节点到不同分区）呢？ 迁移数据操作过于频繁。假设hash(key) = 123456，如果节点数N增加，hash(key) mod N 不断变化，数据必须随节点数变化而不断迁移。 固定数量的分区 先事先设立20个分区（远大于节点个数），假设有4个节点，每个节点有5个分区，一旦集群中添加一个新节点，该节点在每个现有的节点上匀走几（这里是1）个分区，直到分区再次达到全局平衡。删除则相反操作。 这里不会改变key到分区的映射，只会调整分区与节点的对应关系。而且可以逐步完成，旧的分区仍然可以接收读写请求。 Riak、ES、Couchbase都支持这种动态平衡的方法。 数据集总规模不确定的情况下，分区数量怎样算适宜？很难达到一个取舍点。 动态分区 动态分区。分区数量可以自动适配数据总量。分区数据太大就分裂、太小就合并。MongoDB、HBase。每个分区总是分配给一个节点，每个节点可以承担多个分区。对于HBase，分区文件传输需要HDFS。 按节点比例分区 Cassandra。分区数与集群节点数成正比。 请求路由发生了分区再平衡，怎么找到关键字？需要连接哪个IP地址和哪个端口号？ 这属于服务发现问题（zookeeper），任何网络访问的系统都有这样的问题，尤其是当服务目标支持高可用时。 处理策略（3种）。 允许客户端链接任意的节点（例如，采用循环式的负载均衡器）。如果某节点恰好拥有所请求的分区，则直接处理该请求；否则，将请求转发到下一个合适的节点，接收答复，并将答复返回给客户端。 将所有客户端的请求都发送到一个路由层，由后者负责将请求转发到对应的分区节点上。 路由层本身不处理任何请求，它仅充一个分区感知的负载均衡器。 客户端感知分区和节点分配关系。此时，客户端可以直接连接到目标节点， 而不需要任何中介。 所有参与者都要达成共识（分区与节点的对应关系及其变化）。如ZooKeeper，每个节点向ZooKeeper注册自己，它维护了分区到节点的最终映射关系。其他参与者（路由层或分区感知的客户端）订阅此信息。一旦分区改变或者添加、删除节点，ZooKeeper就会通知路由层。 事务事务将应用程序多个读写操作捆绑在一起成为一个逻辑操作单元。而使用事务，也许会丧失一些可用性。为此我们必须考虑事务的作用以及如何使用它。 深入理解事务ACID原子性Atomicity，一致性Consistency，隔离性Isolation，持久性Durability描述了数据库的容错机制。 A：在出错时中止事务，并将部分完成的写入全部丢弃。不用担心数据库的部分失败，它总是保证要么全部成功，要么全部失败 C：数据库处于应用程序所期待的“预期状态” （账户贷款余额和借款保持平衡） I：并发执行的多个事务相互隔离，不能相互交叉。（不能有race condition） D：一旦，事务提交成功，即使硬件故障或数据库崩溃，事务写入的任何数据也不会消失。（硬盘或SSD，预写日志WAL） 脏读脏写、幻读、不可重复读解决方法：四种隔离级别read_uncommit，read_commit，read_repeatable，Serializable 参考 补充总结： read_commit 防止了脏读（读数据库时，只能看到成功提交的数据）；防止脏写（写数据库时，只会覆盖已经成功提交的数据）。 脏写用行级锁来防止，当事务想修改某个对象（例如行或文档）时，它必须首先获得该对象的锁；然后一直持有锁直到事务提交（或中止）。 不能用读锁因为一个写事务就会阻塞很多读的锁申请。因此，大多数据库会维护一个旧值和当前写事务要设置的新值两个版本。事务提交前，所有其他读操作都读旧值，事务提交后才会切换到读取新值。 read_repeatable 防止了重复读问题（A读，B写，B提交，A再读，不一致） MVCC多版本并发控制的一致性快照的可见性规则： 每笔事务开始，列出当时尚在进行中的事务，忽略这些事务完成的部分写入（尽管之后可能会被提交），即不可见 所有终止事务所做的修改全部不可见 较晚事务ID所做的任何修改不可见，不管这些事务是否完成了提交 此外，其他所有的写入都对应用查询可见 Mysql的可重复读级别并没有完全解决幻读，考虑A读，B写，B提交，A再更新，A再提交，可能会出现A对B写的内容进行修改；所以得用MVCC+next-key locks(gap lock间隙锁或record locks索引加锁），或者下面的serializable来完全解决，这个case需要用select * from table where ? for update;select for update来手动锁定查询结果。但如果A只是读请求，Mysql的read_repeatable级别是可以保证幻读不出现的。https://juejin.cn/post/6844903799534911496 serializable 防止了写倾斜（医生轮班例子，同一个会议室预订，声明同一个用户名）与幻读（在一个事务中的写入改变了另一个事务查询结果的现象（行增加或删除）， 称为幻读） 可串行化的三种技术：严格串行顺序执行Redis、两阶段加锁2PL（广泛运用）、乐观并发。 2PL（two-phase locking):如果事务A已经读取了某个对象， 此时事务B想要写入该对象， 那么B必须等到A提交或中止之才能继续。 以确保B不会在事务A执行的过程中间去修改对象。如果事务A已经修改了对象， 此时事务B想要读取该对象， 则B必须等到A提交或中止之后才能继续。 对于2PL, 不会出现读到旧值的情况。 谓词锁（查询条件加锁），效果不佳，使用索引区间（next-key locking)锁。数据库可以简单地将共享锁附加到索引条目，表明事务已搜索了数据。 2PL是一种悲观并发控制机制（如果有锁冲突，那么直接放弃，相当于多线程的互斥锁），SSI可串行化的快照隔离是一种乐观并发机制（发生锁冲突，事务继续执行，当提交时，检查是否发生了冲突）。 分布式系统的挑战故障与部分失效partial failure当通过网络发送数据包时， 数据包可能会丢失或者延迟；同样， 回复也可能会丢失或延迟。 所以如果没有收到回复， 并不能确定消息是否发送成功。 对于HPC这种计算密集型的任务来说（天气预报或分子动力学），会定期对任务状态进行快照，保存在持久存储上，总是整体开停集群的任务。并且，节点间主要通过share memory或RDMA（远程内存直接访问）进行通信。 而对于基于互联网的服务系统（云计算），则必须考虑可用性，在线，低延迟。特征有多租户数据中心，通用计算机，IP以太网链接，弹性资源分配，按需计费。停下集群修复故障是不可取的。设备是通用机器，单节点成本低廉，也有较高故障率。 检测故障如果故障有响应，比如发现服务进程没有侦听目标端口，操作系统会返回RST或FIN数据包辅助关闭或拒绝TCP连接，再比如路由器判断目标节点不可访问就会返回ICMP“目标不可达”数据包。但是想要知道具体请求是否执行成功，还是需要应用级别的回复。如果故障没有响应，一般使用超时判断故障。超时的选择一般是2d+r时间（d是传输时间，r是请求处理时间）。 但是一个问题是网络拥塞与排队。TCP实行流量控制，节点会主动限制自己的发送速率以避免网络链路或接受节点负载。这意味数据在进入网络之前，已经在发送方开始了排队。TCP还实现了超时重传，超时时间由响应时间分布自动调整。这些都会导致网络延迟变化。 拨打电话时，系统会动态建立一条电路，为整个线路上分配一个固定的带宽有保障的通信链路，电路一直维持到通话结束。这本质是同步的。然而，TCP连接会尝试使用所有可用的网络带宽。TCP可以传输任意大小可变的数据块，这样的代价是只能使用分组交换，对突发流量进行很多优化。如果通过电路链接来传输文件，将预估一个带宽，就不能传输任意大小可变的数据块了。有些网络比如ATM（Asynchronous Transfer Mode，与自动提款机无关）, InfiniBand尝试混合电路交换和分组交换，使用QoS（数据包优先级和调度）和准入控制（限制发送速率），在link layer实现端到端的流量控制以减少网络中的排队。但此类QoS在多租户数据中心，公有云和广域网中并未启用。 时钟不同步使用NTP（Network Time Protocol）同步不同机器的时钟。 石英钟漂移 本地时钟被强制重置后，突然倒退或跳跃 NTP失效，同步失败 NTP受延迟影响 闰秒 冲突解决策略：LWW。Cassandra，Riak使用，最后写入获胜。 另一个问题：Lease（租约）based leader election 主节点获得租约，成为leader，这时候进程暂停（垃圾回收）被宣告为失效，recovery后对它暂停毫无所知，导致不知道新leader的存在。 为解决它，可以使用Fencing令牌，这主要是针对使用锁和租约机制来保护资源的并发访问。必须确保过期的唯一节点不能影响其他正常部分。在授予lease时，同时授予fencing令牌，每授予一次就会递增，当客户端每次向存储系统发送写请求时，都必须包含fencing令牌。比如节点A得到了lease成为leader并得到了fencing号 33，然后进程暂停很长时间，此时节点B已经得到lease成为新leader并得到fencing号 34，当节点A恢复再准备写时，就会被拒绝。 这在zookeeper中，可用事务表示zxid或节点版本cversion充当令牌，因为它们都是单调递增的。 fencing可检测无意的误操作，但是万一有节点试图破坏系统，可以伪造令牌，这样就是拜占庭故障。 一些理论术语： 系统模型synchronous, partially synchronous, asynchronous 节点失效模型crash-stop, crash recovery, byzantine crash 算法的正确性uniqueness, monotonic sequence, availability 安全与活性safety(false if有限时间内可以被违背，e.g. uniqueness, monotonic sequence), liveness（true if无限时间内可以eventually达成, availability） 一致性与共识第5章“复制滞后问题”中，多节点复制的先后导致了同时查询可能出现不一致的数据，这一点是无法避免的。因此退而求其次，引入了最终一致性。但这是很弱的保证，没有告诉我们什么时候能收敛于一致，当更新完立即读取，由于读取可能路由到不同副本，不保证一定能读到刚刚写入的值。 可线性化Linearizability又称强一致性，原子一致性，所有客户都有相同的数据视图。直觉的例子参见书上的例子。用一句话概括，不同客户端的所有操作（读，写，cas）的确切执行时刻（在invocation和response之间的某个时刻）都能在一个global的时间轴上表示出来。一旦某个读操作返回了新值，之后所有的读（包括柜同或不同的客户端）都必须返回新值。 可线性化Linearizable vs. 可串行化Serializable可线性化是读写寄存器（单个对象）的最新值保证。 它并不要求将操作组合到事务中，因此无法避免写倾斜等问题，除非采取其他额外措施；可串行化是事务的隔离属性，其中每个事务可以读写多个对象（行，文档，记录等，它用来确保事务执行的结果与串行执行（即每次执行一个事务）的结果完全相同，即使串行执行的顺序可能与事务实际执行顺序不同。数据库可以同时支持这两者，但是可串行化的快照隔离必然不是线性化的，因为快照意味着不包含快照创建之后的写入数据。 什么情况下需要线性化？ 账户余额，库存，座位，都需要所有节点对某个最新值达成一致。 实现线性化系统 主从复制（部分可线性化）主节点写入，从节点备份。如果某节点错误自认主节点，就会违法线性化。这通常用共识算法保证防止脑裂和过期的副本（zookeeper, etcd)，就可以线性化了。 多主复制（不可线性化）在多节点上执行并发写入，发生写冲突后进行处理（根据ID时间戳选择一个写请求作为胜利者，丢弃另外的） 无主复制（部分可线性化）Dynamo风格，写入满足w+r&gt;n，可能满足。Cassandra的LWW和不规范的quorum不能。Dynamo可以牺牲性能，使用read-impose（读修复，读后写，并行检测到某副本有过期的副本，就将新值写入此副本）和write-consult（读取quorum节点获取最新值）来满足线性化。 CAP网络分区情况下，选择一致性（线性化）还是可用性。 权衡选择系统，钱财安全CP, 用户可用AP。 现代CPU上的内存甚至都是非线性化，除非使用内存屏障或fence指令。为了性能，每个CPU核都有自己独立的cache和寄存器，先访问cache，再异步刷新到主存。 不支持线性化，是为了性能。想要满足线性化，读写请求的响应时间至少要与网络中延迟成正比。master挂掉时，zookeeper选举时间30~120s，且选主时间中集群不可用。如果只是向注册中心查询服务列表，这样的时间是无法接受的。Eureka这种AP系统就更好。 顺序保证 什么情况下需要顺序与因果关系？ 第5章，consistent prefix read一致前缀读，观察者先看到问题答案然后才是本身。 全链接拓补（多主节点），图5-9，应当先在一个主节点插入，再在另一个主节点上更新，但是更新操作在后一个主节点比前一个更早执行。 第5章检测并发写，A, B之间存在依赖关系 在事务的快照隔离上下文中，需要“一致性”，如果快照中包含了答案，那么他也必须包含所提的问题。（一致性的快照如何正确切分） 写倾斜与幻读。两方调班，需要有一个因果关系。A申请调班成功需要依赖于B仍在值班。利用可序列化的快照隔离（乐观并发）来跟踪事务之间的因果依赖关系来达到检测写倾斜的目的。 两个通道调整图片大小的例子，一个上传，一个修改，修改了缩略图导致原图被覆盖。 total order全序，可线性化：总是能指出哪个先哪个后，而causal order因果序，如果存在happen before（依赖或同进程中的先后），就是并发关系。全序一定是因果序，反之未必。 Lamport 时间戳可以保证全序与因果关系一致，计数器较大的那个时间戳大，如果计数器正好相同，节点ID越大，时间戳越大。Lamport clock和Vector clock不同，后者可以区分两个操作属于并发还是因果依赖关系，但前者不能，它的优点是紧凑高效。 虽然面临并发请求（比如注册同一个用户名），可以使用lamport clock决定获胜者（先来者申请成功），然而时间戳排序依然不够，因为不知道别的节点是否也在同时创建相同用户名。这个时候就需要全序关系广播。 全序关系广播total order broadcasting/atomic broadcasting必须满足 可靠发送：没有消息丢失， 如果消息发送到了某一个节点， 则它一定要发送到所有节点。 严格有序：消息总是以相同的顺序发送给每个节点。 分布式事务与共识 主节点选举（网络故障，脑裂） 原子事务提交（回滚） 2PCtwp phase commit 是一种在多节点之间实现原子事务提交的算法，用来保证所有节点要么全部提交，要么全部中止。2PC在数据库中使用，或以XA事务（Java Transaction API）或SOAP Web服务WS-AtomicTransaction的形式提供给应用程序。 当应用程序启动一个分布式事务时，它首先向协调者请求事务ID。该ID全局唯一。 prepare阶段，coordinator向所有participant讯问是否写入数据，如果有一票否决就作罢。 commit阶段，coordinator收到所有准备请求的答复，把决定写入到磁盘的事务日志中，防止之后系统崩溃，这个时刻称为提交点。向所有participant发送提交请求。如果请求失败，coordinator就必须一直重复，直到成功。participant收到也不能反悔。 问题是，万一coordinator出现故障怎么办？在commit阶段，participant收不到消息，但他也不知道是别的participant否决了还是coordinator故障导致自己收不到消息。 因此2PC能够顺利完成的唯一方法需要等待协调者恢复。 问题可以由3PC解决，因为在do commit 第三阶段，participant即使收不到消息，由于它在第二阶段收到了消息，所以他知道别的coordinator在第一阶段都同意提交了，所以只可能是coordinator挂了，所以过一段timeout它会自行提交。然而大部分系统还是使用2PC为主。 Zab，Paxos，RaftRaft Zookeeper很多项目间接依赖于Zookeeper，例如HBase，Hadoop YARN, kafka，是因为它提供了全序广播，达到了多副本之间的一致性。具有以下特性： 线性化的原子操作（共识）：多个节点同时尝试相同操作，确保只有一个会成功。分布式锁（租约，可以释放） 全序操作：fencing令牌，解决进程暂停情况引起的冲突 故障检测（心跳） 更改通知（订阅通知机制，客户端可以读取其他客户端所创建的锁和键值） Zookeeper还用于服务发现，例如需要某项服务应该连接到哪个IP地址。在典型的云环境中，虚拟机可能会起起停停，这种动态变化的节点无法提前知道服务节点的IP地址，因此，可以这样配置服务，每当节点启动时将其网络端口信息向ZooKeeper等服务注册，然后其他人只需向ZooKeeper的注册表中询问即可。]]></content>
      <tags>
        <tag>Distributed System</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DDIA 数据密集型应用笔记 (I)]]></title>
    <url>%2Fblog%2F2021%2F06%2F02%2FDDIA%20%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Design Data-intensive applications (I) – 数据系统基础 可靠，可扩展，可维护的应用系统一个常见的应用系统应包括以下模块：数据库、高速索引（memcache，redis）、索引（ES)、流式处理（异步）、批处理（定期处理大量累计数据）。 API客户端请求进来，应首先检测数据缓存(redis)是否命中，命中就从内存读请求，否则更新数据库-&gt;数据库应数据变化更新缓存。同时更新数据库-&gt;更新索引，应用代码就可以进行全文索引(ES)查询。另外，对于异步任务可以交予消息队列(kafka)慢慢处理。 对于大多应用系统应考虑三个问题：可靠性(Reliability),可扩展性(Scalability),可维护性(Maintainability)。 可靠性： 硬件故障硬件冗余：磁盘RAID, 服务器双电源，热插拔CPU 软件错误特定值（闰秒）导致应用程序挂起，级联故障 人为失误抽象层，API以及管理界面。测试边界条件（property based testing)，自动化测试。滚动发布新代码，快速恢复机制。监控性能指标和错误率。 可扩展性 twitter案例：问题：当一个人tweet后，当follower查看自己的timeline时，需要联表查询，效率很低：1234SELECT tweets.*, users.* FROM tweets JOIN users ON tweets.sender_id = users.id JOIN follows ON follows.followee_id =users.id WHERE follows.follower_id = current_user 可以改进的一点是当一个人tweet时就fan-out到所有follower的timeline。虽然牺牲了这个人发布tweet的时间，但是所有follower查看timeline的速度都提升了。 当然如果这个人有很多的follower，就会导致发布时间太长，也不行，所以要混着用。 另外在批处理系统Hadoop中，throughput吞吐量（每秒可处理的记录条数，或者在某指定数据集上运行作业所需的总时间）很重要，而在线系统更关注响应时间。响应时间使用平均值并不好，因为可能出现极端值（上下文切换、进程调度、网络丢包、TCP重传、垃圾回收暂停、缺页中断、磁盘I/O），所以可以使用百分数（percentiles)，中位数。amazon使用99.9百分位数作为响应时间的标准，即1000个请求中有一个无需到达最小响应时间。 如何应对负载增加？垂直扩展vertical scaling（机器升级），水平扩展（负载分布到多个小机器）。有些系统具有弹性，可以自动检测负载增加然后分配更多计算资源。水平扩展会大大提升复杂性。 可维护性监控、自动化、标准工具集成（jenkins,Teamcity,K8s,JIRA,GitHub Action) 敏捷开发，TDD， 重构 数据模型与查询语言三种数据模型：关系模型、文档模型、图模型。 关系模型最知名的数据模型SQL，基于1970年提出的关系模型。数据被组织成关系，在SQL中称为表(table)，其中每个关系都是元组（tuples）的无序集合（SQL中的行）。 第一范式（1NF）强调的是列的原子性，表示列不能够分成其它几列。举例：联系人建表，电话要分成家庭电话和个人电话。第二范式（2NF），表必须有一个主键；二是没有包含在主键中的列必须完全依赖于主键，而不能只依赖于主键的一部分，不符合 2NF 的设计容易产生冗余数据。举例【OrderDetail】（OrderID，ProductID，UnitPrice，Discount，Quantity，ProductName）= 【OrderDetail】（OrderID，ProductID，Discount，Quantity）+ 【Product】（ProductID，UnitPrice，ProductName）。第三范式（3NF），任何非主属性不依赖于其它非主属性。【Order】（OrderID，OrderDate，CustomerID，CustomerName，CustomerAddr，CustomerCity）主键是（OrderID），符合第二范式，但Custom也依赖于CustomID。应拆分出来参考：https://blog.csdn.net/Dream_angel_Z/article/details/45175621 关系数据库的核心在于商业数据处理，用例分为事务处理（银行交易，订票，仓库库存）和批处理（客户发票，工资单，报告）。 NoSQL超大数据集或超高写入吞吐量，关系模型不能很好地支持一些特定的查询操作。开源。 ORM对象关系映射框架有ActiveRecord和Hibernate，降低了应用层对象与传统关系模型之间转换的难度。面向文档数据库MongoDB, RethinkDB, CouchDB, Espresso。MongoDB数据库通过JSON模型将树形结构显示化。 MapReduce 查询MapReduce是一种编程模型,用于在许多机器上批最处理海量数据。一些 NoSQL 存储系统（例如MongoDB和CouchDB) 支持有限的MapReduce方式在大量文档上执行只读查询。举例： 在PostgreSQL中，统计每个月看到了多少鲨鱼，可以这样查询:12345SELECT date_trunc('month', observation_timestamp) AS observation_month, sum(num_animals) AS total_animals FROM observations WHERE family='Sharks' GROUP BY observation_month; 而在MongoDB中MapReduce功能可以这样实现目的：1234567891011121314db.observations.mapReduce( function map() &#123; var year = this.observationTimestamp.getFullYear(); var month = this.observationTimestamp.getMonth() + 1; emit(year + "-" + month, this.numAnimals); &#125;, function reduce(key, values)&#123; return Array.sum(values); &#125; &#123; query: &#123;family: "Sharks"&#125;, out: "monthlySharkReport" &#125;); 一个文档：123456&#123; observationTimestamp: Data.parse(&quot;Mon, 25 Dec 2020 12:11:11 GMT&quot;), family: &quot;Sharks&quot;, species: &quot;xxx&quot;, numAnimals: 3&#125; 对于每个匹配查询的文档，都会调用一次js的map函数，设为文档对象。 map函数emit一个kv对，key如”2021-06”，value代表观察的动物数量 对于相同的key，利用reduce按key分组，reduce将特定月份所有观察到的动物数量相加 写入monthlySharkReport集合中 map和reduce 函数对于可执行的操作有所限制。 它们必须是纯函数， 这意味着只能使用传递进去的数据作为输入， 而不能执行额外的数据库查询， 也不能有任何副作用。这样使得数据库能在任何位置，以任何顺序来运行函数，并在失败时重新运行这些函数。 MongoDB 2.2 增加了聚合管道查询 12345678910db.observations.aggregate([ &#123; $match: &#123;family: &quot;Sharks&quot;&#125;&#125;, &#123; $group: &#123; _id: &#123; year: &#123; $year: &quot;$observationTimestamp&quot; &#125;, month: &#123; $month: &quot;$observationTimestamp&quot; &#125; &#125;, totalAnimals: &#123; $sum: &quot;$numAnimals&quot; &#125; &#125;&#125;]); 图状数据模型属性图 每个顶点包括 唯一的标识符 出边的集合 入边的集合 属性的集合（键值对） 每个边包括 唯一的标识符 边开始的顶点 边结束的顶点 描述两个顶点间关系的label 属性的集合（键值对） 123456789101112131415CREATE TABLE vertices ( vertex_id integer PRIMARY KEY, properties json);CREATE TABLE edges ( edge_id integer PRIMARY KEY, tail_vertex integer REFERENCES vertices (vertex_id), head_vertex integer REFERENCES vertices (vertex_id), label text, properties json);CREATE INDEX edges_tails ON edges (tail_vertex);CREATE INDEX edges_heads ON edges (head_vertex); 123&lt;字段名A&gt; REFERENCES &lt;表名T&gt; &lt;字段名B&gt; -- 表示字段A存在，T表中必须存在相同的值字段BCREATE INDEX &lt;索引名&gt; ON edges (tail_vertex); -- 建立索引 数据存储与检索总体来说存储引擎分为两大类，OLTP（针对事务处理）的架构和OLAP（针对分析型）。OLTP系统面向最终用户，可能收到大量请求。为了处理负载，应用程序在每个查询中只涉及少量记录。应用程序基于某种键来请求记录，而存储引擎使用索引来查找所请求键的数据，磁盘寻道时间是瓶颈。OLAP又业务分析师使用，处理的查询请求数目远低于OLTP系统，但每条查询需要在短时间扫描数百万记录。磁盘带宽（而不是寻道时间）是瓶颈，面向列的存储对于这种工作负载比较流行。 磁盘寻道时间：是指将读写磁头移动至正确的磁道上所需要的时间。寻道时间越短，I/O操作越快，目前磁盘的平均寻道时间一般在3-15ms。来源 磁盘带宽：正相关影响吞吐量（单位时间可以成功传输的数据数量）。 OLTP方面，有两个主要流派的存储引擎家族：日志结构的存储引擎（BitCask, SSTables, LSM-tree, LevelDB, Cassandra, HBase, Lucene）和面向页的存储引擎(B Tree，用于MongoDB, B+树用于MySQL)。 数据结构一个简易的database，实现了get和set： 12345678#!/bin/bashdb_set()&#123; echo "$1, $2" &gt;&gt; database&#125;db_get()&#123; grep "^$1," database | sed -e "s/^$1,//" | tail -n 1 &#125; 缺点：日志文件存储Key-Value存储对需要从头到尾扫描整个数据库文件来查找键的出现位置。 因此，加速读查询，索引是必要的。但是并不是索引越多越好，因为每个索引都会减慢写速度。 哈希索引 哈希索引基于哈希表。哈希表是一种查找算法，希望能尽量做到不经过任何比较，通过一次存取就能得到所查找的数据元素。因而必须要有一个确定的映射：数据的关键字key&lt;=&gt;数据元素位置。这种映射关系称为散列函数h(key)。最普通的散列函数：除留余数法h(key) = key MOD p, p&lt;=m。哈希冲突（不同key经由哈希函数生成的值相同）通常用拉链法解决。 为何不直接用哈希表来直接索引数据？哈希表存储了映射：键&lt;=&gt;数据文件的字节偏移量。查找某个key时，使用hash map找到文件中的偏移量，即存储位置，再读取其value。这就是Bitcask的做法。 Bitcask适合键的值频繁更新的场景。例如key是某个视频的url，value是播放的次数。有很多写操作，但没有很多key，也就是需要所有key都能保存在内存中。注意，这里key-value是追加式（日志的机制），那么怎样才能避免用尽磁盘空间呢？就是把具有相同key的记录压缩，只保留每个键最近的更新。这种实现方式是将日志分解成一定大小的段，当文件达到一定大小就关闭它并后续写入到新的段文件中。多个段也可以合并压缩，合并过程中，写请求还是在旧段上，但是合并后，写请求切换到新的合并后的段。每个段都有自己的内存哈希表，为了找到键的值，从最新的段开始依次检查。 追加式的日志看起来浪费空间，为什么不原地更新？ 追加和分段合并是“顺序写”，比随机写入快很多。 不必担心重写时发生崩溃。 避免碎片化问题 坏处：哈希表必须全部放入内存，有大量键就gg，（注意value很占空间没有问题，因为哈希表只是key&lt;=&gt;存储位置）。很难在磁盘上维护哈希表。区间查询效率不高，只能逐个查找每个键。 SSTables和LSM-TreeSSTable（Sorted String Table)在每个存储段都是一组key-value序列的日志结构的基础上，要求kv对的顺序按键排序。利用B树可以在磁盘上维护排序结构，而利用红黑树或AVL树可以在内存中排序。 SSTable优点： 合并段可以并发读取多个输入段文件，比较每个文件第一个键，把最小的键拷贝到输出文件，重复这个过程。如果重复键出现在多个输入段，保留最新段的值，丢弃旧段的值。 查找特定键时，不再需要在内存中保存所有键的索引。比如查找handwork，知道handbag和handsome就知道要找的offset在中间。 读写规则： 写入时，添加到内存中的平衡树数据结构中，这个内存中的树被称为内存表（memtable） 内存表大于某个threshold（通常几MB)时，将其作为SSTable写入磁盘。由于树已经维护了按键排序的kv，写磁盘比较高效。 处理读请求，先内存表，再最新磁盘段，再次新磁盘段。 后台周期性合并压缩 问题：数据库崩溃，内存表丢失。解决：磁盘上保留日志，每个写入追加到日志，可以乱序，崩溃后恢复内存表。当内存表写入SSTable写入磁盘，相应日志可以丢弃。 从SSTable到LSM-Tree以上算法是LevelDB和RocksDB使用的。类似还被用于Cassandra和HBase，这两个引擎都收到Google Bigtable论文的启发（SSTable和内存表memtable）。 Log-Structured Merge-Tree。基千合并和压缩排序文件原理的存储引擎通常都被称为LSM存储引擎。 Lucene是Elasticsearch和Solr等全文搜索系统使用的索引引擎。键是单词，值是保护该单词的文档ID的列表（倒排表）。在Lucene中这个映射保存在类SSTable的排序文件中，这些文件可以根据需要在后台合并。 优化：查找不存在的键，先SSTable，再最新磁盘段，再次新磁盘段……使用布隆过滤器（不存在某个键，很快告诉你结果）。大小分级（HBase）和分层压缩（levelDB），Cassandra支持这两种压缩。前者让较小较新的SSTables连续合并到旧和较大的SSTables。后者让键的范围分裂成多个更小的SSTables，旧数据被移到单独的“层级”，这样压缩可以逐步进行并节省磁盘空间。 LSM-tree的基本思想是保存在后台合并的一系列SSTable。数据按排序存储，可区间查询，不用存全部索引，磁盘顺序写入，高吞吐量。 B-TreesB-tree将数据库分解成固定大小的块或页,传统上大小为4 KB。页是内部读／写的最小单元。 这种设计更接近底层硬件， 因为磁盘也是以固定大小的块排列。某一页被指定为B-tree的根；每当查找索引中的一个键时，总是从这里开始。。 该页面包含若干个键和对子页的引用。每个孩子都负责一个连续范围内的键， 相邻引用之间的键可以指示这些范围之间的边界。 一个页面引用另一个页面，引用指向磁盘地址而非内存。 B-tree中一个页所包含的子页引用数觉称为分支因子（branching factor)。 注意插入后可能的分裂过程，子页满了，分裂成两个half-full的页，父页也需要更新以包含分裂之后的新的键范围。该算法确保树保持平衡，具有n个键的B-tree总是具有O(logn)的深度。不需要非常深的页面层次就可以找到所需的页。分支因子为500的4KB页的四级树可以存储高达256 TB。计算：1500^4 * 4 * 1024 / (1e12) = 256 B树可靠性B-Tree的写是覆盖磁盘上的旧页，这与日志结构索引（LSM-Tree）不同，因为后者只追加不修改。B树的覆盖不会改变页的磁盘存储位置。被覆盖时引用的引用不变。 分裂时，需要更新对两个新子页的引用，如果部分页写入后发生崩溃，最终会导致索引破坏，为了恢复，常见B-Tree的实现需要支持磁盘上额外的数据结构：预写日志（write-ahead log, WAL)。这是仅支持追加的，每个B-tree的修改必须先更新WAL然后再修改树本身的页。 B树并发控制：latches锁存器（轻量级的锁）。LSM更简单，因为它们在后台执行所有合并，而不会干扰前端的查询，并且会不时地用新段原子地替换旧段。 对比B树和LSM树LSM树： 写入更快，因为有较低的write-amplification写放大（在数据库内，由于一次数据库写入请求导致的多次磁盘写），部分缘由顺序方式写入紧凑的SSTable文件，而不必重写树中的多个页。（顺序写&gt;随机写） 读取慢，因为必须不同压缩阶段检测多个不同的数据结构和SSTable B树： 读取更快 每个键都恰好唯一对应索引的某个位置，LSM可能在不同段中有相同键的多个副本 其它索引结构二级索引使用CREATE INDEX命令。以便可以在每个表中找到属于同一个索引的所有行。 聚集索引：直接存储索引行，无额外跳转，MySQL的InnoDB的表的主键是聚集索引。非聚集索引：value可以是对其它地方存储的行的引用（具体位置称为堆文件），在有多个二级索引时，可以避免复制数据，实际数据仍保存在一个位置。 前者需要额外空间，加快了读取速度，后者反之。 事务处理与分析处理OLTP (online transaction processing) 在线事务处理。 OLAP (online analytic processing) 在线分析处理。 公司放弃使用OLTP系统用于分析目的，而是在单独的数据库上运行分析，这个单独的数据库被称为数据仓库（Data Warehousing）。 可以理解为，对于终端用户操作交互的是OLTP系统的数据库（电商网站-&gt;销售数据库，车辆路径规划-&gt;地理数据库）；而OLAP系统将这些数据库中的信息提取出来，进行数据转换和加载（Extract-Transform-Load，ETL）到数据仓库中，由商业分析员进行查询。 列式存储分析人们购买新鲜水果或糖果的倾向是否取决于一周中的某天1234567891011SELECT dim_date.weekday, dim_product.category, SUM(fact_sales.quantity) AS quantity_soldFROM fact_sales JOIN dim_date ON fact_sales.date_key = dim_date.date_key JOIN dim_product ON fact_sales.product_sk = dim_product.product_skWHERE dim_date.year = 2013 AND dim_product.category IN ('Fresh fruit', 'Candy')GROUP BY dim_date.weekdat, dim_product.category 想要高效执行这个查询，可以在fact_sales.date_key和fact_sales.product_sk上使用索引，告诉哪里找特定产品的所有销售。但这依然会从磁盘加载所有行（一行所有的一百多个属性）到内存，解析，再过滤不符合所需条件的行。在大多数OLTP数据库中，存储以面向行的方式布局，来自表的一行所有值彼此相邻存储。文档数据库的文档也被存储为一个连续的字节序列。 面向列存储，就不需要将一行中的所有值存储在一起，而是将每列的索引值存储在一起。只加载相关列的所有行，再过滤不符合所需条件的行，就快很多。 面向列的存储布局依赖一组列文件，每个文件以相同顺序保存着数据行。 因此，如果需要重新组装整行，可以从每个单独的列文件中获取第23个条目，并将它们放在一起构成表的第23行。 列压缩 常见技术：bitmap encoding位图压缩，位图可以进行run-length encoding游程编码。具体见书上的例子。 12345WHERE product_sk IN (30, 68, 69);加载3个bitmaps，然后按位或。WHERE product_sk = 31 AND store_sk = 3:加载两个bitmaps然后按位与。（思考为什么这个也行） 列存储的排序 排序可以区间查询，也可以进一步压缩列，压缩游程（run-length encoding）。 列存储的写操作 插入一行后，如果想要像B树一样原地更新不太可能，因为必须重写所有列文件，一致地更新所有列。因此要使用LSM-tree，首先进入内存存储区，再添加到已排序的结构中，再写入磁盘。这个过程与面向行还是面向列无关。当累积了足够多的写入时，将与磁盘上的列文件合并，并批量写入新文件。这是Vertica采取的方式。 数据编码与演化代码更迭对于服务端应用程序，需要执行滚动升级rolling update（分阶段发布staged rollout)，即对少数几个节点部署新版本，检查是否正常，然后逐步在所有节点上升级新的代码。无需暂停。对于客户端应用程序，只能寄望于用户，然而他们在一段时间内可能不会马上安装更新。这意味着新旧版本的代码和数据格式可能会在系统共存。因此需要双向的兼容性。 向后兼容Backward compatibility：较新代码可以读取由旧代码编写的数据。 向前兼容：较旧代码可以读取由新代码编写的数据。 数据编码格式内存中：数据保存在对象，结构体，列表，哈希表和树中；这些数据结构对CPU高效访问与操作进行了优化。（指针） 数据写入文件或用网络发送时，必须编码为某种自包含的字节序列（JSON）。相反的过程为解码。 Java java.io.Serializable, python pickle类似的可以完成编码解码，但是问题是编码往往与特定的编程语言绑定在一起，并且解码过程中需要实例化任意类，会导致安全问题。攻击者可能会远程执行任意代码。 JSON: JS的一个子集，在Web中内置支持 XML CSV： 语言无关的格式，功能较弱 Apache Thrift和Protocol Buffers12345&#123; "userName": "Martin", "favoriteNumber": 1337, "interests": ["daydreaming", "hacking"]&#125; Thrify用IDL接口定义语言来描述模式12345struct Person&#123; 1: required string userName, 2: optional i64 favoriteNumber, 3: optional list&lt;string&gt; interests&#125; Protocol Buffers等价模式(.proto文件) 12345message Person&#123; required string user_name = 1; optional int64 favorite_number = 2; repeated string interests = 3;&#125; 上面两者都有对应的代码生成工具，生成支持多种编程语言的类参考链接。 如何用此二者实现向前兼容和向后兼容？ 添加新的字段到模式，给每个字段一个新的标记号码，当旧代码试着读取新代码写入的数据，包括一个不能识别的标记号码（新字段），就忽略。这样可以实现向前兼容 新代码总是可以读取旧的数据，如果添加新字段，无法使其成为必需字段，因为旧代码不会写入添加新字段，因此新字段需可选或有默认值 改变数据类型？int64 -&gt; int32 截断int32 -&gt; int64 补0 Avro适合Hadoop，有两种模式语言（Avro IDL）和基于JSON的语言。 以上三种的模式语言比XML和JSON简单，支持更详细的验证规则。 数据流模式发送一些数据到非共享内存的另一个进程时，都需要编码为字节序列，方式有： 通过数据库 通过服务调用 通过异步消息传递 基于服务的数据流：REST和RPCWeb：客户端（Web浏览器）向Web服务器发出请求，发出GET请求来下载HTML, CSS, JS, 图像等，发出POST请求提交数据到服务器。API包含一组标准的协议和数据格式（HTTP,URL,SSL/TLS,HTML)。 在Web浏览器内运行的Javascript应用程序也可以向服务器发出网络请求，并且可以使用XMLHttpRequest成为HTTP客户端（Ajax）。这种情况下的服务器响应通常不是HTML而是便于客户端应用程序进一步处理的编码数据JSON。 服务器本身可以是另一项服务的客户端（Web应用服务器作为数据库的客户端）。这种方法用于将大型数据库按照功能区域分解为较小的服务，这样当一个服务需要另一个服务的某些功能或数据时，就会向另一个服务发出请求。这种构建应用程序的方式被称为微服务体系架构。 面向服务/微服务的关键在于，通过使服务可以独立部署和演化，让应用程序更易于更改和维护。每个服务由一个团队拥有。换句话说，应当期望新旧版本的服务器和客户端同时运行，因此服务器和客户端的数据编码必须在不同版本的服务API之间兼容。 网络服务REST是一个基于HTTP的设计理念，强调简单的数据格式，使用URL来标识资源，使用HTTP功能进行缓存控制、身份验证和内容类型协商。根据REST原则设计的API称为RESTful。Swagger可以用来描述RESTful API并生成文档。 SOAP是一种基于XML的协议，用于发出网络API请求。独立于HTTP。SOAP Web服务的API称为WSDL（web services description language，一种基于XML的语言）来描述。 RPC虽然强调让远程过程调用和调用本地方法一样，但是并没有那么简单。需要考虑远程与本地调用的差异：网络延迟，大数据的指针，语言转换。 异步消息传递使用消息代理（RabbitMQ,Kafka）或Actor（Akka，Orleans，Erlang OTP），节点之间通过互相发送消息进行通信，消息由发送者编码并由接收者解码。 与直接RPC相比，使用消息代理有以下几个优点： 接收方不可用或过载，它可以充当缓冲区，提高系统可靠性。 可以自动将消息重新发送到崩溃的进程，防止丢失。 避免了发送方需要知道接收方的IP地址和端口号（虚拟机云部署特别有用）。 支持发送一条消息给多个接收方。 逻辑上解耦 与RPC差异在于消息传递通常是单向的，发送方通常不期望收到消息的回复。]]></content>
      <tags>
        <tag>Distributed System</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RunSpec——一个跑步app设计]]></title>
    <url>%2Fblog%2F2021%2F05%2F01%2FRunSpec%E2%80%94%E2%80%94%E4%B8%80%E4%B8%AA%E8%B7%91%E6%AD%A5app%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[RunSpec——一个基于Kotlin前端，Kafka+Spark+MongoDB后台的跑步app设计 点击项目地址 本文主要记录了一个跑步app的设计过程，该项目是一个课余项目，主要是我为了加深对分布式应用架构的理解而写的。项目主体用Kotlin写前端安卓，前端安卓会读取用户安卓手机传感器中的数据并且传递到后台，后台的Kafka作跑步者数据的消息队列用以解耦与缓冲，再以Spark用以数据分析和存储到MongoDB中。由于笔者水平和时间有限，部分功能还在学习实践探索中。以下将对各个模块进行介绍。 adviser - 根据OpenWeather API的跑步建议的模块该模块是是一个极简的springboot项目，主要功能是根据当前经纬度调用OpenWeather API找到当前天气并且提供一个API。根据该API得到的天气可以为跑者在开跑前提供一些建议。 android - 安卓客户端Kotlin客户端，主要有三个界面。Home页面显示了用户的经纬度，天气情况，Top 5的跑步点（预设的POI，即point of interest，每当有用户经过POI，就会增加热度，对这个热度进行排序，选取前五个）。Dashboard页面展示了步数、跑步距离、跑步用时、经过的地方。Setting页面用来debug。 producer - 接收app数据并且转交给Kafka队列的模块由于目标是庞大的用户群体产生的实时跑步数据，因此使用Kafka来作解耦与缓冲的中间件。前端采集到数据后，发布这些数据给producer模块的Kafka broker再由processor模块消费。同时producer模块利用reslet建立了一些REST API来返回该用户历史跑过的POI，Top5的POI，和用户当前跑过的POI。 processor - 用Spark对实时数据进行分析并存储的模块订阅了Kafka broker的processor模块将对用户实时的跑步数据进行一个分析和存储。这里使用Spark来进行分布式处理较为妥当。首先Spark对mongoDB有原生操作的的connector，处理起来较为便捷。此处由于缺乏对相关例子的研究，并没有用到这个connector。而是简单地用insertOne逐条存储到MongoDB的runnerData表中。当然，对于预设的POI进行了广播，用以在不同的executor上处理数据流时可以由多个task共享一个POI，进行更快速的计算。同时，计算POI和用户经纬度的距离，若小于阈值，再判断是否已有同一用户id，同一tripId经过该点的记录，否则该POI热度加一。将这个count存入数据库表runnerPOIData中。 statisticsboard - POI跑步数据显示面板主要是一个springboot项目。它可以在localhost:8081可视化POI的热度，也可以检测经过POI的用户的记录表。数据每5秒通过stomp websocket推送到面版，再由leaflet.js在页面左边进行渲染可视化。页面右侧是一个表格，记录了trip Id，跑者Id，POI Id，距离与时间。 RunSpec项目如何在kafka集群中，确保顺序收到跑步数据runnerData？ 最简单的方法，一个partition对应一个topic，所有属于这个topic的数据发到同一个partition里。 另一种方法，key(也就是userId)先hash再对集群partition数取余，相同结果的分配到同一个partition，虽然消费者随机读一个partition，但是能保证相同userId的跑步记录不会出现记录顺序错误的问题，这样一来，虽然我们依然不能保证linearizable的收到所有跑者的跑步记录，但是我们可以保证同一个跑者不会出现数据顺序错误。倘若有3个server，也就是三个broker，对应的topic runnerData有三个topic。 但这样一旦节点数增加，key取余对应的partition就不一样了，原来有3个分区，现在有4个，数据就存放到不同的partition了，就会出错，一种方法是只改变分区与节点的对应关系，不改变分区与key的映射。 RunSpec项目如何处理跑步路径海量数据点的压缩？ 由于考虑到存储与实时处理的压力，一般需要某种抽稀算法来压缩路径，也就是只存储一些路径上的关键点（比如折线的拐点等）而不用存储路径上的所有点。常见的一种方法是Douglas–Peucker算法，一种方法是垂直限距法。这个项目使用了垂直限距法作为基础，并且进行了一些改动，使其能实时地压缩数据点。我们首先规定一个threshold，并建立一个thinnedList，thinnedList存放的正是所有压缩后留下的点，即所有关键点，利用这些关键点就能大致地画出轨迹，而不至于带来大的存储压力，还要建立一个window，数据点流都会写到window里，可以当它是一个临时的list，每次都用来处理点到直线距离从而判断一个点是否是关键点。算法简述如下：把第一个点（开始点）放入thinnedList，后面的点不断加入window list，直到window大小等于2时，取thinnedList的最后一个点A，window的两个点B、C，计算B到A、C的直线距离，若大于threshold，则B是一个关键点，放入thinnedList，或直接存入mongo，反之，则点B近似在A、C组成的一条直线上，丢弃不作处理。后面的点不断加入window list，每当window size等于2时就可以判断一个点的去留，因此除了最后一个点，我们将获取中间所有的点的压缩路径。代码如下： 12345678910111213141516171819202122232425private void dilutingRealTime(RunnerData runnerData)&#123; if(thinnedList.size()==0) &#123; thinnedList.add(runnerData); return; &#125; if(window.size() &lt; 2)&#123; window.add(runnerData); &#125; if(window.size() == 2)&#123; double distance = pointToLineDistance( Double.parseDouble(window.get(0).getLatitude()), Double.parseDouble(window.get(0).getLongitude()), Double.parseDouble(thinnedList.get(thinnedList.size()-1).getLatitude()), Double.parseDouble(thinnedList.get(thinnedList.size()-1).getLongitude()), Double.parseDouble(window.get(1).getLatitude()), Double.parseDouble(window.get(1).getLongitude()) ); if (distance &gt; this.threshold) &#123; thinnedList.add(window.get(0)); &#125; window.removeFirst(); &#125; &#125;]]></content>
  </entry>
  <entry>
    <title><![CDATA[ubiquitous computing and IoT 普适计算与IoT]]></title>
    <url>%2Fblog%2F2021%2F04%2F13%2Fubiquitous-computing-%E6%99%AE%E9%80%82%E8%AE%A1%E7%AE%97%E7%BB%BC%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[ubiquitous computing &amp; IoT With the booming development of 5G technology and the Internet, peopleare witnessing the era of the intelligent world that everything is connected.Internet of things (IoT) and Ubiquitous computing (UbiComp) are two hottopics under such circumstances. The article [1] written by R.M.C. Andrade etal. is a good material to help readers learn about the relevant concepts of IoTand ubiquitous computing and provide examples of real-world applications andmetrics to measure the characteristics of IoT and UbiComp. This article reviewwill simply summarize the arguments of the article and offer my opinions on thepros and cons of this article. In the introduction of the article [1] written by R.M.C. Andrade et al, Ubiq-uitous Computing (UbiComp) is a concept occuring before the emergence of IoTand basically UbiComp is to let people use services and technologies withoutperceiving them. As they point out, UbiComp emphasizes on Human-Thinginteractions. IoT shares many commonalities with UbiComp such as Human-Thing interactions but on the other hand, IoT is at a more complex level be-cause it also takes Thing-Thing interactions into considerations. However, theyhold the argument that Human-Thing interactions are significantly impacted byThing-Thing interactions. Meanwhile, they raise the argument that the mea-sures that focus on the characteristics of UbiComp, can also be applied to IoT. To address these arguments, the authors, in the chapter of background, pro-vides further explanations on 5 general characteristics, namely context-awareness,mobility, transparency, attention and calmness of ubiquitous applications outof 27 essential quality characteristics identified in previous work of the authors[2]. To support the rationality for measuring of the characteristics, the authorsrefer to their previous studies, in which they provide detailed calculating func-tions for each characteristic. Simultaneously, the authors point out that IoTis composed of six elementary building blocks, namely identification, sensing,communication, computation, services and semantics. These six elements aretightly related to Thing-Thing interaction, which also allows broader communi-cation over Internet, and is not like Machine-To-Machine (M2M) which simplysupports connection on local wired or wireless networks. By analyzing these sixelements the authors insist that two UbiComp features, context awareness andadaptability can be mapped to IoT domain as measures of the characteristicsof IoT, which respectively capture the context information to serve users andmake changes based on the information. Another important feature presented is the spontaneous interaction, which is related to adapted behaviors of the IoTdevices in or out of the environment. This article then provides some experiments and evaluates on their results. To summarize, three UbiComp applications have been made which have threemain functionalities to block video based on battery level (GREat Tour), to mutedevices when the user is in an office and it is the time for the meeting specified onthe user’s agenda (GREatMute), to print documents at the nearest printer forusers (GREatPrint). Meanwhile, two IoT applications are made to respectivelyenable users to control the air conditioners and lamp manually or automaticallyby motions (Automa GREat) and report the presence of people in a particularroom (GREat Room). A comparison is made on the three UbiComp applicationsand the two IoT applications regarding to six more detailed measures mentionedbefore (adaptability, context-awareness etc.). The article insists that measurescome from UbiComp can be applied to IoT applications. I would argue that the applications given are indeed typical ones in relevantareas. It is also reasonable to measure on the characteristics based on the metricsbeforehand. However, the evaluation result cannot necessarily indicate that themeasures that come from UbiComp can be fully applied to IoT applications. Itis not persuasive that GREatRoom is an IoT application rather than a UbiCompapplication, since it also provide services without people manually or externallyperceive or manipulate it (UbiComp). In that case, if we classify GREarRoomas a UbiComp application, the result of AutomaGREat cannot support theargument because two measures of AutomaGREat are zero percentage and itwould be hard to convince people that the two measures really matters to othertypical IoT applications. One solution I would suggest to resolve the problem isto provide another indeed typical IoT application that has a non-zero adaptationdegree and correctness. In the final discussion, the article lists questions and answers to them, includ-ing firstly the commonalities of UbiComp and IoT applications, secondly the in-teraction problems such as synchrony of IoT data, lack of conflicts handling, de-lay of communication, thirdly the characteristics and measures of Thing-Thinginteraction such as synchronicity, responsiveness, reliability, battery, context-Awareness, interoperability and difficulty of installation, fourthly the majorchallenges to the interaction in IoT such as interoperability, consistency of theinteractions, verification of interest conflicts, and evaluation. To sum up, the article serves as a good material to let readers learn aboutthe concepts of UbiComp and IoT, the commonalities and differences betweenthem, the typical applications and how the charateristics can be measured as acriterion for practitioners. The article also point out the challenges for buildingUbiComp and IoT applications, and motivate researchers to think of adaptingthier UbiComp applications to IoT uses in future study. References[1] R. M. Andrade, R. M. Carvalho, I. L. de Ara ́ujo, K. M. Oliveira, and M. E.Maia, “What changes from ubiquitous computing to internet of things in in-teraction evaluation?” inInternational Conference on Distributed, Ambient,and Pervasive Interactions. Springer, 2017, pp. 3–21. [2] R. M. Carvalho, R. M. de Castro Andrade, K. M. de Oliveira,I. de Sousa Santos, and C. I. M. Bezerra, “Quality characteristics and mea-sures for human–computer interaction evaluation in ubiquitous systems,”Software Quality Journal, vol. 25, no. 3, pp. 743–795, 2017.]]></content>
  </entry>
  <entry>
    <title><![CDATA[分布式系统原理]]></title>
    <url>%2Fblog%2F2021%2F04%2F02%2F%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[分布式系统原理 本文基于ID2203 Distributed Systems, Advanced Course课程，对整个分布式领域的问题进行一个总结。课程参考了Introduction to Reliable Distributed Programming, Introduction to Distributed Algorithms 等书籍。前者更偏向代码实现，书中的伪代码清晰易懂，有兴趣的读者可以买一本看看。 待更。]]></content>
  </entry>
  <entry>
    <title><![CDATA[电影推荐系统设计]]></title>
    <url>%2Fblog%2F2021%2F04%2F02%2F%E7%94%B5%E5%BD%B1%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[电影推荐系统设计 本文出发点是总结市面上比较流行的电影推荐系统后端设计的整个流程，包括阐释Kafka/Redis/Spark/ES等工具的作用、在哪里用、怎么去用这些问题，并且加入自己的一些思考。 项目地址 项目管理MavenApache Maven是一个软件项目管理和理解工具，它基于项目对象模型（POM）的概念，可以用以管理项目的构建，报告与文档。 本项目是一个Maven项目，采用父子项目的结构形式。Maven项目中子项目就是一个Maven module，可以通过右键-&gt;New-&gt;Module-&gt;Maven然后设置即可创建。pom文件中可以设置父子项目的信息。在主目录MovieRecommenderSystem下，我们创建一个Maven module名为recommender，再在recommender下建立五个Maven module名为DataLoader（数据加载），StatisticsRecommender(统计推荐），OfflineRecommender（离线推荐），ContentRecommender(基于内容的推荐)，StreamingRecommender（流式推荐）。 同时，在pom文件中，也可以引入相关的jar包依赖。比如spark-core, spark-sql, spark streaming，mongodb的驱动等等。 数据加载DataLoaderDataLoader主要处理把csv文件的数据集加载到数据库MongoDB中。由于我们现有的数据集是三个csv文件，分布存储了电影信息，评分信息和标签信息。为此我们创建了三个case class，Movie、Rating、Tag，其中参数与csv的headers一一对应。Movie有电影id（mid），名字，描述，时长，发行日期，拍摄日期，语言，派别，演员，导演十个参数；Rating有用户id（uid），电影id，电影评分score，评论时间戳timestamp四个参数；Tag有用户id，电影id，tag名，时间戳四个参数。 由于数据集很大，使用Spark来读取到MongoDB中是一个好的选择，否则数据全都存在内存中就崩了。Spark可以尽可能地使用本地的线程分布式地读取数据并存储在MongoDB中。在SparkContext指定数据的路径，并且对csv文件进行一些split和toDF操作得到一个DataFrame，再对DataFrame进行write-&gt;option-&gt;mode-&gt;format-&gt;save就可以存储MongoDB即可。其中option带有mongo的uri和表名，mode表示存储的形式（可以是overwrite）。此外，还需要对每张表的mid，uid建立索引，指定descending或ascending。建立索引能大大加快查找数据的速度[reference]. 在这个模块中，我们使用了MongoDB作为数据库，Spark作为数据读写工具存储到MongoDB。当然，我们也可以把数据存储到ElasticSearch中，以供用户搜索。一般说来，对于读多写少的存储ES是可以替代MongoDB的[reference]。我们可以将这些固定的表写入ES，向用户提供更快的全文检索等搜索服务。 统计推荐StatisticsRecommenderStatisticsRecommender统计推荐和OfflineRecommender离线推荐都是使用Azkaban进行定时的触发执行的模块。本段主要介绍统计推荐模块。 统计推荐模块对上文DataLoader存储在mongo中的数据进行一个分析，从而得到一下四个推荐结果： 最热电影 一个电影的热度通常用点击量或者评论量来衡量。这里用spark sql统计排序Rating表中具有同一个电影id（mid）的数据的行数，返回一个dataframe，把它写入mongo的RateMoreMovies表。1select mid, count(mid) as count from ratings group by mid order by count desc 最近的最热电影 与上面类似，但是排序还要优先考虑评论时间（timestamp）首先注册一个spark udf名为changeDate，对原来表中的timestamp转换成yyyyMM的形式, 得到ratingOfMonth表1select mid, score, changeDate(timestamp) as yearmonth from ratings 再对ratingOfMonth表每个yearmonth，统计每个电影出现个数，对yearmonth、个数排序。1select mid, count(mid) as count, yearmonth from ratingOfMonth group by yearmonth, mid order by yearmonth desc, count desc 返回结果写入mongo的RateMoreRecentlyMovies表。 Top电影 Top电影考虑的不是评论数而是评分的高低，也就是由平均评分进行一个排序1select mid, avg(score) as avg from ratings group by mid order by avg desc 当然有时我们也可以确保评分个数大于某个数量，因为如果电影只有一条五星评分不足以断定它是Top电影。只需要加上having count(mid)&gt;阈值即可 每个类别的Top电影 之前已经计算了Top电影得到了一个名为averageMoviesDF的dataframe，将其与movieDF通过mid进行inner join操作得到一个movieWithScore（含有movie整体信息，包括我们需要的genre信息，以及avg score）。 考虑到有些电影的派别字段有多个类别genres（用竖线分割），我们就应该先对一个里面有所有的genre的list，和movieWithScore做一个笛卡尔积，然后做一个filter，对每个genre和movieRow（movieWithScore的一行），过滤掉movieRow的genres字段中不含有genre的记录。然后再将整个数据集的数据量减小，只留下必要的记录，生成RDD[genre, Iter[mid, avg score]]，再对genre做groupBy，sortWith平均分，即可得到最后的每个类别的Top电影的集合，将它保存在mongo里。 离线推荐OfflineRecommenderStatisticsRecommender统计推荐和OfflineRecommender离线推荐都是使用Azkaban进行定时的触发执行的模块。本段主要介绍离线推荐模块。 统计推荐使用sql对于显性数据进行分析，而本模块使用了spark ML来做一个基于隐语义模型的协同过滤（CF）的推荐。实际上CF这一块主要分为itemCF和userCF，前者就是两个相似的电影，如果user看了一个那么另一个就可以被推荐；而后者就是两个相似的user，如果一个user看了一个movie那么这个movie也可以被推荐给另一个user。这里由于我们没有考虑user标签，所以采用的是itemCF的方式来进行离线推荐。 那么怎么断定两个电影相似？首先要找到features。给定训练集（user,product,rating)的元组和超参数rank、iterations、lambda，spark ML的ALS算法可以让我们训练出一个model。这个model可以得到一些item的features（productFeatures），我们也可以用这个model直接predict出每个user对每个product的rating。这个有什么用呢？因为原本user不可能对所有movie都评分，user对movie的评分矩阵必然是稀疏的[reference]，但是为了得到每个user对每个movie的评分，ALS算法通过一定规律找到了features，填补了原来没有评分的地方。这样我们很轻易就可以进行一个排序然后得到一个用户的电影推荐列表了。最后存入了mongo的userRecs表。 另外，相似电影也可以通过features信息得到。两个电影都有等长的features列，进行一个余弦相似度的计算（阈值&gt;0.6）就可以得到相似电影矩阵。由于短时间相似电影矩阵都不会发生变化，可以存入mongo的MovieRecs表为实时推荐服务。 实施推荐StreamingRecommenderStreamingRecommender提供了流式推荐服务，是针对用户评分行为的实时推荐模块。简单说来，就是当用户 u 对电影 p 进行了评分，将触发一次对 u 的推荐结果的更新。为此，我们先创建一个kafka流，用以实时接收评分message（UID|MID|SCORE|TIMESTAMP）。并且同时定义stream的LocationStrategies（分区分配方式）和ConsumerStrategies（消费者接收什么topics）[reference]，每当用户评分后，Flume-ng会采集到日志并且推送到kafkaStream，算法会对每个RDD的uid和mid 根据uid找到redis中存储的最近K次电影评分，得到一个Array[(Int, Double)]，即(mid, score)的array 根据mid找到mongoDB中存储的N个最相似的电影（mongoDB中已有通过OfflineRecommender模块ALS算法计算出的相似电影表），并且过滤掉已经看过的电影），得到一个Array[Int]，即候选电影的array 融合步骤1的用户最近看过的K次电影和步骤2中找到的每个候选电影，计算出得分并排序成一个推荐列表。得分需要参考相似度，因为我们希望推荐和用户最近看过相关的电影；但得分也同时需要参考评分，因为可能虽然候选电影相似，但是评分爆低的电影我们也不希望推荐给用户； 保存Array[(Int,Double)]，也即mid和上面计算的得分score的元组数组到MongoDB。 其中有用到redis(jedis), mongoDB, spark, kafka。步骤1使用redis存储最近K次电影评分，好处是因为redis的高速缓存，由于redis是一个内存数据存储，它不能存储非常大的数据，通常数据库内存满了就会通过LRU等淘汰策略，这对读写“最近K次的电影评分”来说，是相当符合的，步骤2使用mongoDB存储相似电影矩阵是因为，mongoDB是基于磁盘的数据存储，无需担心空间的限制，因此存在mongoDB中会更好。使用kafka是因为kafka是一个基于分布式日志的高吞吐、低延迟的发布/订阅消息队列，考虑到同时有一万个用户的电影评分数据（UID|MID|SCORE|TIMESTAMP)需要处理，而这些处理很花费时间，利用kafka做一个中介来暂时存储这些数据，而不是先存入mongoDB然后再读出来计算，会大大增加处理速度，减少数据库压力。 总的说来，当用户评分后，评分数据会通过kafka然后通过我们的实时推荐算法进行处理。当中需要用到redis存储的最近K次评分与mongo存储的相似电影表来计算score并排序得到推荐列表。然后把这个推荐列表存储到mongo里面，之后我们渲染到前端就可以看到推荐结果了。 内容推荐ContentRecommenderContentRecommender是基于内容的推荐。考虑我们通过DataLoader模块存储了Movie表。我们可以假设关键属性是类型genres，描述，演员，导演。尤其是genres，我们可以用来进行冷启动的（首次注册时，询问用户他们喜欢的类型用以建立他们的用户个人资料）。我们可以简单地对类型应用one-hot编码，但通常不同的类型应具有不同的权重。例如，大多数战争电影都是动作电影，因此带有战争标签的电影应该更有价值。在这种情况下，我们可以使用tf-idf算法而不是ALS来解决问题。 在该系统中，tf-idf用于genres，并在MongoDB中生成一个名为ContentMovieRecs的表，并且该部分还可以与Streaming推荐器模块中实现的Kafka Streaming结合使用。 tf-idf是正相关与term frequency，负相关于inverse document frequency，它原来的意思是说，当一个词语出现在一个文档中越多（term frequency），它越有价值；但同时如果一个词语出现在多个文档中都很多（inverse document frequency），比如the，a，an这种，它越没有价值，即使tf很高也没有用。类比于我们的genres这个属性，可能一个用户看了许多动作片，但如果很多影片genre中都有动作片这个标签，动作片这个标签就没有那么有价值。利用spark ML中的HashingTF，IDF，Tokenizer可以找到电影tag（genre）的features，然后再计算余弦相似度就可以得到相似电影矩阵，提供给StreamingRecommender进行实时推荐了。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Distributed Systems revision]]></title>
    <url>%2Fblog%2F2021%2F03%2F18%2FDistributed-Systems-revision%2F</url>
    <content type="text"><![CDATA[Distributed Systems revision IntroductionWhy study distributed systems? (2) Partial Failures Network (dropped msgs, partitions) Node failures Concurrency Nodes execute in parallel Msgs travel asynchronously Two Generals’ Problem Concensus? All correct nodes eventually decide Every node decides the same Only decide on proposed values Database Concurrent changes to same data Nodes should agree on changes Use a kind of concensus: atomic commit {commit, abort} Given Atomic Broadcast, can use it to solve concensus =&gt; consensus cannot be solved in asynchronous system if a single node may crash No bound on time to deliver a msg No bound on time to compute Clocks are not synchronized =&gt; consensus solvable in synchronous system with up to N-1 crashes Known bound on time to deliver a msg know bound on time to compute known lower and upper bounds in physical block drift rate Partially synchronous system with up to N/2 crashes Consensus and Atomic Broadcast solvable with failure detectors Byzantine algorithms tolerate up to 1/3 Byzantine processes Basic AbstractionDistributed algorithms are implemented as middleware between network(OS) and the application. 1) Network protocols aren’t enough TCP only offered for one-to-one communicationHow to group communication Abstractions in this courseReliable Broadcast – Causal order broadcast – Total order broadcast 2) N-N communication isn’t enough Need reliable high-level services Shared memoryConsensusAtomic commitRSM Reliable Distributed abstractionsex: reliable broadcast (ensure the msg sent to a all or one); atomic commit (reach the same decision on whether to commit or abort a transaction) Event-based Component ModelEvents(3) Msgs, Timers, Conditions Two types of eventsRequests (Inputs) Indications (Outputs) Stack of Components in a single process Example:Implements: JobHandler, intance jhupon event &lt;jh, Submit|job&gt; do process(job) trigger&lt;jh, Confirm|job&gt; How to specify a distributed service? (4) Interface (aka Contract, API) Requests Responses Correctness Properties Safety Liveness safety 有限时间内可以被违背= safty is false for an execution E if there exists a prefix such that all extensions are falseliveness 无限时间内才可以被达成= liveness is true for an execution E if for all prefixes there exists an extension that is true Model Assumptions on failure Assumptions on timing (amount of synchrony) failure types (4) crash-stop, omissions, crash-recovery, byzantine:Omission failure covers both (1) Send omission (Not send what has to be sent), (2) Receive omissionIn Crash recovery failures, a process is faulty in an execution if it crashes and never recovers or recovers infinitely often. (amnesia: the recovered nodes might not be able to restore all of state)In Byzantine failures, a process may behave arbitrarily: sending or updating its state as not specified by its algorithm, and behave maliciously (collude) Byzantine &gt; Crash-recovery &gt; Omission &gt; Crash Channel failure modes (5) Fair-Loss Links Channels delivers any message sent with non-zero probability (no network partitions) FL1. Fair-Loss: if m is sent inf often by pi to pj, and neither crash, then m is delivered infinitely often by pj FL2. Finite duplication FL3. No creation: No msg is delivered unless it was sent Stubborn Links Channels delivers any message sent infinitely many times SL1. Stubborn delivery: correct pi msg -&gt; pj, pj delivers infinitely SL2. No creation Perfect Links Channels that delivers any message sent exactly once PL1. Reliable Delivery: correct pi msg -&gt; pj, pj eventually deliver PL2. No duplication: deliver once PL3. No creation use stubborn links to implementkeep log of received msgs in Delivered FIFO Perfect linksFIFO. Ordered Delivery Logged Perfect Links Channels delivers any message into a receiver’s persistent store (msg log) Authenticated Perfect Links Channels delivers any message m sent from process p to process q, that guarantees the m is actually sent from p to q Timing: Clocks =&gt; Lower and upper bounds on clock rate-drift and clock skew with regarding to real timeCausal ordera -&gt; b(1) a occurs before b on the same process(2) if a is a send(m) and b deliver(m), then a -&gt; bCausal order is transitiveTwo events are concurrent if not a -&gt; b and not b -&gt; a Partial &amp; Total OrdersPartial -&gt; doesn’t order concurrent eventsTotal -&gt; any two distinct clock values are ordered (adding pid) Implementation Composed of other services Adheres to interface and satisfies correctness Has internal events Failure DetectorsDistributed algorithms are implemented as middleware between network(OS) and the application. 1) Network protocols aren’t enough TCP only offered for one-to-one communicationHow to group communication Abstractions in this courseReliable Broadcast – Causal order broadcast – Total order broadcast 2) N-N communication isn’t enough Need reliable high-level services Shared memoryConsensusAtomic commitRSM Reliable Distributed abstractionsex: reliable broadcast (ensure the msg sent to a all or one); atomic commit (reach the same decision on whether to commit or abort a transaction) Event-based Component ModelEvents(3) Msgs, Timers, Conditions Two types of eventsRequests (Inputs) Indications (Outputs) Stack of Components in a single process Example:Implements: JobHandler, intance jhupon event &lt;jh, Submit|job&gt; do process(job) trigger&lt;jh, Confirm|job&gt; How to specify a distributed service? (4) Interface (aka Contract, API) Requests Responses Correctness Properties Safety Liveness safety 有限时间内可以被违背= safty is false for an execution E if there exists a prefix such that all extensions are falseliveness 无限时间内才可以被达成= liveness is true for an execution E if for all prefixes there exists an extension that is true Model Assumptions on failure Assumptions on timing (amount of synchrony) failure types (4) crash-stop, omissions, crash-recovery, byzantine:Omission failure covers both (1) Send omission (Not send what has to be sent), (2) Receive omissionIn Crash recovery failures, a process is faulty in an execution if it crashes and never recovers or recovers infinitely often. (amnesia: the recovered nodes might not be able to restore all of state)In Byzantine failures, a process may behave arbitrarily: sending or updating its state as not specified by its algorithm, and behave maliciously (collude) Byzantine &gt; Crash-recovery &gt; Omission &gt; Crash Channel failure modes (5) Fair-Loss Links Channels delivers any message sent with non-zero probability (no network partitions) FL1. Fair-Loss: if m is sent inf often by pi to pj, and neither crash, then m is delivered infinitely often by pj FL2. Finite duplication FL3. No creation: No msg is delivered unless it was sent Stubborn Links Channels delivers any message sent infinitely many times SL1. Stubborn delivery: correct pi msg -&gt; pj, pj delivers infinitely SL2. No creation Perfect Links Channels that delivers any message sent exactly once PL1. Reliable Delivery: correct pi msg -&gt; pj, pj eventually deliver PL2. No duplication: deliver once PL3. No creation use stubborn links to implementkeep log of received msgs in Delivered FIFO Perfect linksFIFO. Ordered Delivery Logged Perfect Links Channels delivers any message into a receiver’s persistent store (msg log) Authenticated Perfect Links Channels delivers any message m sent from process p to process q, that guarantees the m is actually sent from p to q Timing: Clocks =&gt; Lower and upper bounds on clock rate-drift and clock skew with regarding to real timeCausal ordera -&gt; b(1) a occurs before b on the same process(2) if a is a send(m) and b deliver(m), then a -&gt; bCausal order is transitiveTwo events are concurrent if not a -&gt; b and not b -&gt; a Partial &amp; Total OrdersPartial -&gt; doesn’t order concurrent eventsTotal -&gt; any two distinct clock values are ordered (adding pid) Implementation Composed of other services Adheres to interface and satisfies correctness Has internal events Reliable BroadcastFail-stop &lt;=&gt; synchronous (P + PL_Link)Fail-silent &lt;=&gt; aynchronous (PL)Fail-noisy &lt;=&gt; partially synchronous (*P + PL)Fail-recovery &lt;=&gt; (stubborn links or a persistent logs) Quorums A set with at least floor(N/2) + 1 processesresilience f max number of faulty processes &lt; N/2 no deliver guarantees whether sender fails or not 5 reliable broadcast abstractionsBest-Effort: Guarantees reliability only if sender is correctReliable broadcast: Guarantees reliability independent of whether sender is correctUniform reliable broadcast: Also considers behavior of failed nodesFIFO reliable broadcast: Reliable broadcast with FIFO delivery orderCausal reliable broadcast: Reliable broadcast with causal delivery order Best-effort broadcast:If p_i is and broadcast then eventually all processes deliver; (Best effort validity) + No duplication + No creation Reliable broadcast: (Best-effort + Agreement)考虑了发送者fail但有correct的node deliver的情况，这种情况下也必须其它correct的node都deliver&lt;==&gt;If p_i is correct then eventually all correct processes deliver m. If p_i is faulty then either all correct processes eventually deliver m, or no correct process delivers m; Algo: Fail-Stop, Lazy Reliable BroadcastUse P Agreement: If a correct node delivers m, then every correct process delivers m Uniform Reliable broadcast:Reliable broadcast + Uniform Agreement (发送者fail，只要有node deliver，不管crash or correct，别的correctnode都deliver）If a process delivers message m, then every correct process delivers m (Uniform agreement, take “keeping uniform with faulty process which delivers m” into consideration) one time unit is the longest message delay in E Complexity of lazy reliable broadcastN processesBest case: O(N) msgsWorst case: O(N^2) msgsTime complexityBest case: 1 time unitWorst case: 2 time units Eager Reliable Broadcast In lazy rb, we only use completness of P, not related to correctnessQ: replace P with *P? A: replace P with diamond P will lead to:“Pk gets info that Pi has crashed” false (Pi do not crash at all, although Pk will eventually get that Pi is alive, it currently thinks Pk is crashed. So:Pk rebroadcast all msgs of Pi (it is unnecessary) only affect performance, not affect correctness For Uniform Eager Reliable BroadcastWe add a ack list; when all acks received, urb deliver. Uniform agreement need P. Majority-ACK Uniform RB &lt;==&gt;fail-silentResilience less than N/2 for fail-stop algorithmhas resilience = N - 1all acks weaker constraints on ACK less resilience tradeoff Causal BroadcastFor Chat applicationWe should maintain a causal (happen-before) order on the contextUniform broadcast does not remedy this.! Causal reliable broadcast solves this Causality of messageC1 (FIFO order) Some process pi broadcasts m1 before broadcasting m2C2 (Network order) Some process pi delivers m1 and later broadcasts m2C2 (transitivity) There is a message m’ such that m1 -&gt; m’ and m’ -&gt; m2 Causal BroadcastCB: If node pi delivers m1, then pi must have delivered every message causally preceding -&gt; m1 before m1 CB’: If pj delivers m1 and m2 (保证要deliver), and m1 -&gt; m2, then pj must deliver m1 before m2 满足CB’ 不满足CB的情况：图 实现在rb基础上，使用P做GCFail-Silent No waiting causal broadcast Each message m carries ordered list of causally preceding messages in past_m message size grows, uaw Perfect detector P to garbage collect old messages 实现在FIFO-rb上Fail-Silent Causal Broadcast Each msg carries a history, history is set of all causally preceding messages, and a vector timestamp Only deliver m once VCm ≤ VCiDo Not deliver if VCm &gt; VCi or VCm ≠ VCi Single-Source FIFO orderIntuitively: Msgs from same node delivered in order sentFor all msgs m1 and m2 and all pi and pj, if p i broadcasts m1 before m2, and if pj delivers m2, then pj delivers m1 before m2This formulation doesn’t require delivery of both msgs Total OrderIntuitively: Everyone delivers everything in exact same orderFor all messages m1 and m2 and all pi and pj,if both pi and pj deliver both messages, then they deliver them inthe same orderThis formulation doesn’t require delivery of both msgsEveryone delivers same order, maybe not send order! 如果不是single-source fifo必不是total order Hierarchy 图 Distributed Shared MemorywikiThe memory location which is concurrently accessed (read/write/CAS) is sometimes called a register. DSM interface (4)read invokation, read response, write invocation, write response Regular Register (1, N) Termination Each read and write of a correct node completes ValidityRead returns last value written if Not concurrent with another write and Not concurrent with a failed writeOtherwise may return last or concurrent “value” Read-One Write-All (1, N) algorithmread locally没有RTT，之后的算法都是read globallyP22 Postpone write responses to ensurethe writer does not return until it knows that the reader delivers the value that is broadcasted写有1个RTT2 communication steps (broadcast and Ack from all)O(N) messagesresilience: N-1然而却要Perfect Failure Detector，下面的就不用FD Majority voting (1,N) algorithmEach process stores the value of all registers=&gt; write(r, v)UPDATE PHASEts++(ts is a sequence number initialized to zero at the writer and incremented at each write)timestamp-value pair, tvp = (ts, v)send 一个update requestpj updates r = max(r, (ts, v)) and responds with ACKQUERY PHASEpi sends query, receives response (ts,v), picks max(ts, v) !Avoid old writes overiting new writewrite will be ignored if it has lower timestamp 2 communication steps (one round trip)O(N) messagesresilience: f &lt; floor(N/2) Atomic/Linearizability vs. Sequential Consistencysequential order vs. global time order看例子 Majority voting算法是regular register但是如何保证Atomic的？ (SWMR)Read-Impose Write Majority (1, N)P66 When reading, also do an update (if ts same, then just return) before responding读后写，写上一个写的值 (MWMR linerizable)Atomic Register Read-impose write-consult-majority (N, N)具有linearizability Before writing, read from majority to get last ts Do a query phase to get the latest timestamp before the update phase 为了synchronize ts Two concurrent writes with same ts? compare process identifierwrite operationquery + update phasewrite needs 2 tripsOne for the timestampOne for broadcast-ACK写前读，读上一个ts + 读后写，写上一个写的值read needs 2 round-tripsone for readone for impose if necessary (MWMR sequential consistent)==&gt;LTLogical Time algorithm (LT)(N,N) Seq ConsistentWrites in 1 RTT and reads in 2 RTTsTolerates f&lt;n/2 faulty processesLinearizability in logical time allows compositionality tvp = ((lt, i), v)((10,1),5) timestamp 10, pid 1,value 5 Livness(3)Wait-free (no deadlocks, no live-locks, no starvation)Lock-free/non-blocking (no deadlocks, no live locks, maybe starvation)Obstruction free/solo-termination (no deadlocks, maybe live-locks, maybe starvation) 总结Distributed Algorithms ===&gt;the weak model (regular register) SWMR (Single write multiple read) regular registers Bogus algo (did not work)Centralized(no failures)Read-One Write-All Algorithm (P)Majority Voting(No FD) ===&gt;the strong model(atomic register)atomic register SWMR linearizable registers read-impose idea MWMR linearizable registers read-impose write-consult MWMR sequentially consistent registers read-impose write-consult-majority Compare the performance and resilience of algorithms ConsensusSingle Value Consensus properties (4)Validity: Any value decided is a value proposedAgreement: No two correct nodes decide differentlytermination: Every correct node eventually decidesintegrity: A node decides at most once do not care about crashed nodes 怎样避免orphan message（之前propose的值后到了，不应该再decide了）Invariantadopt if proposer p is ranked higher than lastpropotherwise p has crashed and should be ignored Implements: Hierarchical Consensus(c)Uses:beb + P第几轮就是第几个process decide和broadcast Validity: Always decide own proposal or adpoted valueIntegrity: Rounds increase monotonically, A node only decide once in the round it is leaderTermincation: Every correct node makes it to the round it is leader, if some leader fails, completeness of P ensures progress. If leader correct, validity of BEB ensures deliveryAgreement: No two correct nodes decide differently How many failures can it tolerate? N-1 Uniform Consensus properties (4)Uniform Agreement (care about crashed nodes) Possible with weaker FD than P?Yes! use Strong Detector (S)Strong completenessWeak Accuracy: the “accurate” corect leader will BEB value and final decision is v by all Eventually perfect detector, cannot solveconsensus with resilience t ≥ n/2 PaxosSingle Value Uniform Consensus Validity (only proposed -&gt; decided) Uniform Agreement (No diff decide) Integrity (at most once) Termination (eventually decide a value) not solvable in Fail-Silent (aynchronous sytem model) 所以assumePartially synchronous system + fail-noisy model + Message duplication, loss, re-ordering use omega(evetual leader election to elect a single proposer) Proposer imposes its proposal to everyone Everyone decides问题是serveral processes might initially be proposers多个process都能propose使用abortable consensus 解决omega ensures evetually 1 proposer succeeds (liveness) PAXOSproposers (impose proposal to set of acceptors)acceptors (may accept values issued by proposers)learner (will decide depending on acceptors acceptances) centralized因为面临单点故障，不行 there will be a single proposer at least providing obstruction-free progress不能无脑选第一个distinguish proposals with unique seq number (ballot number)不能restart（这样就chose了两个值） P1 An acceptor accepts first proposal it receives (ensures obstruction-free progress and validity)P2 If v is chosen, every higher proposal chosen has value v (ensures agreement, integrity trivial to implement)P2a( lemma方便实现) every higher proposal accepted has value vP2b (加强) every higher proposal issued has value vP2c If any proposal (n,v) is issued, there is a majority set S of acceptors such that either(a) no one in S has accepted any proposal numbered less than n(b) v is the value of the highest proposal among all proposals less than n accepted by acceptors in S A proposer at round n needs a query phase to get the value of highest round number + a promise that the state of S does not change until round n 总体流程 proposer pick unique seq n, send prepare(n) to acceptors acceptors 承认不会接收n以下的proposals（freeze）, 发送最高n的accepted proposal proposer收到majority的promise, 取最高n的proposed value (如果没有就任取一个v（说明第一次）)进行accept(n, v) acceptor接收了(n, v)，如果无接收prepare m&gt;n, 则accept proposal (ack); 否则reject(nack) Proposer 接收到majority的response，decide否则abort 可能abort的点 Contention (multiple proposals competing) Message loss (not getting an ack) process failue (proposer dies) Optimizations Paxos (AC) in a nutshell Necessary:rej accept(n,v) if answered prepare(m): m&gt;n Optimizations: rej prepare(n) if answered prepare(m): m&gt;n rej accept(n,v) if answered accept(m,u): m&gt;n reject prepare(n) if answered accept(m, u): m&gt;n ignore old msgs to proposals that got majority Proposer skips the accept phase if a majority of acceptors return the same value vperformance++ 只要有stable storage可以应用到fail recover model RSM (Replicated State Machine)multi-paxos: ProCmds = {}Log = &lt;&gt;s0(initial state)proposed = false A client q wants to execute a command C, it reliably rb-broadcast &lt;C, Pid_q&gt; to all serversupon delivery &lt;C,Pid_q&gt; at pj, the command pair is added to ProCmds unless it is already in Log Validity● If process p decides v then v is a sequence of proposed commands(without duplicates)Uniform Agreement● If process p decides u and process q decides v then one is a prefix ofthe otherIntegrity● If process p decides u and later decides v then u is a strict prefix of vTermination (liveness)● If command C is proposed by a correct process then eventually everycorrect process decides a sequence containing C Agree on (non-duplicate) commandsallow to issue the same command C multiple times Initial statePropoer:np:=0 proposer’s current round numbervp:=&lt;&gt; proposer’s current value (empty sequence) Acceptor:npromise:=0 promise not to accept in lower roundsna:=0 round number in which a value is acceptedva:=&lt;&gt; accepted value(empty sequence) Learnervd:=&lt;&gt; decided value(empty sequence) 看ppt图 依然有一些问题● A proposer can run only one proposal until decide before taking thenext proposal. No pipelining of proposals● Multiple proposers may lead to live-locks (liveness violation)● Two round-trips for each sequence chosen use BLE to make a single proposer running for a longer period of time as a leader BLE1: Eventually every correct process trusts some correct correct process if a majority are correctBLE2: Eventually no two correct processes trust different correct processes We assume initially fail-noisybut net is weaker model that may drop msg and process crash and recover Majority requirement Each correct process will trust a leader only if the leader’s max ballot is among the collected ballots from a majority of processes Monotonically increasing ballotsEvery process p that do not receive the leader’s ballot (n, pidL) among collected ballots consider the leader has crashes p increases his own ballot (n+1, pidp) Eventual agreement&lt;=&gt; BLE2Completeness&lt;=&gt; BLE1 Leader Based Sequence PaxosAssume eventual leader election abstraction with a ballot number BLEBLE satisfies completeness and eventually accuracy and also monotonically unique ballots P4 inefficient 有多个proposer时，conflicts和restarts are likely (higher load -&gt; more conflicts) 2 round of msgs for each value chosen (Prepare, Accept) Solution: pick a leader (L,n) where n is a unique higher round number the leader acts as sole Proposer for round n After first Prepare (if not aborted) only perform Accepts until aborted by another Leader where n’ &gt; n Allow issuing and accepting multiple proposals in round n Initial State for Sequence Paxos ProposersnL=0, vL= leader’s current round number, proposed valuepropCmds=&lt;&gt; leader’s current set of proposed commands(empty set)las=[0]^N length of longest accepted sequence per acceptorlc=0 length of longest chosen sequencestate={(leader, prepare), (leader, accept), follower} Acceptornprom=0 Pomise not to accept in lower roundsna=0 round number in which a value is accpetedva=&lt;&gt; Accepted value(empty sequence) Learner Decide value(empty sequence) Removing redundancy of vL, va and vd removing vL:When p becomes a leader, it is possible to remove the need tostore the sequences vL and va separately at the leader removing vd: at decide phase add a new assumptionA3: FIFO Perfect Links partially sync for BLE but async for LBSP ReconfigurationA replicated state machine is running on a set of N processes Impossible to know if a process is faulty or slow in asychronous system must be able to replace any process this is called reconfiguration Each configuration is conceptually an instance of Sequence-Paxosreplicas in configuration c1 = {r11,r12,r13,r14}A process may act as multiple replicas in different configurationse.g. p1 is {r01, r11, r21} if seq v is issued in round n then v is an extension of all sequences chosen in rounds &lt;= n stop-sign - last command - final sequence rij: replica j in config i Overlapping configurations A process have replicas in multiple configurationsBut can only be running in one configuration at anytime Time and Clocks in DSMotivation for using physical clocksConsider a slightly stronger system model: Computation: no bounds on time to take a step Communication: no bounds on latency Clocks: Lower and upper bounds on clock rate Time-based leader leases network partition P17one is elected as leader but the original leader never hears about that A propose p to become leader: sends a request (prepare) to acceptors An acceptor gives a time-based leader lease to p, lasting for 10 seconds If a proposer gets leases from a majority of acceptors, then proposer holds lease on group and becomes a leader In the time until the first acceptor lease expires, the proposer knows that no other proposer can hold the lease on the group此时leader可以从local state里读然后直接返回 两个问题asynchronous networkclock drift P34如果proposer（receive lease的人）时钟比较快，那么leader会先取消自己的时钟，所以不会影响safety 反之，如果acceptor（give lease的人）时钟比较快，就会影响safety Shared memory using clocks Review of shared memory:Leases at proposerThe Read-Impose Write-Consult_Majority algorithm does 2 round-trips to a majority of processes for both reads and writes… need synchronized clocks Interval ClocksCi(t) = (lo, hi) the correct time t is guaranteed to be in intervalCi(t).lo &lt;= t &lt;= Ci(t).hi Ci read at t1, Cj read at t2, and t1 &lt; t2Ci(t1).lo &lt; Cj(t2).hi use ICs to remove query phase in write operations p1 must wait until ts(o1).t &lt;= C1(t1).lo ts(o2).t = C2(t2).hi (invoke write o2) 因为t1 &lt; t2 所以 C1(t1).lo &lt; C2(t2).hiHence: ts(o1) &lt; ts(o2) Consistent Snapshotfailure recovery and reconfiguration SNAP -&gt; Restart system from snapshot -&gt; restart system with new configuration S1: Termination: Eventuallt every process records its stateS2: Validity: All recorded states correspond to a consistent cut of the execution Chandy Lamport Algorithm FIFO Reliable Channels Single Initiating Process pi Strong Connectivity 强连通 Design goal:Obstruction-free: run concurrently but not alter underlying computation Intuition:Disseminate a special message to mark events before and after the consistent cut Termination is still satisfied if the protocol is initiated by a set of processes that can reach all tasks. Epoch Snapshotting:make production-grade data processing systems reliable Previous approaches Complex Workarounds (e.g., duplicate elimination, input logging, acks) Strong Assumptions (idempotent operations, key vs task level causal order) External State Management (transactional external commits per action Epoch-based stream execution the intuitionfor each epochinput: deterministic input streams &amp; task statesstream processing systemsuccess: commit system configurationfailure: abort and start from previous epoch consistent cut is not enoughepoch cut support the large stream processing system]]></content>
      <tags>
        <tag>Distributed System</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dirty read, phantom read, and unrepeatable read]]></title>
    <url>%2Fblog%2F2021%2F02%2F22%2Fdirty-read-phantom-read-and-unrepeatable-read%2F</url>
    <content type="text"><![CDATA[dirty read, phantom read, and unrepeatable read 脏读dirty read：读取未提交的数据。B发起事务，B写后，A读（读取未提交的数据），但B之后回滚了，再提交，A再读，不一致。 不可重复读unrepeatable read：前后多次读取不一致。A读，B写，B提交，A再读，不一致。针对update操作。 幻读phantom read：前后多次读取，数据总量不一致。A读数据库行数，B插入或删除某一行，A再读行数，不一致。 针对insert和delete操作 解决方案： 根据数据库事务四大性质中的隔离性：隔离性级别被分为read_uncommit，read_commit，read_repeatable，Serializable用以解决以上的问题。它们的区别是：read_uncommit没有解决任何问题，read_commit解决了脏读，read_repeatable解决了脏读和不可重复读，Serializable解决了三种情况。 read_commit：在上文的情况下，B写的整个事务周期，A都不能读。只有B发起事务前和提交事务后A才能读，这样就不会出现B写时A读从而读取不一致的情况。（Sql Server , Oracle使用的就是read_commit级别） read_repeatable: 保证了不出现脏读，并且保证不可重复读。A读时，就对行加锁，B不能写这条数据。直到A多次读完后，B才能写。（MySQL使用的就是read_repeatable级别）123/* （参数可以为：Read uncommitted，Read committed， Repeatable，Serializable） */SET session TRANSACTION ISOLATION LEVEL Repeatable;SELECT `id` FROM `users` WHERE `id` = 1 FOR UPDATE; serializable：保证了不出现脏读、不可重复读和幻读。A读时，对表加锁，B不能添加或删除其它数据行。1SET session TRANSACTION ISOLATION LEVEL Serializable; 参考 https://cloud.tencent.com/developer/article/1450773 https://segmentfault.com/a/1190000016566788]]></content>
      <tags>
        <tag>Distributed System</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Disributed Framework and Dubbo]]></title>
    <url>%2Fblog%2F2021%2F01%2F28%2FDisributed-Framework-and-Dubbo%2F</url>
    <content type="text"><![CDATA[Distributed Framework and Dubbo What is Distributed System?a collection of independent comptuters which serve like a coherent system to users. Framework transition and why we need Distributed Framework?All in One ArchitectureInitially, we have one simple application, on which all the functionalities are integrated, when we have only a few users. At that time, ORM is necessary because it simplify the CRUD processes. When there are more and more users, we surely need more servers to bear more pressure (One application Multiple servers). Therefore we need more servers ro bear the pressure together (use Ngnix to balance overload). However that will cause two problems: Difficult to extendWhen we modify one func of one server, we need to package the whole application again to other servers. Difficult to collaborate Vertical Architecturedifferent modules of applications (e.g. User/Shopping Cart/Payment), assign different number of servers to modules based on demands. We will meet the problems and we should also: View/ Logics should be divided Applications cannot be fully seperated, some should interact RPC ArchitectureBut there yield another problem, how to interact between Web view and Services logics as they are divided? Answer: Use RPC (Remote Process Call). Therefore, we need a distributed service framework to handle the RPC. And we also need a scheduler to balance the load. RPC problemsRPC is a method that used by one service on one server A to call the procedure on another server B. Both server A and B should have its own stub (helper) to handle the sending messages(functions/parameters)and returning messages(results). The RPC is an aynchronous process. To send or receive the messages the stub should firstly serialize or deserialize the objects. The core problems in an RPC framework: how efficient to establish connection how efficient to serialize/deserialize RPC framework - Dubbohttps://dubbo.apache.org/en/ Dubbo is a framework with following features: Interface-based High-performance RPC Intelligent load balance Automatic service registration and discovery (“recommend”) High extensibility (micro-kernal and plugin design) Runtime traffic routing (blue-green deployment, some requests use new services, some use old services) Visualization]]></content>
      <tags>
        <tag>Distributed System</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Byzantine Leader Election]]></title>
    <url>%2Fblog%2F2021%2F01%2F24%2FByzantine-Leader-Election%2F</url>
    <content type="text"><![CDATA[Why in Byzantine Leader Election, N &gt; 3f GivenN: number of the processesf: number of the Byzantine processes In the paper “Practical Byzantine Fault Tolerance”, we get the conclusion that 3f+1 is the minimum number of replicas that allow an asynchronous system to provide the safety and liveness properties when up to f replicas are faulty. This many replicas are needed because it must be possible to proceed after communicating with n-f replicas, since f replicas might be faulty and not responding. However, it is possible that the f replicas that did not respond are not faulty and therefore f of those that responded might be faulty. Even so, there must still be enough responses that those from non-faulty replicas outnumber those from faulty ones, i.e., n-2f&gt;f. Therefore n&gt;3f. 理解起来其实很困难，总给人一种哪里不对的感觉。比如为什么不能直接大多数N &gt; 2f 就能解决呢？只要有f+1个正确节点都表态(+)，即使有f个拜占庭节点都投反对票(-)，那正确节点也占多数，最后不也达成了正确的一致性吗？ 但是这忽略了系统的一个根本问题：什么时候才能达成一致性呢？拜占庭节点之所以叫拜占庭节点，就是说它所做的是不可控的（表态可以是表态+或-或者干脆不表态）。也就是说，如果我规定某个节点A（可能是正常也可能是拜占庭节点）要知道大多数的意见，A需要收集N个消息（包括自己），但是拜占庭可能不回复，因此就永远收集不了N-f个消息，无限等待。我们当然不希望无限等待一个永远不回复的拜占庭节点，因此我们的quorum就必须规定为最大N-f。当我们收集到最多N-f个消息后，我们就必须能够通过多数派判断选票结果。 因此，考虑到拜占庭节点的不确定性，除了本身N-f即形成quorum，我们还要考虑回复消息的至多f个拜占庭节点，除去这些节点，也即N-2f这些节点必是正确节点，这些节点的个数要大于f个拜占庭节点从而形成正确的consensus，也即N-2f&gt;f，也即N&gt;3f。 例子： 前提：由于f个拜占庭节点可能都挂，f个拜占庭节点可能不回复，所以必须收集到最多N-f个消息就已经决定结果了，也就是最大的quorum大小Q（极限情况） f=1时，N=3，不行，因为收到2个消息时，可能一正一误，无法判断。N=4，可以，因为收到3个消息，必有两正一误，或三正，都可以得出正确结果。N&gt;4，可以，收到N-1个消息，必有N-1 &gt; 2 * 1，quorum中正确节点数总是大于拜占庭节点数 f=2时，N=5，不行，因为收到3个消息时，可能一正两误。N=6，不行，因为收到4个消息时，可能两正两误，无法判断。N=7，可以，因为收到5个消息，必有三正，大于两误，可以得出正确结果。N&gt;7，可以，收到N-2个消息，必有N-2 &gt; 2 * 2，quorum中正确节点数总是大于拜占庭节点数 … 由以上每种情况最后一行类推，N-f &gt; 2 * f，可知N &gt; 3f 补充：没有拜占庭情况，即crash-stop, crash noisy, crash-recovery, crash silent情况N=2f+1, Q=(N+1)/2有拜占庭情况，N=3f+1，Q=N-f也等于2f+1]]></content>
      <tags>
        <tag>Distributed System</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SVM公式推导和原理解析]]></title>
    <url>%2Fblog%2F2020%2F12%2F16%2FSVM%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC%E5%92%8C%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[SVM公式推导和原理解析]]></content>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多分类AUC计算]]></title>
    <url>%2Fblog%2F2020%2F11%2F07%2F%E5%A4%9A%E5%88%86%E7%B1%BBAUC%E8%AE%A1%E7%AE%97%2F</url>
    <content type="text"><![CDATA[一般涉及到的是binary classification的AUC计算,这里给出的计算方法即可用于binary也可用于多分类问题。 input: 给定的dataframe, 实际预测的correctlabelsoutput: AUC 面积 举个例子，给定的dataframe是 d A B C 0 0.50 0.50 0.00 1 0.50 0.25 0.25 2 0.50 0.25 0.25 3 0.25 0.50 0.25 4 0.25 0.25 0.50 A,B,C代表三个类，其中的数字代表着预测该类的概率 而corrrectlabels也即实际预测的结果是[“B”,”A”,”B”,”B”,”C”]这两者作为input可以计算output的AUC面积 以下是求面积的代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071def find_pos_neg_instance_scores(prediction_column, correct_labels, column_name): prediction_column_array = np.array(prediction_column) binary_AUC = [column_name == i for i in correct_labels] print('binary_AUC=', binary_AUC) # positive_instance_scores =&gt; Col-Name (predicted class) matches with the correct class positive_instance_scores = prediction_column_array[binary_AUC] # negative_instance_scores =&gt; Col-Name (predicted class) DOES NOT match with the correct class negative_instance_scores = prediction_column_array[~np.array(binary_AUC)] print(positive_instance_scores) print(negative_instance_scores) return positive_instance_scores, negative_instance_scores# fpr=False_Positive_Rate# tpr=True_Positive_Ratedef get_tpr_fpr(prediction_column, correct_labels, column_name): positive_instance_scores, negative_instance_scores = find_pos_neg_instance_scores(prediction_column, correct_labels, column_name)# print(positive_instance_scores)# print(negative_instance_scores) scores_extended = [0] scores_extended += sorted(prediction_column) scores_extended += [1] print('scores_extended=',scores_extended) dict_tpr_fpr = &#123;&#125; for predicted_score in scores_extended: if(len(negative_instance_scores)==0): count_false_pos_instances = 0 else: count_false_pos_instances = np.sum(negative_instance_scores &gt;= predicted_score)/len(negative_instance_scores) if(len(positive_instance_scores)==0): count_true_pos_instances = 0 else: count_true_pos_instances = np.sum(positive_instance_scores &gt;= predicted_score)/len(positive_instance_scores) #dict_tpr_fpr[predicted_score] = [count_false_pos_instances, count_true_pos_instances] dict_tpr_fpr[predicted_score] = [count_true_pos_instances, count_false_pos_instances] print('dict_tpr_fpr=',dict_tpr_fpr) list_reversed_tpr_fpr = [i for i in reversed(list(dict_tpr_fpr.values()))] print('list_reversed_tpr_fpr=', list_reversed_tpr_fpr) return list_reversed_tpr_fprdef calculate_AUC(list_reversed_tpr_fpr): # AUC = Area under ROC curve AUC = 0 n_tpr_fpr = len(list_reversed_tpr_fpr) for i in range(n_tpr_fpr - 1): if(list_reversed_tpr_fpr[i][1] != list_reversed_tpr_fpr[i + 1][1]): # if fpr is changing but tpr is not changing then the area is a square=a*b=(tpr[i+1]-0)*(fpr[i+1]-fpr[i]) if(list_reversed_tpr_fpr[i][0] == list_reversed_tpr_fpr[i + 1][0]): AUC += list_reversed_tpr_fpr[i + 1][0]*(list_reversed_tpr_fpr[i + 1][1] - list_reversed_tpr_fpr[i][1]) else: # if both are changing then the area is a trapezoid=(a+b)*h/2=(tpr[i]+tpr[i+1])*(fpr[i+1]-fpr[i])/2 AUC += (list_reversed_tpr_fpr[i + 1][0] + list_reversed_tpr_fpr[i][0])*(list_reversed_tpr_fpr[i + 1][1] - list_reversed_tpr_fpr[i][1])/2 return AUC def auc(df, correctlabels): AUC = 0 class_frequency = dict() for i in correctlabels: if i not in class_frequency: class_frequency[i] = (1/len(correctlabels)) else: class_frequency[i] += (1/len(correctlabels)) for col in df.columns: prediction_vector = df[col] list_reversed_tpr_fpr = get_tpr_fpr(prediction_vector, correctlabels, col) area_col = calculate_AUC(list_reversed_tpr_fpr) AUC += class_frequency[col] * area_col return AUC 测试代码:12345predictions = pd.DataFrame(&#123;"A":[0.5,0.5,0.5,0.25,0.25],"B":[0.5,0.25,0.25,0.5,0.25],"C":[0.0,0.25,0.25,0.25,0.5]&#125;)correctlabels = ["B","A","B","B","C"]print("AUC: &#123;&#125;".format(auc(predictions,correctlabels))) 步骤说明：第一步即调用auc方法计算class_frequency，即利用frequency作为权重将所有类的AUC相加。(Calculate the weighted AUC by summing the individual AUCs weighted by the relativefrequency of each class (as estimated from the correct labels) 接下来就是计算每个类的AUC了,实际上是每个类的binary AUC, 也即对于这个类的FPR和TPR点所围面积的和 概念链接。 因此，首先我们必须计算TPR和FPR点的坐标，也就是get_tpr_fpr函数，先找到其中判断对positive与错negative的scores（find_pos_neg_instance_scores函数），再对prediction_column（这里需要在首尾加一个0和一个1，好帮助后面的面积计算）中的每个prediction_score，判断它和判断negative 或positive instance的score的关系。得到count_false_pos_instances和count_true_pos_instances的两句实际上就是FPR（在所有实际为阴性的样本中，被错误地判断为阳性之比率FPR=FP/(FP+TN)）和TPR（在所有实际为阴性的样本中，被错误地判断为阳性之比率TPR=TP/(TP+FN)）的计算过程。 这一步之后再进行个从小到大的排序，其实就得到了所有的score对应的TPR和FPR pair 也即点坐标，只要画出点坐标连接后下方在坐标轴上的面积（以TPR为纵轴，FPR为横轴），就可以得到AUC的面积了。而这一步则用calculate_AUC函数自动计算得到。 得到了每一个类的AUC，再做一个weight sum就是最后的多分类AUC面积。 更简单的多分类方法（概率方法）：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849def auc(df,correctlabels): new_df=df.copy() lens=len(correctlabels) cols=new_df.columns.tolist() if len(cols)&lt;3: #binary ;only Pos and Neg pos=[ i for i in range(lens) if correctlabels[i]==cols[0]] neg=[i for i in range(lens) if correctlabels[i]!=cols[0]] print(pos,neg) one=new_df[cols[0]] auc = 0 for i in pos: for j in neg: if one[i] &gt; one[j]: auc += 1 elif one[i] == one[j]: auc += 0.5 return auc / (len(pos)*len(neg)) else: # CLASS &gt;=3 Pos / non-Pos aucs=[] for col in cols: pos=[ i for i in range(lens) if correctlabels[i]==col] nonpos=[i for i in range(lens) if correctlabels[i]!=col] print(pos,nonpos) one=new_df[col] auc = 0 for i in pos: for j in nonpos: if one[i] &gt; one[j]: auc += 1 elif one[i] == one[j]: auc += 0.5 auc=auc/(len(pos)*len(nonpos)) aucs.append(auc) weights=[correctlabels.count(col)/len(correctlabels) for col in cols ] print(weights) print(aucs) weights=np.array(weights) aucs=np.array(aucs) avg_auc=np.sum(aucs*weights) return avg_auc# testpredictions = pd.DataFrame(&#123;"A":[0.5,0.5,0.5,0.25,0.25],"B":[0.5,0.25,0.25,0.5,0.25],"C":[0.0,0.25,0.25,0.25,0.5]&#125;)correctlabels = ["B","A","B","B","C"]print("AUC: &#123;&#125;".format(auc(predictions,correctlabels))) 简单的二分类AUC计算12345678910111213141516171819def cal_auc(prob, labels): f = list(zip(prob, labels)) rank = [values2 for values1, values2 in sorted(f, key=lambda x: x[0])] rankList = [i + 1 for i in range(len(rank)) if rank[i] == 1] posNum = 0 negNum = 0 for i in range(len(labels)): if (labels[i] == 1): posNum += 1 else: negNum += 1 auc = (sum(rankList) - (posNum * (posNum + 1)) / 2) / (posNum * negNum) return auc# testmodel = BernoulliNB()model.fit(x_train, y_train)prediction = model.predict_proba(x_val)auc = cal_auc(prediction[:, 1], np.array(y_val))]]></content>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[computer network]]></title>
    <url>%2Fblog%2F2020%2F08%2F03%2Fcomputer-network%2F</url>
    <content type="text"><![CDATA[计算机网络知识点 用户态（应用层HTTP,FTP,DNS,HTTPS)核心态(传输层tcp, 网络层ip, 链路层) 二、链路层 功能：将上层数据封装成帧，用MAC地址访问媒介，错误检测与修正 以太网帧格式7字节前导码（同步）1字节帧开始符6子节MAC目标地址6子节MAC源地址一个4子节标签（可选）2字节以太类型（0x0800 IPv4; 0x0806 ARP)负载46-1500字节CRC冗余校验帧间距12字节 MTU（Maximum transmission Unit) 数据链路层最大数据包大小，单位：字节。即无需进一步分片就能穿过这条“路径”的最大传输单元的最大值。如果不要分片，设置数据报的DF位（Don’t fragment），路径上任何需要将分组进行分片的设备都会将这种数据报丢弃并返回一个“数据报过大”的ICMP响应到源地址。 arp协议 address resolution protocol 实现ip地址到MAC地址的映射，即询问目标IP地址对应的MAC地址，然后放入ARP缓存表。原理：把带有目标ip地址的arp请求广播到局域网上所有主机，并接受响应获取mac地址。存入arp缓存表一段时间。目的MAC地址：占6字节，表示接收方设备的硬件地址，在请求报文中该字段值全为0，即00-00-00-00-00-00，表示任意地址，因为现在不知道这个MAC地址。 基于功能来考虑，ARP是链路层协议；基于分层/包封装来考虑，ARP是网络层协议（2字节以太类型（0x0800 IPv4; 0x0806 ARP)） 三、网络层功能：1、路由选择（规划路线）2、存储、交换、转发（路由器通过路由表转发包，如果接收速度大于转发速度就缓存）3、拥塞控制 4、呼叫准入（所有路由器的许可） ip首部格式：如图第二行，16位序列号：如有分片，下一个序列号与上一个相同，若无分片，下一个序列号等于上一个加一。3三个bit位：第一位保留，未使用。第二位是DF（Don’t Fragment），如果为1，表示未发生分片。第三位是MF（More Fragment），如果为1，表示发生了分片，并且除了分片出的最后一个报文中此标志为0，其余报文中此标志均为1。13位片位移：分片相对于原始ip数据报开始处的偏移。 8位生存时间TTL（time to live), 防止数据报兜圈子，不断减去在路由器间传递的时间，直到零就丢弃数据报，不再转发。 16位首部检验和 掌握IP分片一个长4000B的IP数据报，数据部分3980B,到达了一个路由，需要转发到一个MTU为1500B的链路上，这样就得分片了。分片数目是3片。每个片都是一个数据报。假设标识是777，那么数据报分片结果是：分片一：标识：777，MF=1，DF=0,片偏移=0，有效数据：1480B(编号0~1479)分片二：标识：777，MF=1,DF=0,片偏移=185，1858=1480，有效数据：1480B(编号1480~2959)分片三：标识：777，MF=0,DF=0,片偏移370，3708=2960，有效数据：1020B(编号2960~3979) IP路由表 分组转发流程 从数据报首部提取主机的IP地址D，得到目的网络地址N（子网掩码存储在路由表中，与IP地址D进行逻辑与即可得到N） 若N是与此路由器直接相连的某个网络地址，直接交付 若路由表中有目的地址为D的特定主机路由/到达网络N的路由，则把数据报传送给表中指明的下一跳路由 若路由表中有一个默认路由，则把数据报传送给路由表所指明的默认路由器 报告转发分组出错 IP内部网关协议RIPRIP 按固定的时间间隔仅和相邻路由器交换自己的路由表，经过若干次交换之后，所有路由器最终会知道到达本自治系统中任何一个网络的最短距离和下一跳路由器地址。 ICMP查询2种+差错5种 四、传输层UDP协议：特点，首部字段 TCP协议：特点+首部字段+可靠机制首部（校验和。。。） 连接基础 三次握手 目的：为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误。主要防止资源的浪费。 四次挥手（为什么） 关闭连接时，当收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，我们也未必全部数据都发送给对方了，所以我们不可以立即close，也可以发送一些数据给对方后，再发送FIN报文给对方来表示同意现在关闭连接，因此，我们的ACK和FIN一般都会分开发送。 同时打开、同时关闭、半关闭 服务器第一次收到客户端的 SYN 之后，就会处于 SYN_RCVD 状态，此时双方还没有完全建立其连接，服务器会把此种状态下请求连接放在一个队列里，我们把这种队列称之为半连接队列。当然还有一个全连接队列，就是已经完成三次握手，建立起连接的就会放在全连接队列中。如果队列满了就有可能会出现丢包现象。来源链接 tcp流量控制机制：滑窗、 在未收到ACK确认之间都必须暂时保留在发送窗口内，以便超时重传使用 慢启动、拥塞避免、快速重传、快速恢复超时重传 伪包头 五、应用层域名解析DNS协议名字空间、DNS指针查询（反向查找或逆向解析）、DNS缓存 DNS查询过程实例1）客户端将www.redhat.com的查询提交给本地DNS服务器（递归查询）。2）本地DNS服务器检查区域数据库，由于该服务器没有redhat.com的授权，它将查询传递到根服务器（“.”DNS服务器），请求解析主机名称。根名称服务器把“com”DNS服务器IP地址返回给本地DNS服务器（迭代查询）。3）本地DNS服务器将请求发给“com”DNS服务器，该服务器根据请求将“redhat.com”DNS服务器IP地址返回给本地DNS服务器（迭代查询）。4）本地DNS服务器向“redhat.com”DNS服务器发送请求，由于该服务器具有“www.redhat.com”记录，它将www.redhat.com的IP地址返回给本地DNS服务器。5）本地DNS服务器将www.redhat.com的IP地址发送给客户端。 FTP数据流、控制流：端口20用于在客户端和服务器之间传输数据流，而端口21用于传输控制流 两种工作模式：PASV+PORT 1、主动FTP：命令连接：客户端 &gt;1024端口 -&gt; 服务器 21端口数据连接：客户端 &gt;1024端口 1024端口 -&gt; 服务器 21端口 数据连接：客户端 &gt;1024端口 -&gt; 服务器 &gt;1024端口 我自己的理解是主动模式的话，客户端随意起一个大于1024端口去连服务器的21端口，然后告诉服务器我已经准备好数据连接了，你过来连我的数据端口吧，然后服务器用自己的20端口去连客户端的端口，注意此时客户端其实为了响应，是随意启用了一个自己不用的端口，即大于1024的端口。 被动模式：从头到尾都是客户端去连服务器，服务器一直处于响应状态。客户端打开两个大于1024的端口，然后第一个端口去连服务器的21号端口，告诉服务器：“你准备好了吗？我要向你传输数据了。然后服务器说我好了，客户端用自己事先开好的第二个端口去连接服务器，注意此时服务器的数据端口已经不是20了，服务器为了响应请求，随机开了一个大于1024端口(https://blog.51cto.com/9237101/1911032) FTP指令和响应码FTP断电续传、匿名ftp HTTP报文格式：请求报文、响应报文、请求头各种字段、响应头各种字段http状态码 HTTPS详细握手摘要算法、数字签名、数字证书]]></content>
      <tags>
        <tag>Computer Network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go基础]]></title>
    <url>%2Fblog%2F2020%2F07%2F21%2Fgo%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[go programming 基础 Why go1.Code run fast2.Garbage collection3.Simpler objects4.Concurrency is efficient Software Translation machine language: CPU instructions represented in binary Assembly language: CPU ~ with mnemonics (easier to read) High level language CompilationTranslate instructions while code is executed C++, C, Java (compiler) Translation occurs once Java(compiled to bytecode then be interpreted), Python (interpreter) Translation occurs every execution ObjectsGo is weakly OOP language Go use structs instead of class No contructor, generics and inheritance ConcurrencyPerformance Limits:Moore’s LawMore transistors used to lead to higher clock frequenciesPower/temperature constraints ParallelismGPU thounsands of cores Concurrency is the management of multiple tasks at the same time Key requirement for large systems Concurrent programming enables parallelism-&gt; Management of task execution-&gt; Communication between tasks-&gt; Synchronization between tasks Go includes concurrency primitivesGoroutines represent concurrent tasksChannels are used to communicate between tasksSelect enables task sysnchronizationConcurrency primitives are efficient and easy to use InstallationPackage Main12345package mainimport "fmt"func main()&#123; fmt.Printf("hellow world\n")&#125; Commands: go build - compiles the program to .exe file go doc print documentation go fmt format indentation go get package go run go test Variablevar x int = 100var x, y int = 100 var x = 100 (auto infer) x := 100 Define and alias for a typetype Celsius float64type IDnum int PointerA pointer is an address to data in memory &amp; returns the address of a variable/function * operator returns the data at the address123456var x int = 1var y intvar ip *intip = &amp;xy = *ip New new() function creates a variable and returns a pointer to the variable12ptr := new(int)*ptr = 3 1fmt.Printf("Hi %s", x) x = int32(y) String PackageCompareTo(a, b) Contains(s, substr) HasPrefix(s, prefix) Index(s, substr) Replace(s, old, new, n) ToLower(s) TrimSpace(s) returns a new string Strconv PackageAtoi(s) -converts string s to int Itoa(s) -convert int to string FormatFloat(f, fmt,prec, bitSize) - convert flot to string ParseFloat(s, bitSize) - Converts a string to a floating point number Constants Expression whose value is known at compile time Type is inferred from righthand side (boolean, string number)12345const x = 1.3const( y=4 z="Hi") iota (like enumerate) generate a set of related but distinct constants Ofter represents a property which has several distinct values123456789101112131415161718type Grades intconst( A Grade = iota // 0 B // 1 C // 2 D F)type Allergen intconst ( IgEggs Allergen = 1 &lt;&lt; iota // 1 &lt;&lt; 0 which is 00000001 IgChocolate // 1 &lt;&lt; 1 which is 00000010 IgNuts // 1 &lt;&lt; 2 which is 00000100 IgStrawberries // 1 &lt;&lt; 3 which is 00001000 IgShellfish // 1 &lt;&lt; 4 which is 00010000) Control flow123if x &gt; 5&#123; fmt.Printf("aa")&#125; 123for i:=0; i&lt;10; i++&#123;&#125; 12345678switch x&#123; case 1: fmt.Printf("") case 2: fmt.Printf("") default: fmt.Printf("nocase") // auto break&#125; Scan Scan reads user input Takes a pointer as an argument Typed data is written to pointer Returns number of scanned item 12345var appleNum intfmt.Printf("Number of apples?")num, err := fmt.scan(&amp;appleNum)fmt.Printf(appleNum) Composite Data typesArrays: fixed length12345678910var x [5]intx[0] = 2var x [5]int = [5]&#123;1,2,3,4,5&#125;x:=[...]int&#123;1, 2, 3, 4&#125; // infers size from number of initializersfor i, v := range x&#123; fmt.Printf("ind %d, val %d", i, v)&#125; Slices A “window” on an underlying array Variable size, up to the whole array Pointer indicates the start of the slice Length Capacity is the max number of elts(elements) 1234arr := [...]string&#123;"a", "b", "c", "d", "e", "f", "g"&#125;s1:=arr[1:3]s2:=arr[2:5]fmt.Printf(len(s1), cap(s))// 3 7 1sli := []int&#123;1,2,3&#125; // this is a slice because no ... or number in the bracket init a slice directly make() 123sli := make([]int, 10) // 10 is the lengthsli := make([]int, 10, 15) // 15 is the capacity append() 1sli = append(sli, 100) Maps Implementation of a hash map 123456789101112131415161718var idMap map[string][int]idMap = make(map[string]int)idMap := map[string]int&#123; "joe": 123&#125;idMap["joe"] = 456delete(idMap, "joe")id, p := idMap["joe"] // id is value, p is True/False the key in the maplen(idMap)for key, val := range idMap&#123; fmt.Println(key, val)&#125; structsPerson StructName, Address, phone 12345678910111213141516type struct Person&#123; name string addr string phone string&#125;var p1 Person// dot notation to access struct fieldsp1.name = "joe"x1 = p1.addr// init a structp1 := new(Person)p1 := Person(name: "joe", addr: "a st.", phone: "123") Protocols and Format Request for Comments (RFC) Definition of Internet protocols and formate.g. HTML Hypertext Markup Language URI Uniform Resource Identifier HTTP Hypertext Transfer Protocol 12345import "net/http"http.Get(www.baidu.com)import "net"net.Dial("tcp", "uci.edu:80") //make a tcp connect with the url JSONJavaScript Object Notation Go structp1 := Person(name:”joe”, addr: “a st.”) equivalent JSON object{“name”:”jow, “addr”:”a st.”} 12345p1 := Person(name:"joe", addr:"aaa")barr, err:=json.Marshal(p1)var p2 Personerr := json.Unmarshal(barr, &amp;p2) Marshal() returns JSON representation as []byte Unmarschal() pointer passed to GO object and object must fit JSON []byte Files (Read, Write) Linear access, not random access Open, Read, write close seek(move read/write head) ioutil File Read 123456dat, e := ioutil.ReadFile("test.txt") // content, error// Explicit open/close are not needed// Large files cause a problem (in RAM)dat = "JoJO"err:= ioutil.WriteFile("out.txt", dat, 0777) // permission os.Open() os.Close() os.Read() reads from a file into byte[] os.Write() 1234f, err := os.Open("dt.txt")barr :=make([]byte, 10) // read 10 bytenb, err := f.Read(barr)f.Close() 12345f, err := os.Create("outfile.txt")barr:=[]byte&#123;1,2,3&#125;nb,err:=f.Write(barr) // write any unicode sequencenb,err:=f.WriteString("Hi") Functions123func main()&#123; fmt.Printf("Helllo, world.") // main function called automatically&#125; Abstraction is hiding details that are less important Call by Reference12345678func foo(y *int)&#123; *y = *y + 1&#125;func main()&#123; x:=2 foo(&amp;x)&#125; pros: copying time(no need to pass a whole array)cons: data encapsulation Passing Array Arguments1234567891011121314151617181920212223242526272829func foo(x [3]int) int&#123; return x[0]&#125;func main()&#123; a:=[3]int&#123;1,2,3&#125; fmt.Print(foo(a))&#125;// modify by passing array pointers (messy and unnecessary)func foo(x *[3]int)int&#123; (*x)[0] = (*x)[0] + 1&#125;func main()&#123; a:=[3]int&#123;1,2,3&#125; foo(&amp;a) fmt.Print(a)&#125;// using slices in go!!!func foo(sli []) int&#123; sli[0] = sli[0] +1&#125;func main()&#123; a := []int&#123;1,2,3&#125; // no size foo(a) fmt.Print(a)&#125; First-Class Values Functions can be treated like other types Variables can be declared as a func 12345678910var funcVar func(int) intfunc incFn(x int) int&#123; return x+1&#125;func main()&#123; funcVar = incFn fmt.Print(funcVar(1))&#125; Functions as Arguments 123func applyIt(afunct func(int) int, val int) int&#123; return afunct(val)&#125; Anonymous Functions 12345678func applyIt(afunct func(int) int, val int) int&#123; return afunct(val)&#125;func main()&#123; v:= applyIt(func (x int) int &#123;return x+1&#125;, 2) fmt.Println(v)&#125; Function Defines a Functionex: compute the distance between a point to a origin (variable) 1234567891011121314func MakeDistOrigin(o_x, o_y float64) // 参数类型 func(float64, float64) float64&#123; // 返回类型是一个函数 fn := func(x, y float64) float64&#123; return math.Sqrt(math.Pow(x-o_x, 2) + math.Pow(y-o_y, 2)) &#125; return fn&#125;func main()&#123; Dist1 := MakeDistOrigin(0,0) // return a function which can compute the distance from given point to (0,0) Dist2 := MakeDistOrigin(2,2) fmt.Println(Dist1(2,2)) fmt.Println(Dist2(2,2))&#125; environment along with a function Closure function + its environment when functions are passed/ returned, their environment comes with them in the previous exampleo_x, o_y are the environment 闭包的好处 希望一个变量长期保存内存中 避免全局变量污染 私有成员的存在。 12345678910111213141516171819// 拍卖func makeComparePrice() func(float64) float64 &#123; // 返回类型是一个函数,指定这个函数的参数类型和返回类型 o_price := 5.0 // := 是申明新的变量并赋值 fn := func(price float64) float64 &#123; if o_price &lt; price &#123; o_price = price // =是改变原来的o_price,这里不能使用o_price := price这样就是新的一个o_price &#125; return o_price &#125; return fn&#125;func main() &#123; comparePrice := makeComparePrice() fmt.Println(comparePrice(4)) // 5 fmt.Println(comparePrice(6)) // 6 fmt.Println(comparePrice(980.424)) // 980.424 fmt.Println(comparePrice(1.23)) // 980.424&#125; Variadic and Deferred variable argument number 123456789101112131415func getMax(val ...int) int&#123; maxV := -1 for _, v := range vals&#123; if v&gt;maxV&#123; maxV = V &#125; &#125; return maxV&#125;func main()&#123; fmt.Println(getMax(1,3,6,4)) vslice := []int&#123;1,3,6,4&#125; fmt.Println(getMax(vslice...))&#125; defer calling function 123456func main()&#123; i:=1 defer fmt.Prinln(i+1) // 2 i++ fmt.Println("Hello"!)&#125; Classes and EncapsulationEncapsulation data can be protected from the programmer data can be accessed by only methods Associating Methods with Data Method has a receiver type that it is associated with Use dot notation to call the method 12345678910type MyInt intfunc (mi MyInt) Double() int&#123; // MyInt is the receiver type, this type has a method named Double(), we can call it by dot notation return int(mi*2)&#125;func main()&#123; v:=MyInt(3) fmt.Println(v.Double())&#125; use struct12345678910111213141516//Point typetype Point struct&#123; x float64 y float64&#125;// 为Point类定义一个方法func (p Point) DistToOrig()&#123; t := math.Pow(p.x, 2) + math.Pow(p.y,2) return math.Sqrt(t)&#125;func main()&#123; p1 := Point(3,4) fmt.Println(p1.DistToOrig())&#125; Controlling Access123456789package datavar x int = 1func PrintX()&#123;fmt.Println(x)&#125;package mainimport "data"func main()&#123; data.PrintX()&#125; Controlling Access to Structs12345678910111213141516171819202122package datatype Point struct&#123; x float64 y float64&#125;func (p *Point) InitMe(xn, yn float64)&#123; p.x = xn p.y = yn&#125;func (p *Point) Scale(v float64)&#123; p.x = p.x* v p.y = p.y* v&#125;package mainfunc main()&#123; var p data.Point p.InitMe(2,3) p.Scale(2)&#125; 1234567891011121314151617// wrong, just the copy, do not change x coord at allfunc main()&#123; p1 := Point(3, 4) p1.OffsetX(5)&#125;// large receiver!!type Image [100][100] intfunc main()&#123; i1:= GrabImage() il.BlurImage() // 10000 ints copied to BlurImage()&#125;// 正确func(p *Point) Offset(v float64)&#123; p.x = p.x + v&#125; Polymorphism Ability for an object to have different forms depending on the context OverridingSubclass redefines a method inherited from the superclass -polumorphic Interfaces Name, parameters, return values Implementation is NOT defined Satisfying an Interfaceimplement all the methods(similar to inheritance with overriding) additional functions permitted 123456789type Shape2D interface&#123; Area() float64 Perimeter() float64&#125;type Triangle&#123;...&#125;func(t Triangle) Area() float64&#123;...&#125; // match to the func in Shape2D interface automaticallyfunc(t Triangle) Perimeter float64&#123;...&#125; Concrete vs Interface Types(data &amp; methods) vs (methods) 1234567891011121314151617type Speaker interface &#123;Speak()&#125;type Dog struct &#123;name string&#125;// 实现Speaker里的Speak函数，无需指定Speaker名。有一个associated type是实现类型Dog// x相当于Dog实现了Speaker的Speak函数func (d Dog) Speak()&#123; fmt.Println(d.name)&#125;func main()&#123; var s1 Speaker var d1 Dog&#123;"Brian"&#125; s1 = d1 s1.Speak()&#125; // var d1 *Dog //legal, d1 has no concrete value, ca still call the Speak()1234567891011func (d*Dog) Speak()&#123; if d == nil&#123; fmt.Println("&lt;noise&gt;") &#125; else&#123; fmt.Println(d.name) &#125;&#125;var s1 Speakervar d1 *Dogs1 = d1s1.Speak() 12345678910111213141516171819202122232425262728293031// 任意实现Shape2D的图形都可以用func FitInYard(s Shape2D) bool&#123; if(s.Area()&gt;100 &amp;&amp; s.Perimeter()&gt;100)&#123; return true &#125; return False&#125;// 不同图Type不同功能func DrawRect(r Rectangle)&#123;...&#125;func DrawTriangle(t Triangle)&#123;...&#125;func DrawShape(s Shape2D) bool&#123; // rect, ok:= s.(Rectangle) // if ok&#123; // DrawRect(rect) // &#125; // tri, ok:= s.(Triangle) // if ok&#123; // DrawTriangle(tri) // &#125; switch:=sh:=s.(type)&#123; case Rectangle: DrawRect(sh) case Triangle: DrawTriangle(tri) &#125;&#125; Error Interface12345678910type error interface&#123; Error() string&#125;// Handling Errorsf, err := os.Open("/harris/test.txt")if err != nil&#123; fmt.Println(err) return&#125; Why use concurrency Parallel ExecutionTwo programs execute in parallel if they execute at exactly the same time. (At time t, an instruction is being performed for both P! and P2) CPU1, CPU2 Von Neumann Bottlenecka limitation on throughput on personal computerWith the processing becoming faster for processors, the memory transfer rates meet a limitation. To solve that:Cache, Prefetching, Multithreading, DDR SDRAM P = alpha * CFV^2 alpha is percent of time switchingC is capacitanceF is the clock frequencyV is voltage swing Other concurrent tasks can operate while one task is waiting Processes vs. Threads Threads share some context Many threads can exist in one process Goroutines Like a thread in Go Many Goroutines execute within a single OS thread switch the go routines like threads Interleaving Order of execution within a task is unknown Order of execution between concurrent tasks is unknown Interleaving of instructions between tasks is unknown WebThreads are largely independent but not completely independent (some communication between)Web server, one thread per client Image processingblur the pixels1 thread per pixel block (GPU does) some pixel values are shared between the neighbors Create a Goroutine One goroutine is created automatically to execute the main() Other goroutines are created using the go keyword 123a = 1go foo() // 使用go关键词, Main goroutine 不会blocka = 2 when the main goroutine end, all other goroutines will exit Exit goroutinesEarly Exit1234func main()&#123; go fmt.Printf("New routine") fmt.Printf("Main routine")&#125; Only “Main routine” is printed because Main finished before the new goroutine started. Delayed Exit12345func main()&#123; go fmt.Printf("New routine") time.Sleep(100 * time.Millisecond) // Adding a delay to wait is bad because assumptions may be wrong fmt.Printf("Main routine")&#125; Synchronization Using global events whose execution is viewed by all threads, simultaneously GLOBAL EVENT is viewed by all tasks at the same time 123456x = 1x = x+1GLOBAL EVENTif GLOBAL EVENT // x has been updated print x Wait groups Sync package contains functions to synchronize between goroutines sync.WaitGroup forces a goroutine to wait for other goroutines contains an internal counter increment counter for each goroutine to wait for decrement counter when each goroutine completes Waiting goroutine cannot continue until counter is 0 Using waitgroup Add() increments the counterDone() decrements the counterWait() blocks until counter == 0 1234567var wg sync.WaitGroupwg.Add(1)go foo(&amp;wg)wg.Wait() // wait on one thread// 在foo里wg.Done() 123456789101112func foo(wg *sync.WaitGroup)&#123; fmt.Printf("New routine") wg.Done()&#125;func main()&#123; var wg sync.WaitGroup wg.Add(1) go foo (&amp;wg) // 传递引用，免得copy一大堆过去 wg.Wait() fmt.Printf("Main routine")&#125; Channels Transfer data between goroutines Channels are typed Use make() to create a channelc:=make(chan int) send and receive data usign the &lt;- Send data on a channelc&lt;-3 receive data from a channelx := &lt;- c 123456789101112func prod(v1 int, v2 int, c chan int)&#123; c &lt;- v1 * v2&#125;func main()&#123; c := make(chan int) go prod(1, 2, c) go prod(3, 4, c) // In the same channel c a:= &lt;-c b:=&lt;-c fmt.Println(a*b)&#125; cache 是为了弥补高速设备和低速设备的鸿沟而引入的中间层，最终起到加快访问速度的作用。 而 buffer 的主要目的进行流量整形，把突发的大数量较小规模的 I/O 整理成平稳的小数量较大规模的 I/O，以减少响应次数 Unbuffered Channel cannot hold datta in transitSendind blocks until data is receivedReceiving blocks until data is sent 1234567Task 1c &lt;- 3 // no buffer, has to wait for task 2 to receiveOne hour laterTask 2x := &lt;- c // wait task 1 to send So a Wait() should be here Channel Capacity channels can obtain a limited number of objects Capacity is the number of objects it can hold in transit c:=make(chan int, 3) Sending only blocks if buffer is full receiving only blocks if buffer is empty 生产者线程-&gt;有限的缓冲区-&gt;消费者线程 在缓冲区为空时，消费者不能再消费 缓冲区满时，生产者不能再进行生产 Iterate through a channel123for i:= range c&#123; // i is the read value fmt.Println(i)&#125; iterates when sender calls close(c) Receiving from Multiple Goroutines Multiple channels may be used to receive from multiple sources Select Statement May have a choice of which data to use-First come First served use the select statement to wait on the first data from a set of channels 1234567// 只选第一个select&#123; case a = &lt;- c1: fmt.Println(a) case b = &lt;- c2: fmt.Println(b)&#125; 123456select&#123; case a = &lt;- inchan: fmt.Println("Received a") case b = &lt;- outchan: fmt.Println("Send b")&#125; Select with an Abort Channel Producer-consumer12345678for&#123; //infinite for loop keep receiving select&#123; case a &lt;- c: fmt.Println(a) // keep receivinf and processing case &lt;-abort: // abort channel maybe enter quit, 如果有东西到abort channel上了，就会return return &#125;&#125; 12345678select&#123; case a=&lt;-c1: // case b=&lt;-c2: // default: // default case do not block //&#125; Mutual ExclusionTwo goroutines write to a shared variable can interfere with each other. 12345678910111213141516var i int = 0var wg sync.WaitGroupfunc inc()&#123; i = i + 1 wg.Done()&#125;// not corrent!!func main()&#123; wg.Add(2) // create 2 goroutines go inc() go inc() wg.Wait() // wait for the two routines fmt.Println(i) // i should equal 2&#125; seems no problem and i should equal 2?? Granularity of Concurrencyi = i+1 might be three machine instructionsread iincrementwrite i Interleaving machine instructions|Task 1|Task2|i||—|—|—||read i||0|||read i|0||inc||1||write i||1|||inc|1|||write i|1| Correct Sharing Don’t let 2 goroutines write to a shared variable at the same time Mutual Exclusion Sync.Mutex A Mutex ensures mutual exclusion uses a binary semaphore Flag up - shared variable is in use Flag down - shared variable is available Lock() method puts the flag up - shared variale i use Unlock() method puts the flag downWhen Unlock() is called, a Lock() can be proceed 1234567var i int = 0var mut sync.Mutexfunc inc()&#123; mut.Lock() i = i+1 mut.Unlock()&#125; Synchronous InitializationInitialization must happen once and before everything elseSync.Once Has one method, once.Do(f) Function f is executed only one time even if it is ccalled in multiple gotoutines All calls to once.Do() block until the first returns Ensures that init executes first 1234567891011121314151617181920212223var wg sync.WaitGroupfunc main()&#123; wg.Add(2) go dostuff() go dostuff() wg.Wait()&#125;var on sync.Oncefunc setup()&#123; fmt.Pringln("Init")&#125;func dostuff()&#123; on.Do(setup) fmt.Println("hello") wg.Done()&#125;//result// Init// hello// hello Deadlock example1234567891011121314func dostuff(c1 chan int, c2 chan int)&#123; &lt;- c1 c2 &lt;- 1 wg.Done()&#125;func main()&#123; ch1 := make(chan int) ch2 := make(chan int) wg.Add(2) go dostuff(ch1, ch2) go dostuff(ch2, ch1) wg.Wait()&#125; Golang detects when all goroutine are deadlocks, but cannot detect subset of goroutines are deadlocks Dining Philosophers ProblemEach chopstick is a mutexEach philosopher is associated with a goroutine and two chopsticks 123456789101112131415161718192021222324252627282930313233type ChopS struct&#123; sync.Mutex&#125;type Philo struct&#123; leftCS, rightCS *ChopS&#125;func (p Philo) eat()&#123; for&#123; // All people will lock the chopstick on their left side firstly p.leftCS.Lock() p.rightCS.Lock() fmt.Println("eating") p.rightCS.UnLock() p.leftCS.UnLock() &#125;&#125;// initCSticks := make([]*ChopS, 5)for i:=0; i&lt;5; i++&#123; CStick[i] = new(ChopS)&#125;philos := make([]*Philo, 5)for i:=0; i&lt;5; i++&#123; philos[i] = &amp;Philo&#123;CSticks[i], CSticks[(i+1)%5]&#125;&#125;// start eatingfor i:=0; i&lt;5; i++&#123; go philos[i].eat()&#125; 每个人拿最小的Solutionchange to &amp;Philo{CSticks[min(i, (i+1)%5)], CSticks[max(i, (i+1)%5)]}]]></content>
      <tags>
        <tag>Go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Internet programming]]></title>
    <url>%2Fblog%2F2019%2F10%2F14%2FInternet-programming%2F</url>
    <content type="text"><![CDATA[Internet programming 笔记 note1http: hypertext transfer protocol, the underlying protocol used by the WWW and this protocol defines how messages are formatted and transmitted, and what actions Web servers and browsers should take in response to various commands. https: http over secure session: a temporary and interactive information interchange between two or more communicating devices or between computer and user. Internet vs WWW : Internet is a global network comprised of computers( conceptualized during 1969, APRA), World Wide Web is a collection of web pages following Http that can be accessed via the Internet from any part of the world. Cookie: a small piece of data sent from a website and stored on the user’s computer by the user’s web browser. It can record user’s browsing activity and remember stateful information and arbitrary information that user entered into form fields. JSP: JSP stands for Java Server Pages, which helps developers to create dynamically web pages based on HTML, XML, or other types. Servlets: are Java programs that are already compiled which also creates dynamic web content. HTML: HyperText Markup Language, the authoring language used to create documents on the World Wide Web javascript: make web pages dynamic and interactive by implementing client-side scripts. css: Cascading Style Sheets is a language that describes the style of an HTML document.]]></content>
      <tags>
        <tag>Computer Network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Screen Design]]></title>
    <url>%2Fblog%2F2019%2F05%2F22%2FScreenDesign%2F</url>
    <content type="text"><![CDATA[A brief introduction of Screen Design Design, 50% instinct, 50% hard work. Gestalt pyschology The whole(unity) is greater than the sum of its parts.(Aristotle) Composition, Symmetry and Balance Pictures need a frame for their composition. Youe must know where is the end of the picture and where begins reality. Composition with perspective not in the middle Symmetry in the composition and in the meaning Golden section Color color palettes Grid Logo from tangram 七巧板 to logotype pictogram 象形符号 Typography Leading captical letter typographie Design Thinking]]></content>
  </entry>
  <entry>
    <title><![CDATA[DSP_SwarmIntelligence]]></title>
    <url>%2Fblog%2F2019%2F05%2F21%2FDSP-SwarmIntelligence%2F</url>
    <content type="text"><![CDATA[Swarm intelligence (SI) is the collective behavior of decentralized, self-organized systems, natural or artificial. The concept is employed in work on artificial intelligence. The expression was introduced by Gerardo Beni and Jing Wang in 1989, in the context of cellular robotic systems How can we implement the coordination among the groups? flask-&gt;waterholr-&gt;on and another predator-&gt;flask split-&gt; knowledge accumulated to concesus penguin-40 together to brook the temperaturehuddle tiny streps awayshift and rotate fro, back to frontnot let the overheat-&gt;breakdown step by step huddle after huddle mayfly flock of fish collide with predator pheromone 信息素]]></content>
  </entry>
  <entry>
    <title><![CDATA[java网络编程]]></title>
    <url>%2Fblog%2F2019%2F05%2F18%2Fjava%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[java网络编程 任务一 TCP实现逆序字符串输出 客户端想要发一行字符行给服务器端然后得到一个逆序的字符行。 SocketClient.java12345678910111213141516171819202122232425262728import java.io.BufferedReader;import java.io.IOException;import java.io.InputStreamReader;import java.io.PrintStream;import java.net.Socket;import java.net.UnknownHostException;import java.util.Scanner;public class SocketClient &#123; public static void main(String args[]) throws UnknownHostException, IOException &#123; Scanner sc = new Scanner(System.in); Socket socket = new Socket("127.0.0.1", 54321); // get input stream BufferedReader br = new BufferedReader(new InputStreamReader(socket.getInputStream())); // get output stream PrintStream ps = new PrintStream(socket.getOutputStream()); // write string into server ps.println(sc.nextLine()); // print the reversed string from server System.out.println(br.readLine()); socket.close(); &#125;&#125; SocketServer.java1234567891011121314151617181920212223242526272829303132333435import java.io.BufferedReader;import java.io.IOException;import java.io.InputStreamReader;import java.io.PrintStream;import java.net.ServerSocket;import java.net.Socket;public class SocketServer &#123; public static void main(String[] args) throws IOException &#123; ServerSocket server = new ServerSocket(54321); System.out.println("Server is on, binded to 54321 port"); while (true) &#123; final Socket socket = server.accept(); new Thread() &#123; public void run() &#123; try &#123; // get the input stream BufferedReader br = new BufferedReader(new InputStreamReader(socket.getInputStream())); PrintStream ps = new PrintStream(socket.getOutputStream()); String line = br.readLine(); line = new StringBuilder(line).reverse().toString(); ps.println(line); socket.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;.start(); &#125; &#125;&#125; 建立Socket连接 客户端Socket指定host和port，服务器Socket使用给定的ServerSocket绑定port即可再调用accept函数，当客户端运行时，会找到指定的host:port，建立和服务器的连接 通信 服务器的输入流就是客户端的输出流，反之亦然。在服务器和客户端都写一个BufferedReader（简称br）用来输入，和一个PrintStream（简称ps）用来输出。我客户端要发一个字符串，就用ps.println输出；服务器要接收就用br.readLine接收（接收就是输入流）；然后我服务器逆序一下字符串用ps输出，客户端用br再接收就是逆序的字符串了。 客户端 服务器 ps输出 -&gt; br接收 reverse字符串 br接收 &lt;- ps输出 有一个误区就是ps的println不是系统的输出，而是把这一行放到服务器和客户端的交流通道里，客户端println输出，服务器就可以用输入的方式读取了，反之亦然 任务二 UDP实现简单计算通信 使用UDP完成简单计算，比如客户端输入3*4，服务端输出12；客户端输入9/3，服务端输出3 UDPclient.java12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667import java.io.IOException;import java.net.DatagramPacket;import java.net.DatagramSocket;import java.net.InetAddress;import java.net.SocketException;import java.net.UnknownHostException;import java.util.Scanner;import java.util.regex.Matcher;import java.util.regex.Pattern;public class UDPclient &#123; public static int compute(String s) &#123; String pattern = "(\\d*)([\\+\\-\\*\\/])(\\d*)"; Pattern r = Pattern.compile(pattern); Matcher m = r.matcher(s); int consequence = 0; if(m.find())&#123; // necessary! int leftInt = Integer.parseInt(m.group(1)); char operator = m.group(2).charAt(0); int rightInt = Integer.parseInt(m.group(3)); switch(operator) &#123; case '+': consequence = leftInt + rightInt; break; // important! case '-': consequence = leftInt - rightInt; break; case '*': consequence = leftInt * rightInt; break; case '/': consequence = leftInt / rightInt; break; default: &#125; &#125; return consequence; &#125; public static void main(String[] args) &#123; try &#123; Scanner sc = new Scanner(System.in);// byte[] bytes = sc.nextLine().getBytes(); String test =sc.nextLine(); int result1 = compute(test); System.out.println((int) result1); byte[] bytes = (""+result1).getBytes(); DatagramSocket socket = new DatagramSocket(); DatagramPacket packet = new DatagramPacket(bytes, bytes.length); packet.setAddress(InetAddress.getByName("127.0.0.1")); packet.setPort(55555); socket.send(packet); &#125; catch (SocketException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; catch (UnknownHostException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; catch (IOException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; &#125; UDPserver.java1234567891011121314151617181920212223import java.io.IOException;import java.net.DatagramPacket;import java.net.DatagramSocket;import java.net.SocketException;public class UDPserver &#123; public static void main(String[] args) &#123; try &#123; byte[] buf = new byte[1024]; DatagramSocket socket = new DatagramSocket(55555); DatagramPacket packet = new DatagramPacket(buf, buf.length); socket.receive(packet); byte[] data = packet.getData(); System.out.println(new String(data, 0, data.length)); &#125; catch (SocketException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; catch (IOException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125;&#125; 我在客户端计算了result，因为UDP传递的是数据包，我们把然后把这个result存放在byte数组中，再放到数据包中，用客户端socket的send发送，就可以用服务器端socket的receive接收了。可以看出，我server不用开，client也能发送，就是永远送不到server了，这就是丢包的原理。TCP则是要先建立连接，就保证了数据是能送到位的。其它UDP和TCP的区别： 1、基于连接与无连接； 2、对系统资源的要求（TCP较多，UDP少）； 3、UDP程序结构较简单； 4、流模式与数据报模式 ； 5、TCP保证数据正确性，UDP可能丢包； 6、TCP保证数据顺序，UDP不保证。 参考来源 任务三 多线程实现多客户端通信 建立25个线程，把它建立连接的时间戳、发送信息的时间戳和2秒后断开的时间戳信息，发给服务器显示。 Server.java123456789101112131415161718192021222324252627282930313233import java.io.BufferedReader;import java.io.IOException;import java.io.InputStreamReader;import java.net.ServerSocket;import java.net.Socket;public class Server &#123; public static void main(String[] args) throws IOException &#123; ServerSocket serve = new ServerSocket(54322); System.out.println("Server is on and binded to 54322 port"); while (true) &#123; final Socket socket = serve.accept(); new Thread() &#123; public void run() &#123; try &#123; BufferedReader br = new BufferedReader(new InputStreamReader(socket.getInputStream())); System.out.println(br.readLine()); // receive the timestamp info of // connection and sending infomation System.out.println(br.readLine()); // receive the timestamp info of // disconnection socket.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;.start(); &#125; &#125;&#125; MutipleClients.java12345678910111213141516171819202122232425262728293031323334353637383940import java.io.IOException;import java.io.PrintStream;import java.net.Socket;import java.sql.Timestamp;public class MutipleClients &#123; public static void main(String[] args) throws IOException &#123; for (int i = 1; i &lt;= 25; i++) &#123; new Thread() &#123; public void run() &#123; try &#123; Socket socket = new Socket("127.0.0.1", 54322); String Stamp1 = new Timestamp(System.currentTimeMillis()).toString(); Thread t = Thread.currentThread(); PrintStream ps = new PrintStream(socket.getOutputStream()); String Stamp2 = new Timestamp(System.currentTimeMillis()).toString(); ps.println("Client " + t.getId() + " connected at " + Stamp1 + " and sent timestamp " + Stamp2); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; String Stamp3 = new Timestamp(System.currentTimeMillis()).toString(); ps.println("Client " + t.getId() + " disconnected at " + Stamp3); socket.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;.start(); &#125; &#125;&#125; 一个服务器与25个客户端进行连接，需要用while(True)使之一直处于accept状态。 服务器要接收两行信息，第一行客户端发来(println)的连接与发送信息时间戳，第二行是过一段时间客户端发来的结束时间戳。 任务四 RMI实现远程方法调用 前面我们看到的都是在客户端处理好数据送给服务器，让服务器进行输出。那有什么办法在服务器上定义一些接口，然后在本地调用呢？ 这就是RMI(remote method invocation)。本地调用方法时实质上是传给服务器该方法的引用，让服务器调用该方法，然后return给本地结果。本地有stub，是远程对象在本地的代理(proxy),类似于RPC系统中的clinet stub。 RMI的实现首先要发现远程对象，那就必须要开启注册表(RTegistry)，什么是注册表？ 拿DNS来类比最为方便，DNS相当于一种注册表。它建立了IP地址和域名的对应，IP就是对远程对象的引用，域名就是远程对象的标识符。格式类似于 rmi://host:port/name。host指明注册表运行的注解，port表明接收调用的端口，name是一个标识该对象的简单名称。下面代码用LocateRegistry.createRegistry方法确定了注册表。再进行bind或rebind操作就可以连接了。 远程接口 IHello.java 1234567// define remote interfaceimport java.rmi.Remote;import java.rmi.RemoteException;public interface IHello extends Remote &#123; public int helloWorld()throws RemoteException;&#125; 实现类 Hello.java 123456789101112131415161718// define the implementation classimport java.io.Serializable;import java.rmi.RemoteException;import java.rmi.server.UnicastRemoteObject;public class Hello extends UnicastRemoteObject implements IHello&#123; private static final long serialVersionUID = 1L; private int index = 0; protected Hello() throws RemoteException&#123; &#125; @Override public int helloWorld() &#123; System.out.println("Hello!"); return ++index; &#125;&#125; 服务器端 HelloServer.java 123456789101112131415import java.rmi.registry.LocateRegistry;import java.rmi.registry.Registry;public class HelloServer &#123; public static void main(String args[]) &#123; try &#123; IHello rhello = new Hello(); Registry registry = LocateRegistry.createRegistry(8888); registry.bind("test",rhello); // in client side rmi://localhost:8888/test System.out.println("Remote Hello Object is bound succesfully!"); &#125; catch(Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 客户端 HelloClient.java 123456789101112131415import java.rmi.Naming;public class HelloClient &#123; public static void main(String args[]) &#123; try &#123; for(int i=0;i&lt;5;i++) &#123; IHello rhello = (IHello) Naming.lookup("rmi://192.168.31.102:8888/test"); System.out.println(rhello.helloWorld()); &#125; &#125;catch(Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125;]]></content>
      <tags>
        <tag>学校</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SWEII_TEST]]></title>
    <url>%2Fblog%2F2019%2F05%2F17%2FSWEII-TEST%2F</url>
    <content type="text"><![CDATA[4 types of coverage in testing branch coverage&gt;statement coverage because it can examine empty else statement]]></content>
      <tags>
        <tag>学校</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DSP_ConsistentModel_Ex]]></title>
    <url>%2Fblog%2F2019%2F05%2F17%2FDSP_ConsistenctModel%2F</url>
    <content type="text"><![CDATA[小练习 P17 VC LA a (1,0,0,0) 1.1 b (2,1,0,0) 2.1 c (3,1,0,0) 3.1 d (4,3,2,0) 6.1 e (5,5,2,2) 7.1 f (6,5,4,2) 8.1 g (7,5,4,2) 9.1 h (0,1,0,0) 1.2 i (1,2,1,0) 3.2 j (1,3,1,0) 4.2 k (1,4,1,2) 5.2 l (1,5,1,2) 6.2 m (4,6,2,4) 9.2 n (7,7,4,4) 10.2 o (1,0,1,0) 2.3 p (1,3,2,0) 5.3 q (3,3,3,0) 6.3 r (3,3,4,0) 7.3 s (1,0,0,1) 2.4 t (1,0,0,2) 3.4 u (4,3,2,3) 7.4 v (4,3,2,4) 8.4 Total/Partial order add process num the timestamp belongs]]></content>
  </entry>
  <entry>
    <title><![CDATA[Equicalence Partitioning Class]]></title>
    <url>%2Fblog%2F2019%2F05%2F02%2FEC%2F</url>
    <content type="text"><![CDATA[在软件工程中，常常遇到测试数据不完全而不能有效地测试出bug的过程，这个时候需要对所有输出进行划分，同时在边界需要格外注意，多测试几组边界值。 empty digits characters 六位id的可写成 id = {num|num = (\d){6,6}}]]></content>
  </entry>
  <entry>
    <title><![CDATA[ds5]]></title>
    <url>%2Fblog%2F2019%2F04%2F26%2Fds5%2F</url>
    <content type="text"><![CDATA[4-26笔记 7 fat client microsoft excel thin client automatioc flight check-in machine 18which is on client and which on server 27localhost：在计算机网络中，localhost（意为“本地主机”，指“这台计算机”）是给回路网络接口（loopback）的一个标准主机名，相对应的IP地址为127.0.0.1（IPv4）和[::1]（IPv6）。127.0.0.1是回送地址，指本地机。127.0.0.1是用来检测网络的自己的IP.就是说任何一台电脑来说,不管是否连接到INTERNET上,127.0.0.1对于自己来说都是自己.就是说,每台电脑都是由4位的256进制数组成的.而192.168.1.102现在是本机，但本机也可以设置成其他ip地址，但127.0.0.1一定是指本机。 JAVA client-server 简单例子Socketclient.java123456789101112131415161718192021222324252627282930import java.io.BufferedReader;import java.io.IOException;import java.io.InputStreamReader;import java.io.PrintStream;import java.net.Socket;import java.net.UnknownHostException;import java.util.Scanner;public class SocketClient &#123; public static void main(String args[]) throws UnknownHostException, IOException &#123; Scanner sc = new Scanner(System.in); Socket socket = new Socket("127.0.0.1", 54321); // get input stream BufferedReader br = new BufferedReader(new InputStreamReader(socket.getInputStream())); // get output stream PrintStream ps = new PrintStream(socket.getOutputStream()); // write string into server ps.println(sc.nextLine()); // print the reversed string from server System.out.println(br.readLine()); socket.close(); &#125;&#125;- SocketServer.java1234567891011121314151617181920212223242526272829303132333435import java.io.BufferedReader;import java.io.IOException;import java.io.InputStreamReader;import java.io.PrintStream;import java.net.ServerSocket;import java.net.Socket;public class SocketServer &#123; public static void main(String[] args) throws IOException &#123; ServerSocket server = new ServerSocket(54321); System.out.println("Server is on, binded to 54321 port"); while (true) &#123; final Socket socket = server.accept(); new Thread() &#123; public void run() &#123; try &#123; // get the input stream BufferedReader br = new BufferedReader(new InputStreamReader(socket.getInputStream())); PrintStream ps = new PrintStream(socket.getOutputStream()); String line = br.readLine(); line = new StringBuilder(line).reverse().toString(); ps.println(line); socket.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;.start(); &#125; &#125;&#125;]]></content>
      <tags>
        <tag>学校</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java基础]]></title>
    <url>%2Fblog%2F2019%2F04%2F22%2Fjava%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[JAVA 入门到放弃 Access modifiers(specifiers) in java protected 基类的 protected 成员是包内可见的，并且对子类可见； 若子类与基类不在同一包中，那么在子类中，子类实例可以访问其从基类继承而来的protected方法，而不能访问基类实例的protected方法。 detail overloadeach overloaded method must take a unique list of the argument types override（1）重写方法必须和被重写方法具有相同的参数列表（包括顺序及个数还有类型），返回类型必须和被重写方法的返回类型相同或者是返回类型的子类型。 （2）重写方法的访问控制修饰符不能比被重写方法更严格（比如一个在父类中声明为public的方法重写成一个protected的方法）。 （3）只有实例方法才能被重写，超类中的static和final方法不能被重写。 （4）重写方法不能抛出新的检查异常，或者是抛出比被重写方法声明的检查异常更广泛的检查异常。 （5）注意一种特殊情况：如果超类的方法版本中声明了检查异常，但重写的子类方法中没有声明，这时如果使用多态的方式进行调用，那么编译器认为你调用的是声明了异常的方法。 （6）尽管多态是在编译时确定对象的类型，但在编译时，还是根据父类的方法声明进行程序检查。因此，如果子类中定义的方法，在父类中没有定义，则会出项编译错误。 upcastthe act of converting a subclass reference into a baseclass reference 缺点：使用向上转型时不能调用子类特有的方法了 优点：一个父类有多个子类时，一个子类重写了许多父类的方法，可以声明一个public static函数统一对每个属于父类的子类进行操作，节省代码。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798/** * @author Spycsh * 2019-04-28 */class Car &#123; private String carDescription = "Car"; public void run() &#123; System.out.println("父类run方法"); &#125; public void speed() &#123; System.out.println("父类speed方法"); &#125; public String getDescription() &#123;return carDescription;&#125;;&#125;class Benz extends Car&#123; public void run() &#123; System.out.println("Benz:run方法"); &#125; public void speed() &#123; System.out.println("Benz:speed方法"); &#125; &#125;class BMW extends Car&#123; public void run() &#123; System.out.println("BMW:run方法"); &#125; public void speed() &#123; System.out.println("BMW:speed方法"); &#125;&#125;class Porsche extends Car&#123; private String carDescription = "Porsche is the best!"; public void run() &#123; System.out.println("Porche:run方法"); &#125; public void speed() &#123; System.out.println("Porche:speed方法"); &#125; public void price() &#123; System.out.println("Porche:price方法"); &#125; public String getDescription() &#123;return carDescription;&#125;;&#125;public class UpcastEX extends Car&#123; /** * @param car * !upcast * without upcast you need to define show method for each car brand * save code amount */ public static void show(Car car) &#123; car.run(); car.speed(); &#125; public static void showAll(Car[] e) &#123; for(Car i:e) &#123; show(i); &#125; &#125; public static void main(String[] args) &#123; Car[] carFleet = &#123; new Benz(), new BMW(), new Porsche() &#125;; showAll(carFleet); Car porsche911 = new Porsche(); //porsche911.price(); // ERROR // !cannot be implemented because of upcasting! // baseclass don`t define price()! System.out.println("test getDescription:"); // show that although upcasting, field are accessed // in subclass, not baseclass. System.out.println(porsche911.getDescription()); &#125;&#125; OUTPUT Benz:run方法 Benz:speed方法 BMW:run方法 BMW:speed方法 Porche:run方法 Porche:speed方法 test getDescription: Porsche is the best! staticstatic修饰方法 静态方法 属于类的方法 即访问它不需要实例对象就能访问 finalstatic, final修饰data static 强调只有一份，final 说明是一个常量，final定义的基本类型(primitive)的值是不可改变的，但是fianl定义的引用对象的值是可以改变的 只申明final，每次new产生不同的对象static, final一起使用时，只有一块存储地址申明static final，每次new产生相同对象 final修饰methods 把方法锁定，确保在继承中使用方法行为不变，并且不会被覆盖其二是效率，如果一个方法指明为final，就是同意编译器将针对该方法的所有调用都转为内嵌调用。 转为内嵌调用的目的是节省开销，因为编译器发现一个final方法调用命令时，会跳过程序代码这种正常方式而执行方法调用机制（将参数压入栈，跳至方法代码处并执行，然后跳回并清理栈中的参数，处理返回值），并且以方法体中的实际代码的副本来替代方法调用。但是如果一个方法很大，程序很膨胀，就会看不到内嵌带来的任何性能的提高。 final修饰类 当某个类的整体定义为final时，表明该类不能被继承，方法不能被覆盖，且final类中的所有方法都隐式指定为是final的，方法声明为final后还可以有效地“关闭”动态绑定。 Containers synchronized 修饰代码块，其他试图访问该对象的线程阻塞123synchronized(this) &#123; // 同步代码块&#125; 对象作为锁123synchronized (account) &#123; // 同步代码块&#125; 没有明确的对象作为锁1234567891011121314class Test implements Runnable&#123; private byte[] lock = new byte[0]; // 特殊的instance变量 public void method() &#123; synchronized(lock) &#123; // todo 同步代码块 &#125; &#125; public void run() &#123; &#125;&#125; 参考资料 消费者-生产者例子 lambda事件监听12345678910// 使用匿名内部类 btn.setOnAction(new EventHandler&lt;ActionEvent&gt;() &#123; @Override public void handle(ActionEvent event) &#123; System.out.println("Hello World!"); &#125; &#125;); // 或者使用 lambda expression btn.setOnAction(event -&gt; System.out.println("Hello World!")); 排序，线程，集合用法参考资料 LinkedList 和 ArrayList 区别LinkedList插入元素（任意位置只要断开链接再与新元素链接即可）很快，但访问中间元素需要从头或从尾开始遍历，很慢。ArrayList插入元素很慢，它需要更新一遍数组，但访问元素只需要给出索引，相对较快。]]></content>
  </entry>
  <entry>
    <title><![CDATA[ds4]]></title>
    <url>%2Fblog%2F2019%2F04%2F12%2Fds4%2F</url>
    <content type="text"><![CDATA[2019-04-12 笔记 File IO operation123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110import java.util.*;import java.io.*;/** * @author Spycsh ●int countLines(): count line amount of file ●void print(): * print file on command line ●void copy(String filename): copy file * content to the file ‘filename’ ●void delete(): delete the file ●void * printDirectory(): prints the file directory ●List&lt;String&gt; * getOtherFiles(): returns list of other files in same directory as * file Addtionally, create a test class which demonstrates the * functionality of your IOFile class! */public class FileIo &#123; private String fileName; FileIo(String fileName) &#123; this.fileName = fileName; &#125; int countLines() throws FileNotFoundException &#123; int lineNum = 1; File file = new File(this.fileName); FileReader fr = new FileReader(file); char[] a = new char[500]; try &#123; fr.read(a); &#125; catch (IOException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; for (char c : a) &#123; if (c == '\n') lineNum += 1; &#125; return lineNum; &#125; void print() throws FileNotFoundException &#123; File file = new File(this.fileName); FileReader fr = new FileReader(file); char[] a = new char[500]; try &#123; fr.read(a); &#125; catch (IOException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; for (char c : a) &#123; System.out.print(c); &#125; &#125; void copy(String filename) throws IOException &#123; // create a new destination file with the filename File copyfile = new File(filename); copyfile.createNewFile(); FileWriter fw = new FileWriter(copyfile); // Read the source file File sourcefile = new File(this.fileName); FileReader fr = new FileReader(sourcefile); char[] a = new char[500]; try &#123; fr.read(a); &#125; catch (IOException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; for (char c : a) &#123; fw.write(c); &#125; fr.close(); fw.close(); &#125; void delete() &#123; File file = new File(this.fileName); file.delete(); if (file.exists() == true) &#123; System.out.println("delete fail!"); &#125; else &#123; System.out.println("delete success!"); &#125; &#125; void printDirectory() &#123; File file = new File(this.fileName); System.out.println(file.getParent()); &#125; List&lt;String&gt; getOtherFiles() &#123; List&lt;String&gt; anotherFile = new ArrayList&lt;String&gt;(); // first we should get the directory File file = new File(this.fileName); String directoryStr = file.getParent(); File directory = new File(directoryStr); String[] allfile = directory.list(); for (String f : allfile) &#123; // filter given file // We should use equals rather than == // because we just need to filter // by comparing content if (!f.equals(file.getName())) anotherFile.add(f); &#125; return anotherFile; &#125;&#125;]]></content>
      <tags>
        <tag>学校</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SWE]]></title>
    <url>%2Fblog%2F2019%2F04%2F11%2FSWE%2F</url>
    <content type="text"><![CDATA[2019-04-09 笔记 14 Social acceptability: base on culture and region SWING123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172import javax.swing.*;import java.awt.*;import java.awt.event.ActionEvent;import java.awt.event.ActionListener;import javax.swing.event.ChangeEvent;import javax.swing.event.ChangeListener;import javafx.scene.control.Button;import javafx.scene.control.CheckBox;import java.util.*;/** * @author Spycsh * */public class FruitHodgepodge &#123; public static void main(String[] args) &#123; JFrame f = new JFrame(); f.setSize(600, 400); f.setTitle("FruitOrder"); JPanel panel = new JPanel(); Set&lt;String&gt; allFruitList = new HashSet&lt;String&gt;(); // display all fruit choosed f.getContentPane().setLayout(new FlowLayout());// f.add("Nor", new Button("Nor")); LinkedList&lt;String&gt; boxList = new LinkedList&lt;String&gt;(); Collections.addAll(boxList, "apple banana kiwi orange melon grape".split(" ")); JCheckBox[] cbs = new JCheckBox[boxList.size()]; for (int i = 0; i &lt; boxList.size(); i++) &#123; JCheckBox cb = cbs[i] = new JCheckBox(boxList.get(i)); cb.addChangeListener(new ChangeListener() &#123; @Override public void stateChanged(ChangeEvent e) &#123; // get the event source( checkbox itself) JCheckBox checkBox = (JCheckBox) e.getSource(); System.out.println(checkBox.getText() + " 是否选中: " + checkBox.isSelected()); if (checkBox.isSelected()) allFruitList.add(checkBox.getText()); else allFruitList.remove(checkBox.getText()); System.out.println(allFruitList); &#125; &#125;); panel.add(cb); &#125; JButton btn = new JButton(); btn.setText("Display the order!"); btn.addActionListener(new ActionListener() &#123; @Override public void actionPerformed(ActionEvent e) &#123; JOptionPane testOpt = new JOptionPane(); testOpt.showMessageDialog(new JFrame(), "Your oder:" + "\n" + allFruitList); &#125; &#125;); panel.add(btn); f.setContentPane(panel); // f.setVisible(true); &#125;&#125; JAVAFX123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115package application;/** * @author Spycsh * Main window: user can choose from 6 different fruits * After confirming the choice of fruits another window will pop up and tell the user the choice of fruits */import javafx.application.Application;import javafx.stage.Stage;import javafx.scene.Scene;import javafx.scene.layout.BorderPane;import javafx.scene.Group;import javafx.scene.control.CheckBox;import javafx.beans.value.ChangeListener;import javafx.beans.value.ObservableValue;import javafx.scene.layout.GridPane;import javafx.scene.control.Button;import javafx.event.ActionEvent;import javafx.event.EventHandler;import javafx.scene.text.Text;import java.util.*;import java.util.regex.*;public class FruitHodgepodge extends Application &#123; @Override public void start(Stage primaryStage) &#123; try &#123; BorderPane root = new BorderPane(); GridPane gp = new GridPane(); Scene scene = new Scene(gp, 500, 300); LinkedList&lt;String&gt; boxList = new LinkedList&lt;String&gt;(); Collections.addAll(boxList, "apple banana kiwi orange melon grape".split(" ")); CheckBox[] cbs = new CheckBox[boxList.size()]; LinkedList&lt;String&gt; allFruitList = new LinkedList&lt;String&gt;(); // display all fruit choosed // final CheckBox cb; for (int i = 0; i &lt; boxList.size(); i++) &#123;// cbs[i] = boxList.poll(); CheckBox cb = cbs[i] = new CheckBox(boxList.get(i));// final CheckBox cb0 = new CheckBox("checkBox");// final CheckBox cb1 = new CheckBox("aa"); cb.selectedProperty().addListener(new ChangeListener&lt;Boolean&gt;() &#123; public void changed(ObservableValue&lt;? extends Boolean&gt; ov, Boolean old_val, Boolean new_val) &#123;// System.out.println(cb.isSelected());&#125; if (new_val) &#123; allFruitList.offer(cb.getText()); &#125; else &#123; allFruitList.remove(cb.getText()); &#125; System.out.println(allFruitList); &#125; &#125;); gp.add(cb, 0, i); &#125; Button btn = new Button(); btn.setText("Display the order!"); btn.setOnAction(new EventHandler&lt;ActionEvent&gt;() &#123; @Override public void handle(ActionEvent event) &#123; Group root = new Group(); Scene scene = new Scene(root, 300, 250);// Stage stg = new Stage();// System.out.println((String)allFruitList.toString());// Pattern pattern = Pattern.compile("'(\\D+)'");// String i = (String)allFruitList.toString();// Matcher m = pattern.matcher(i);// if (m.find())&#123;// Text text = new Text(100, 100, m.group(1));// root.getChildren().add(text);// &#125;// String[] arr = allFruitList.toString().split("'"); System.out.println(); String orderString = new String(); for (String s : allFruitList) &#123; orderString += s + "\n"; &#125; Text text = new Text(100, 100, "final order:" + "\n" + orderString); root.getChildren().add(text); primaryStage.setScene(scene); primaryStage.show(); &#125; &#125;); gp.add(btn, 10, 0); // place the button scene.getStylesheets().add(getClass().getResource("application.css").toExternalForm()); primaryStage.setScene(scene); primaryStage.show(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; public static void main(String[] args) &#123; launch(args); &#125;&#125;]]></content>
      <tags>
        <tag>学校</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ds3h]]></title>
    <url>%2Fblog%2F2019%2F04%2F09%2Fds3h%2F</url>
    <content type="text"><![CDATA[2019-04-09 笔记 P16 What does a ds do? share hardwares, software and data let computers coordinate and synchronize offer users an integrated computing facility not limited by location P17 What is the essetial part? auto scaling &amp; load balance 城市规划例子,when a computer is broken, it will be slower for the system implementation because of the boundary computation which counts on the coordinations one and another computers, so as for synchronization the system have to wait for the slowest computer, with heavier load than others, to process. P18 (b) filters the redundant info and ensure the useful info procured to minimum. (b) will have a higher speed of response. P26 What is Mobility Transparency? eg. Stream serialize deserialize]]></content>
      <tags>
        <tag>学校</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[eigen-everthing]]></title>
    <url>%2Fblog%2F2019%2F04%2F08%2Feigen-everthing%2F</url>
    <content type="text"><![CDATA[brief introduction of eigenvalue and eigenvector in linear algebra determinant 行列式 eigenvalue特征值/eigenvector特征向量/eigenspace特征空间(all of the eigenvectors that correspond the eigrnvalue) null space nontrival]]></content>
      <tags>
        <tag>Math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ds2]]></title>
    <url>%2Fblog%2F2019%2F04%2F05%2Fds2%2F</url>
    <content type="text"><![CDATA[2019-04-05 笔记 make every attribute private and Use getter and setter to access them Communication of DS synchronous: The sender may block activity until acknowledgement from receiver big-endian大端法 small-endian小端法 ASCII, Unicode external data representation and marshalling alternative method Streamsnote transforming in bytes and characters encoded in unicode, must be 2 bytes not 1 class Employee implements Serializable(In China)-&gt; Seralization-&gt;deserialization-&gt;class Employee(In luebeck) 例子说明：建立一个Student类，把它用Stream的方式serialize再deserialize,从而实现信息的传输。 定义Student类1234567891011121314151617import java.io.*;public class Student implements Serializable &#123; private static final long serialVersionUID = 1L; private int studentNumber; private String degreeCourse; Student(int studentNumber, String degreeCourse) &#123; this.studentNumber = studentNumber; this.degreeCourse = degreeCourse; &#125; @Override public String toString() &#123; return "studentNumber:" + studentNumber + " " + "degreeCourse:" + degreeCourse; &#125;&#125; serialize过程12345678910111213141516import java.io.ObjectOutputStream;import java.io.FileOutputStream;import java.io.IOException;public class TestSerializing &#123; public static void main(String[] args) throws IOException &#123; FileOutputStream fos = new FileOutputStream("test"); ObjectOutputStream oos = new ObjectOutputStream(fos); Student chen = new Student(12, "ITB"); oos.writeObject(chen); oos.close(); fos.close(); &#125;&#125; deserialize过程12345678910111213141516171819import java.io.*;public class TestDeserialize &#123; public static void main(String[] args) throws IOException, ClassNotFoundException &#123; FileInputStream fos = new FileInputStream("test"); ObjectInputStream oos = new ObjectInputStream(fos); Student aStudent = null; try &#123; aStudent = (Student) oos.readObject(); &#125; catch (ClassNotFoundException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; System.out.println(aStudent.toString()); oos.close(); fos.close(); &#125;&#125; 结果test文件中显示乱码，是serialize后的字符流deserialize后通过自己定义的toString打印可以输出原来的信息 疑难 test文件建在项目文件夹而不是src文件夹下 使用ObjectInputStream反序列化的时候，ObjeectInputStream会先读取文件中的serialVersionUID，然后与本地的class文件的serialVersionUID进行对比，如果这两个id不一致，反序列则失败 因此在Student class中定义 1private static final long serialVersionUID = 1L; 即可 参考资料Source]]></content>
      <tags>
        <tag>学校</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Eclipse 高效代码]]></title>
    <url>%2Fblog%2F2019%2F04%2F04%2FEclipse%E7%AE%80%E6%B4%81%E4%BB%A3%E7%A0%81%2F</url>
    <content type="text"><![CDATA[Eclipse use &amp; code convention Eclipse use项目导出压缩包File-&gt;Export-&gt;General-&gt;选择要压缩的类型 修改缩进等格式(CTRL+SHIFT+F)选中代码-&gt;Source-&gt;Format 添加javadoc注释（ALT+SHIFT+J)选中元素-&gt;Source-&gt;Generate Element Comment 改名(ALT+SHIFT+R)选中需要改名的元素-&gt;右键Refactor-&gt;Rename.将会修改文件中所有有这个名字的元素 生成javadoccode conventionjava code convention Javadoc comment Header/Classes Functions Name Package: student Class&amp;Inteface: Student variable&amp;method: inputFileSize constant:MAXWEIGHT Layout/indentation Space]]></content>
      <tags>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Information about application for master degree]]></title>
    <url>%2Fblog%2F2019%2F03%2F19%2FMaster%2F</url>
    <content type="text"><![CDATA[德电160硕士申请 德国信息表 大学名 相关专业名称 地点 绩点要求 托福/GRE要求 申请截止日期 评价 亚琛工业大学 Media Infomatics（多媒体信息） 波恩&amp;亚琛 托福90 3.1 EE,IT,CE 托福90 GREverbal超过%15，quantitive超过%75 Dortmund 大学 机器人自动化 Dortmund 80 3.31 机器人研究方面很强 慕尼黑工业大学 ECE 慕尼黑 3.5+ 88 斯图加特大学 infomation technology 官网 DAAD网址 Stuttgart 70%ofbest-on-scale, e.g.70%/100%; 2.8/4; 2.5/1.0 (for German Marks) 托福80 2.15 EU citizens do not pay tuition, whereas non-EU citizens pay a tuition of 1,500 EUR per semester.（有学费要求） Computer Science 官网 DAAD网址 无 托福80 2.15（winter semester） 6.15(summer semester) Bachelor’s degree with a programme duration of at least six semesters in computer science, software engineering, or in a closely related subject(专业匹配度可能较低)EU citizens do not pay tuition, whereas non-EU citizens pay a tuition of 1,500 EUR per semester.（有学费要求） Saarland University萨尔大学 Saarbrücken Graduate School of Computer Science Saarbrücken 75%以上 推荐GRE，托福95/120 11/15；根据专业 不用学费，强在：马普所，视觉信息但毕业很难，挂科率极高 Saarland University萨尔大学DAAD网址 Visual Computing (MSc) Saarland University萨尔大学 Embedded Systems (MSc) Saarland University萨尔大学 Mathematics and Computer Science (MSc) Saarland University萨尔大学 Computer Science (MSc) KIT EEM,FE,MPD,MSEM,POM,ISEM Karlsruhe 托福90 1/15 30000欧 基本简介学校概览 11所精英大学 理工类3所（慕尼黑工业大学、德累斯顿工业大学、亚琛工业大学），文理类8所（海德堡大学、 柏林自由大学、柏林洪堡大学、慕尼黑大学、图宾根大学、康斯坦茨大学、科隆大学、不莱梅大学） 大学名称对应 TU9 九所德国大学，包括亚琛工业大学RWTH Aachen, 柏林工业大学TU Berlin, 不伦瑞克工业大学TU Braunschweig, 达姆施达特工业大学TU Darmstadt, 德累斯顿工业大学TU Dresden, 莱布尼茨-汉诺威大学Leibniz Universität Hannover, 卡尔斯鲁厄理工学院Karlsruher Institut für Technologie, 慕尼黑工业大学TU München, 斯图加特大学Universität Stuttgart。九所大学都是1900年之前成立的理工高校。 TU9联盟主席Ernst Schmachtenberg博士教授指出，”TU9理工高校联盟就是科研实力的代名词。“ U15 U15大学联盟是德国的大型高校、研究型高校联盟，成立于2012年10月12日。联盟成立宗旨为改善德国科研和教育的架构。占德国高校总数13%的十五所高校，承担了37%的第三方资助、60%的医科资助、43%的博士授予，并获得了43%的莱布尼茨奖。目前联盟主席为海德堡大学校长爱特尔(Bernd Eitel)。联盟成员,柏林自由大学,海德堡大学,柏林洪堡大学,波恩大学,法兰克福大学,弗莱堡大学,哥廷根大学,汉堡大学,科隆大学,莱比锡大学,美因茨大学,慕尼黑大学,明斯特大学,图宾根大学,维尔茨堡大学. 参考DAAD查找路径]]></content>
  </entry>
  <entry>
    <title><![CDATA[少年的诗]]></title>
    <url>%2Fblog%2F2018%2F12%2F13%2F%E5%B0%91%E5%B9%B4%E7%9A%84%E8%AF%97%2F</url>
    <content type="text"><![CDATA[三峡江声流笔底, 六朝帆影落樽前胸中机杼，笔底波澜写一点诗，总是好的 《侠的诗》 “傲指弹云分入酒，青冠流古照秋霜”太平无侠士那就写一点诗放浪侠气 「侠」辞京飘迹楚山茫，谑眼穿尘淡冕光。傲指弹云分入酒，青冠流古照秋霜。 《少年游》 “花有重开日，人无再少年”最好的时光总是少年时那走遍的江河 「入山」山深纵马伫难前，步下飞光百丈渊。雾卷云廊封道尽，雨开峰骨作桥源。悠笛风远惊人迹，长海际回忆陌年。绝处寻松掬水月，春秋一脉本多缘。 「古原雨」故迹青鸦驻，三江入古原。立堤涛水逝，临野聚峰眠。塔外清魂雨，烟间断梦田。萧霜凋旧木，归马闭门前。 「题赛里木湖」深云压海境，微雨落晶珠。几骑寻闲客，风波自在途。 《韵之心》 古有琴谱阳关三叠“劝君更进一杯酒，西出阳关无故人”古有诗歌驻马衔杯“圣代即今多雨露，暂时分手莫踌躇” 「缘深缘浅，留念诸君」何泣春江归晚照？松风水落对槐花。遗朝柳折留寻念，此坊歌倾续梦茶。解带吹心风作客，流光转忆泪分霞。云终不见诸君影，碧海行帆懒问涯。 「岳麓•祭•忆君之风忆水长」 望尽湘江暮，亭间墨客愁。满林兼叶落，独木与谁谋！老雁飞斜镜，青衫立冷丘。出钩疑钓叟，惟是月如舟。 《家国情》 “王师北定中原日”太平年间曾经的荣辱仿佛被渐渐淡化了而那血脉奔腾的黄河长江却依然肃穆 「记南京大屠杀」 寇兵侵戮昔悲史，瑟瑟汗青警自鸣。国父陵前国尽复，雨花台上雨堪惊！三江拾恨祭英骨，亿气同途筑远程。勿任危心流海去，涯间舟载惜天明。]]></content>
  </entry>
</search>
